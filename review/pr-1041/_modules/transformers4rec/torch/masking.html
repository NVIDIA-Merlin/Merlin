

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>transformers4rec.torch.masking &#8212; NVIDIA Merlin</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/versions.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/js/rtd-version-switcher.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/transformers4rec/torch/masking';</script>
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/_modules/transformers4rec/torch/masking.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVJ1Y1YJHK', {
        'anonymize_ip': false,
    });
  </script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,300&display=swap" rel="stylesheet">
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">NVIDIA Merlin</p>
  
</a></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../README.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../guide/recommender_system_guide.html">Recommender System Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/recommender_models.html">Recommender Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples/index.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/getting-started-movielens/index.html">Getting Started using the MovieLens Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/01-Download-Convert.html">MovieLens Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-TF.html">Getting Started MovieLens: Training with TensorFlow</a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-PyTorch.html">Training with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/04-Triton-Inference-with-HugeCTR.html">Serving the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/04-Triton-Inference-with-TF.html">Serve Recommendations from the TensorFlow Model</a></li>

</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/index.html">Deploying a Multi-Stage Recommender System</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/01-Building-Recommender-Systems-with-Merlin.html">Building the Recommender System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/02-Deploying-multi-stage-RecSys-with-Merlin-Systems.html">Deploying the Recommender System with Triton</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/sagemaker-tensorflow/index.html">Merlin and AWS SageMaker</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/sagemaker-tensorflow/sagemaker-merlin-tensorflow.html">Training and Serving Merlin on AWS SageMaker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/scaling-criteo/index.html">Scaling Large Datasets with Criteo</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/01-Download-Convert.html">Criteo Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/03-Training-with-Merlin-Models-TensorFlow.html">Training with Merlin Models and TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/04-Triton-Inference-with-HugeCTR.html">Deploy the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/04-Triton-Inference-with-Merlin-Models-TensorFlow.html">Deploy the TensorFlow Model with Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../support_matrix/index.html">Merlin Support Matrix</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_hugectr.html">Merlin HugeCTR Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_tensorflow.html">Merlin TensorFlow Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_pytorch.html">Merlin PyTorch Support Matrix</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.dag.html">merlin.dag</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.BaseOperator.html">merlin.dag.BaseOperator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.Graph.html">merlin.dag.Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.Node.html">merlin.dag.Node</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.ColumnSelector.html">merlin.dag.ColumnSelector</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_dataloader.html">merlin.loader</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tensorflow.Loader.html">merlin.dataloader.tensorflow.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tensorflow.KerasSequenceValidater.html">merlin.dataloader.tensorflow.KerasSequenceValidater</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.configure_tensorflow.html">merlin.dataloader.tf_utils.configure_tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns.html">merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.HAS_GPU.html">merlin.dataloader.tf_utils.HAS_GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.torch.Loader.html">merlin.dataloader.torch.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.torch.DLDataLoader.html">merlin.dataloader.torch.DLDataLoader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.jax.Loader.html">merlin.dataloader.jax.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.loader_base.LoaderBase.html">merlin.dataloader.loader_base.LoaderBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.loader_base.ChunkQueue.html">merlin.dataloader.loader_base.ChunkQueue</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.io.html">merlin.io</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.io.Dataset.html">merlin.io.Dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_models.html">merlin.models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DCNModel.html">merlin.models.tf.DCNModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DeepFMModel.html">merlin.models.tf.DeepFMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DLRMModel.html">merlin.models.tf.DLRMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.WideAndDeepModel.html">merlin.models.tf.WideAndDeepModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Encoder.html">merlin.models.tf.Encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.EmbeddingEncoder.html">merlin.models.tf.EmbeddingEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemRetrievalScorer.html">merlin.models.tf.ItemRetrievalScorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RetrievalModelV2.html">merlin.models.tf.RetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationModelV2.html">merlin.models.tf.MatrixFactorizationModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationModel.html">merlin.models.tf.MatrixFactorizationModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerModelV2.html">merlin.models.tf.TwoTowerModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerModel.html">merlin.models.tf.TwoTowerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.YoutubeDNNRetrievalModelV2.html">merlin.models.tf.YoutubeDNNRetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.YoutubeDNNRetrievalModel.html">merlin.models.tf.YoutubeDNNRetrievalModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Embeddings.html">merlin.models.tf.Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.EmbeddingTable.html">merlin.models.tf.EmbeddingTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AverageEmbeddingsByWeightFeature.html">merlin.models.tf.AverageEmbeddingsByWeightFeature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ReplaceMaskedEmbeddings.html">merlin.models.tf.ReplaceMaskedEmbeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.L2Norm.html">merlin.models.tf.L2Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InputBlockV2.html">merlin.models.tf.InputBlockV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InputBlock.html">merlin.models.tf.InputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Continuous.html">merlin.models.tf.Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousFeatures.html">merlin.models.tf.ContinuousFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousEmbedding.html">merlin.models.tf.ContinuousEmbedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousProjection.html">merlin.models.tf.ContinuousProjection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceEmbeddingFeatures.html">merlin.models.tf.SequenceEmbeddingFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DLRMBlock.html">merlin.models.tf.DLRMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MLPBlock.html">merlin.models.tf.MLPBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CrossBlock.html">merlin.models.tf.CrossBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerBlock.html">merlin.models.tf.TwoTowerBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationBlock.html">merlin.models.tf.MatrixFactorizationBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DotProductInteraction.html">merlin.models.tf.DotProductInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.FMBlock.html">merlin.models.tf.FMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.FMPairwiseInteraction.html">merlin.models.tf.FMPairwiseInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PredictionTasks.html">merlin.models.tf.PredictionTasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PredictionTask.html">merlin.models.tf.PredictionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BinaryClassificationTask.html">merlin.models.tf.BinaryClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MultiClassClassificationTask.html">merlin.models.tf.MultiClassClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RegressionTask.html">merlin.models.tf.RegressionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemRetrievalTask.html">merlin.models.tf.ItemRetrievalTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.OutputBlock.html">merlin.models.tf.OutputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ModelOutput.html">merlin.models.tf.ModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BinaryOutput.html">merlin.models.tf.BinaryOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CategoricalOutput.html">merlin.models.tf.CategoricalOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContrastiveOutput.html">merlin.models.tf.ContrastiveOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RegressionOutput.html">merlin.models.tf.RegressionOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ColumnBasedSampleWeight.html">merlin.models.tf.ColumnBasedSampleWeight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequentialBlock.html">merlin.models.tf.SequentialBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ParallelBlock.html">merlin.models.tf.ParallelBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ParallelPredictionBlock.html">merlin.models.tf.ParallelPredictionBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DenseResidualBlock.html">merlin.models.tf.DenseResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DualEncoderBlock.html">merlin.models.tf.DualEncoderBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ResidualBlock.html">merlin.models.tf.ResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TabularBlock.html">merlin.models.tf.TabularBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Filter.html">merlin.models.tf.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Cond.html">merlin.models.tf.Cond</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TopKEncoder.html">merlin.models.tf.TopKEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MultiOptimizer.html">merlin.models.tf.MultiOptimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.LazyAdam.html">merlin.models.tf.LazyAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.OptimizerBlocks.html">merlin.models.tf.OptimizerBlocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.split_embeddings_on_size.html">merlin.models.tf.split_embeddings_on_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CategoryEncoding.html">merlin.models.tf.CategoryEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MapValues.html">merlin.models.tf.MapValues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PrepareListFeatures.html">merlin.models.tf.PrepareListFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PrepareFeatures.html">merlin.models.tf.PrepareFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToSparse.html">merlin.models.tf.ToSparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToDense.html">merlin.models.tf.ToDense</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToTarget.html">merlin.models.tf.ToTarget</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToOneHot.html">merlin.models.tf.ToOneHot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.HashedCross.html">merlin.models.tf.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.HashedCrossAll.html">merlin.models.tf.HashedCrossAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BroadcastToSequence.html">merlin.models.tf.BroadcastToSequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictNext.html">merlin.models.tf.SequencePredictNext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictLast.html">merlin.models.tf.SequencePredictLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictRandom.html">merlin.models.tf.SequencePredictRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceTargetAsInput.html">merlin.models.tf.SequenceTargetAsInput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceMaskLast.html">merlin.models.tf.SequenceMaskLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceMaskRandom.html">merlin.models.tf.SequenceMaskRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ExpandDims.html">merlin.models.tf.ExpandDims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.StochasticSwapNoise.html">merlin.models.tf.StochasticSwapNoise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AsTabular.html">merlin.models.tf.AsTabular</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MMOEBlock.html">merlin.models.tf.MMOEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CGCBlock.html">merlin.models.tf.CGCBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PLEBlock.html">merlin.models.tf.PLEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Loader.html">merlin.models.tf.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AvgPrecisionAt.html">merlin.models.tf.AvgPrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MRRAt.html">merlin.models.tf.MRRAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.NDCGAt.html">merlin.models.tf.NDCGAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PrecisionAt.html">merlin.models.tf.PrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RecallAt.html">merlin.models.tf.RecallAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TopKMetricsAggregator.html">merlin.models.tf.TopKMetricsAggregator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemSampler.html">merlin.models.tf.ItemSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InBatchSampler.html">merlin.models.tf.InBatchSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PopularityBasedSampler.html">merlin.models.tf.PopularityBasedSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.CategoricalCrossEntropy.html">merlin.models.tf.losses.CategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.SparseCategoricalCrossEntropy.html">merlin.models.tf.losses.SparseCategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.BPRLoss.html">merlin.models.tf.losses.BPRLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.BPRmaxLoss.html">merlin.models.tf.losses.BPRmaxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.HingeLoss.html">merlin.models.tf.losses.HingeLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.LogisticLoss.html">merlin.models.tf.losses.LogisticLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1Loss.html">merlin.models.tf.losses.TOP1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1maxLoss.html">merlin.models.tf.losses.TOP1maxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1v2Loss.html">merlin.models.tf.losses.TOP1v2Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.select_targets.html">merlin.models.utils.schema_utils.select_targets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json.html">merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema.html">merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.create_categorical_column.html">merlin.models.utils.schema_utils.create_categorical_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.create_continuous_column.html">merlin.models.utils.schema_utils.create_continuous_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.filter_dict_by_schema.html">merlin.models.utils.schema_utils.filter_dict_by_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.categorical_cardinalities.html">merlin.models.utils.schema_utils.categorical_cardinalities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.categorical_domains.html">merlin.models.utils.schema_utils.categorical_domains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.get_embedding_sizes_from_schema.html">merlin.models.utils.schema_utils.get_embedding_sizes_from_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.get_embedding_size_from_cardinality.html">merlin.models.utils.schema_utils.get_embedding_size_from_cardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TensorInitializer.html">merlin.models.tf.TensorInitializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.filter_kwargs.html">merlin.models.utils.misc_utils.filter_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.safe_json.html">merlin.models.utils.misc_utils.safe_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_filenames.html">merlin.models.utils.misc_utils.get_filenames</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_label_feature_name.html">merlin.models.utils.misc_utils.get_label_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_timestamp_feature_name.html">merlin.models.utils.misc_utils.get_timestamp_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_parquet_files_names.html">merlin.models.utils.misc_utils.get_parquet_files_names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.Timing.html">merlin.models.utils.misc_utils.Timing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_object_size.html">merlin.models.utils.misc_utils.get_object_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.validate_dataset.html">merlin.models.utils.misc_utils.validate_dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.camelcase_to_snakecase.html">merlin.models.utils.registry.camelcase_to_snakecase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.snakecase_to_camelcase.html">merlin.models.utils.registry.snakecase_to_camelcase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.default_name.html">merlin.models.utils.registry.default_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.default_object_name.html">merlin.models.utils.registry.default_object_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.Registry.html">merlin.models.utils.registry.Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.RegistryMixin.html">merlin.models.utils.registry.RegistryMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.display_list_by_prefix.html">merlin.models.utils.registry.display_list_by_prefix</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.schema.html">merlin.schema</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.Schema.html">merlin.schema.Schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.ColumnSchema.html">merlin.schema.ColumnSchema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.Tags.html">merlin.schema.Tags</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_systems.html">merlin.systems</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.Ensemble.html">merlin.systems.dag.Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.workflow.TransformWorkflow.html">merlin.systems.dag.ops.workflow.TransformWorkflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.tensorflow.PredictTensorflow.html">merlin.systems.dag.ops.tensorflow.PredictTensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.fil.PredictForest.html">merlin.systems.dag.ops.fil.PredictForest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.implicit.PredictImplicit.html">merlin.systems.dag.ops.implicit.PredictImplicit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling.html">merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.session_filter.FilterCandidates.html">merlin.systems.dag.ops.session_filter.FilterCandidates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.unroll_features.UnrollFeatures.html">merlin.systems.dag.ops.unroll_features.UnrollFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.triton.convert_df_to_triton_input.html">merlin.systems.triton.convert_df_to_triton_input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.triton.convert_triton_output_to_df.html">merlin.systems.triton.convert_triton_output_to_df</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_nvtabular.html">nvtabular</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.workflow.workflow.Workflow.html">nvtabular.workflow.workflow.Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.workflow.workflow.WorkflowNode.html">nvtabular.workflow.workflow.WorkflowNode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Bucketize.html">nvtabular.ops.Bucketize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Categorify.html">nvtabular.ops.Categorify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.DropLowCardinality.html">nvtabular.ops.DropLowCardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.HashBucket.html">nvtabular.ops.HashBucket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.HashedCross.html">nvtabular.ops.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TargetEncoding.html">nvtabular.ops.TargetEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Clip.html">nvtabular.ops.Clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.LogOp.html">nvtabular.ops.LogOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Normalize.html">nvtabular.ops.Normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.NormalizeMinMax.html">nvtabular.ops.NormalizeMinMax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Dropna.html">nvtabular.ops.Dropna</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.FillMissing.html">nvtabular.ops.FillMissing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.FillMedian.html">nvtabular.ops.FillMedian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.DifferenceLag.html">nvtabular.ops.DifferenceLag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Filter.html">nvtabular.ops.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Groupby.html">nvtabular.ops.Groupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.JoinExternal.html">nvtabular.ops.JoinExternal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.JoinGroupby.html">nvtabular.ops.JoinGroupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddMetadata.html">nvtabular.ops.AddMetadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddProperties.html">nvtabular.ops.AddProperties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddTags.html">nvtabular.ops.AddTags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Rename.html">nvtabular.ops.Rename</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ReduceDtypeSize.html">nvtabular.ops.ReduceDtypeSize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsItemFeatures.html">nvtabular.ops.TagAsItemFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsItemID.html">nvtabular.ops.TagAsItemID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsUserFeatures.html">nvtabular.ops.TagAsUserFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsUserID.html">nvtabular.ops.TagAsUserID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ListSlice.html">nvtabular.ops.ListSlice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ValueCount.html">nvtabular.ops.ValueCount</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ColumnSimilarity.html">nvtabular.ops.ColumnSimilarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.LambdaOp.html">nvtabular.ops.LambdaOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Operator.html">nvtabular.ops.Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.StatOperator.html">nvtabular.ops.StatOperator</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_transformers4rec/modules.html">transformers4rec</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.html">transformers4rec package</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.config.html">transformers4rec.config package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.html">transformers4rec.torch package</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.block.html">transformers4rec.torch.block package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.features.html">transformers4rec.torch.features package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.model.html">transformers4rec.torch.model package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.tabular.html">transformers4rec.torch.tabular package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.utils.html">transformers4rec.torch.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.utils.html">transformers4rec.utils package</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.html">merlin_standard_lib package</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.proto.html">merlin_standard_lib.proto package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.schema.html">merlin_standard_lib.schema package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.utils.html">merlin_standard_lib.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-merlin-ecosystem-nav" aria-label="Merlin Ecosystem Nav">
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul class="nav bd-sidenav">
      <li class="toctree-l1"><a class="reference external" href="/core/">Core</a></li>
      <li class="toctree-l1"><a class="reference external" href="/models/">Models</a></li>
      <li class="toctree-l1"><a class="reference external" href="/systems/">Systems</a></li>
      <li class="toctree-l1"><a class="reference external" href="/NVTabular/">NVTabular</a></li>
      <li class="toctree-l1"><a class="reference external" href="/Transformers4Rec/">Transformers4Rec</a></li>
      <li class="toctree-l1"><a class="reference external" href="/dataloader/">Dataloader</a></li>
      <li class="toctree-l1"><a class="reference external" href="/HugetCTR/">HugeCTR</a></li>
    </ul>
  </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for transformers4rec.torch.masking</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright (c) 2021, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">merlin.models.utils.doc_utils</span> <span class="kn">import</span> <span class="n">docstring_parameter</span>
<span class="kn">from</span> <span class="nn">merlin.models.utils.registry</span> <span class="kn">import</span> <span class="n">Registry</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="kn">from</span> <span class="nn">.utils.torch_utils</span> <span class="kn">import</span> <span class="n">OutputSizeMixin</span>

<span class="n">masking_registry</span> <span class="o">=</span> <span class="n">Registry</span><span class="p">(</span><span class="s2">&quot;torch.masking&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="MaskingInfo"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskingInfo">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">MaskingInfo</span><span class="p">:</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></div>


<span class="n">MASK_SEQUENCE_PARAMETERS_DOCSTRING</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    hidden_size: int</span>
<span class="s2">        The hidden dimension of input tensors, needed to initialize trainable vector of masked</span>
<span class="s2">        positions.</span>
<span class="s2">    padding_idx: int, default = 0</span>
<span class="s2">        Index of padding item used for getting batch of sequences with the same length</span>
<span class="s2">    eval_on_last_item_seq_only: bool, default = True</span>
<span class="s2">        Predict only last item during evaluation</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">TRAINING_TESTING_FLAGS_DOCSTRING</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    training: bool</span>
<span class="s2">        Flag to indicate whether we are in `Training` mode or not.</span>
<span class="s2">        During training, the labels can be any items within the sequence</span>
<span class="s2">        based on the selected masking task.</span>
<span class="s2">    testing: bool</span>
<span class="s2">        Flag to indicate whether we are in `Evaluation` (=True)</span>
<span class="s2">        or `Inference` (=False) mode.</span>
<span class="s2">        During evaluation, we are predicting all next items or last item only</span>
<span class="s2">        in the sequence based on the param `eval_on_last_item_seq_only`.</span>
<span class="s2">        During inference, we don&#39;t mask the input sequence and use all available</span>
<span class="s2">        information to predict the next item.</span>
<span class="s2">&quot;&quot;&quot;</span>


<div class="viewcode-block" id="MaskSequence"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence">[docs]</a><span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">mask_sequence_parameters</span><span class="o">=</span><span class="n">MASK_SEQUENCE_PARAMETERS_DOCSTRING</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">MaskSequence</span><span class="p">(</span><span class="n">OutputSizeMixin</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class to prepare masked items inputs/labels for language modeling tasks.</span>

<span class="sd">    Transformer architectures can be trained in different ways. Depending of the training method,</span>
<span class="sd">    there is a specific masking schema. The masking schema sets the items to be predicted (labels)</span>
<span class="sd">    and mask (hide) their positions in the sequence so that they are not used by the Transformer</span>
<span class="sd">    layers for prediction.</span>

<span class="sd">    We currently provide 4 different masking schemes out of the box:</span>
<span class="sd">        - Causal LM (clm)</span>
<span class="sd">        - Masked LM (mlm)</span>
<span class="sd">        - Permutation LM (plm)</span>
<span class="sd">        - Replacement Token Detection (rtd)</span>

<span class="sd">    This class can be extended to add different a masking scheme.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    hidden_size:</span>
<span class="sd">        The hidden dimension of input tensors, needed to initialize trainable vector of</span>
<span class="sd">        masked positions.</span>
<span class="sd">    pad_token: int, default = 0</span>
<span class="sd">        Index of the padding token used for getting batch of sequences with the same length</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># TODO: Link to masking-class in the doc-string.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">eval_on_last_item_seq_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaskSequence</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="n">padding_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_on_last_item_seq_only</span> <span class="o">=</span> <span class="n">eval_on_last_item_seq_only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masked_targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Create a trainable embedding to replace masked interactions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_embedding</span><span class="p">,</span>
            <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">std</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">flags_parameters_docstrings</span><span class="o">=</span><span class="n">TRAINING_TESTING_FLAGS_DOCSTRING</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_compute_masked_targets</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaskingInfo</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to prepare masked labels based on the sequence of item ids.</span>
<span class="sd">        It returns The true labels of masked positions and the related boolean mask.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        item_ids: torch.Tensor</span>
<span class="sd">            The sequence of input item ids used for deriving labels of</span>
<span class="sd">            next item prediction task.</span>
<span class="sd">        {flags_parameters_docstrings}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

<div class="viewcode-block" id="MaskSequence.compute_masked_targets"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence.compute_masked_targets">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">flags_parameters_docstrings</span><span class="o">=</span><span class="n">TRAINING_TESTING_FLAGS_DOCSTRING</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_masked_targets</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaskingInfo</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to prepare masked labels based on the sequence of item ids.</span>
<span class="sd">        It returns The true labels of masked positions and the related boolean mask.</span>
<span class="sd">        And the attributes of the class `mask_schema` and `masked_targets`</span>
<span class="sd">        are updated to be re-used in other modules.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        item_ids: torch.Tensor</span>
<span class="sd">            The sequence of input item ids used for deriving labels of</span>
<span class="sd">            next item prediction task.</span>
<span class="sd">        {flags_parameters_docstrings}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[MaskingSchema, MaskedTargets]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">item_ids</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;`item_ids` must have 2 dimensions.&quot;</span>
        <span class="n">masking_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_masked_targets</span><span class="p">(</span><span class="n">item_ids</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span> <span class="n">testing</span><span class="o">=</span><span class="n">testing</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_schema</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">masked_targets</span> <span class="o">=</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">targets</span>

        <span class="k">return</span> <span class="n">masking_info</span></div>

<div class="viewcode-block" id="MaskSequence.apply_mask_to_inputs"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence.apply_mask_to_inputs">[docs]</a>    <span class="k">def</span> <span class="nf">apply_mask_to_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">schema</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Control the masked positions in the inputs by replacing the true interaction</span>
<span class="sd">        by a learnable masked embedding.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs: torch.Tensor</span>
<span class="sd">            The 3-D tensor of interaction embeddings resulting from the ops:</span>
<span class="sd">            TabularFeatures + aggregation + projection(optional)</span>
<span class="sd">        schema: MaskingSchema</span>
<span class="sd">            The boolean mask indicating masked positions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">testing</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">inputs</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">schema</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_embedding</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">inputs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">inputs</span></div>

<div class="viewcode-block" id="MaskSequence.predict_all"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence.predict_all">[docs]</a>    <span class="k">def</span> <span class="nf">predict_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaskingInfo</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare labels for all next item predictions instead of</span>
<span class="sd">        last-item predictions in a user&#39;s sequence.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        item_ids: torch.Tensor</span>
<span class="sd">            The sequence of input item ids used for deriving labels of</span>
<span class="sd">            next item prediction task.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[MaskingSchema, MaskedTargets]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO : Add option to predict N-last items</span>
        <span class="c1"># shift sequence of item-ids</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">item_ids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="c1"># As after shifting the sequence length will be subtracted by one, adding a masked item in</span>
        <span class="c1"># the sequence to return to the initial sequence.</span>
        <span class="c1"># This is important for ReformerModel(), for example</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
            <span class="p">[</span>
                <span class="n">labels</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># apply mask on input where target is on padding index</span>
        <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>

        <span class="k">return</span> <span class="n">MaskingInfo</span><span class="p">(</span><span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span></div>

<div class="viewcode-block" id="MaskSequence.forward"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_masked_targets</span><span class="p">(</span><span class="n">item_ids</span><span class="o">=</span><span class="n">item_ids</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span> <span class="n">testing</span><span class="o">=</span><span class="n">testing</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`mask_schema must be set.`&quot;</span><span class="p">)</span>
        <span class="n">schema</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_schema</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_mask_to_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span> <span class="n">testing</span><span class="o">=</span><span class="n">testing</span><span class="p">)</span></div>

<div class="viewcode-block" id="MaskSequence.forward_output_size"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence.forward_output_size">[docs]</a>    <span class="k">def</span> <span class="nf">forward_output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_size</span></div>

<div class="viewcode-block" id="MaskSequence.transformer_required_arguments"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence.transformer_required_arguments">[docs]</a>    <span class="k">def</span> <span class="nf">transformer_required_arguments</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">{}</span></div>

<div class="viewcode-block" id="MaskSequence.transformer_optional_arguments"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence.transformer_optional_arguments">[docs]</a>    <span class="k">def</span> <span class="nf">transformer_optional_arguments</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">{}</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">transformer_arguments</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare additional arguments to pass to the Transformer forward methods.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_required_arguments</span><span class="p">(),</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_optional_arguments</span><span class="p">()}</span></div>


<div class="viewcode-block" id="CausalLanguageModeling"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.CausalLanguageModeling">[docs]</a><span class="nd">@masking_registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;clm&quot;</span><span class="p">,</span> <span class="s2">&quot;causal&quot;</span><span class="p">)</span>
<span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">mask_sequence_parameters</span><span class="o">=</span><span class="n">MASK_SEQUENCE_PARAMETERS_DOCSTRING</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CausalLanguageModeling</span><span class="p">(</span><span class="n">MaskSequence</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In Causal Language Modeling (clm) you predict the next item based on past positions of the</span>
<span class="sd">    sequence. Future positions are masked.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    {mask_sequence_parameters}</span>
<span class="sd">    train_on_last_item_seq_only: predict only last item during training</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">eval_on_last_item_seq_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">train_on_last_item_seq_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CausalLanguageModeling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
            <span class="n">eval_on_last_item_seq_only</span><span class="o">=</span><span class="n">eval_on_last_item_seq_only</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_on_last_item_seq_only</span> <span class="o">=</span> <span class="n">train_on_last_item_seq_only</span>

    <span class="k">def</span> <span class="nf">_compute_masked_targets</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaskingInfo</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">testing</span><span class="p">:</span>
            <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">item_ids</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
            <span class="k">return</span> <span class="n">MaskingInfo</span><span class="p">(</span><span class="n">mask_labels</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">)</span>

        <span class="n">masking_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_all</span><span class="p">(</span><span class="n">item_ids</span><span class="p">)</span>
        <span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">targets</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_on_last_item_seq_only</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">training</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_on_last_item_seq_only</span> <span class="ow">and</span> <span class="n">training</span>
        <span class="p">):</span>
            <span class="n">rows_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span>  <span class="c1"># type: ignore</span>
            <span class="p">)</span>
            <span class="n">last_item_sessions</span> <span class="o">=</span> <span class="n">mask_labels</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">label_seq_trg_eval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">label_seq_trg_eval</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span>
            <span class="c1"># Updating labels and mask</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">label_seq_trg_eval</span>
            <span class="c1"># We only mask padded positions</span>
            <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">item_ids</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>

        <span class="k">return</span> <span class="n">MaskingInfo</span><span class="p">(</span><span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<div class="viewcode-block" id="CausalLanguageModeling.apply_mask_to_inputs"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.CausalLanguageModeling.apply_mask_to_inputs">[docs]</a>    <span class="k">def</span> <span class="nf">apply_mask_to_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask_schema</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">testing</span><span class="p">:</span>
            <span class="c1"># Replacing the inputs corresponding to padded items with a trainable embedding</span>
            <span class="c1"># To mimic training and evaluation masking strategy</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">mask_schema</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
                <span class="n">inputs</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_embedding</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">inputs</span>
        <span class="c1"># shift sequence of interaction embeddings</span>
        <span class="n">pos_emb_inp</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Adding a masked item in the sequence to return to the initial sequence.</span>
        <span class="n">pos_emb_inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
            <span class="p">[</span>
                <span class="n">pos_emb_inp</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">pos_emb_inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pos_emb_inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">pos_emb_inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Replacing the inputs corresponding to padded items with a trainable embedding</span>
        <span class="n">pos_emb_inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">mask_schema</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
            <span class="n">pos_emb_inp</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_embedding</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">pos_emb_inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_emb_inp</span></div></div>


<div class="viewcode-block" id="MaskedLanguageModeling"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskedLanguageModeling">[docs]</a><span class="nd">@masking_registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;mlm&quot;</span><span class="p">,</span> <span class="s2">&quot;masked&quot;</span><span class="p">)</span>
<span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">mask_sequence_parameters</span><span class="o">=</span><span class="n">MASK_SEQUENCE_PARAMETERS_DOCSTRING</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">MaskedLanguageModeling</span><span class="p">(</span><span class="n">MaskSequence</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In Masked Language Modeling (mlm) you randomly select some positions of the sequence to be</span>
<span class="sd">    predicted, which are masked.</span>
<span class="sd">    During training, the Transformer layer is allowed to use positions on the right (future info).</span>
<span class="sd">    During inference, all past items are visible for the Transformer layer, which tries to predict</span>
<span class="sd">    the next item.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    {mask_sequence_parameters}</span>
<span class="sd">    mlm_probability: Optional[float], default = 0.15</span>
<span class="sd">        Probability of an item to be selected (masked) as a label of the given sequence.</span>
<span class="sd">        p.s. We enforce that at least one item is masked for each sequence, so that the network can</span>
<span class="sd">        learn something with it.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">eval_on_last_item_seq_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">mlm_probability</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.15</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaskedLanguageModeling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
            <span class="n">eval_on_last_item_seq_only</span><span class="o">=</span><span class="n">eval_on_last_item_seq_only</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlm_probability</span> <span class="o">=</span> <span class="n">mlm_probability</span>

    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">flags_parameters_docstrings</span><span class="o">=</span><span class="n">TRAINING_TESTING_FLAGS_DOCSTRING</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_compute_masked_targets</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">testing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaskingInfo</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare sequence with mask schema for masked language modeling prediction</span>
<span class="sd">        the function is based on HuggingFace&#39;s transformers/data/data_collator.py</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        item_ids: torch.Tensor</span>
<span class="sd">            Sequence of input itemid (target) column</span>
<span class="sd">        {flags_parameters_docstrings}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        labels: torch.Tensor</span>
<span class="sd">            Sequence of masked item ids.</span>
<span class="sd">        mask_labels: torch.Tensor</span>
<span class="sd">            Masking schema for masked targets positions.</span>
<span class="sd">        {flags_parameters_docstrings}</span>

<span class="sd">        `Note:` During inference, the inputs are extended with one additional</span>
<span class="sd">            [MASK] item embeddings. This position is then used to retrieve</span>
<span class="sd">            the final hidden representation from the transformer block.</span>
<span class="sd">            This is needed to take into account the actual target position</span>
<span class="sd">            when applying the transformer layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">non_padded_mask</span> <span class="o">=</span> <span class="n">item_ids</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
        <span class="n">rows_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">item_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">testing</span><span class="p">:</span>
            <span class="c1"># At inference we extend the input with a [MASK] element at the first padded position</span>
            <span class="c1"># to take into account the positional encoding of the target</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                <span class="p">(</span><span class="n">item_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">item_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">last_item_sessions</span> <span class="o">=</span> <span class="n">non_padded_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span> <span class="o">=</span> <span class="n">item_ids</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
            <span class="k">return</span> <span class="n">MaskingInfo</span><span class="p">(</span><span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="n">item_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="c1"># During training, masks labels to be predicted according to a probability, ensuring that</span>
        <span class="c1">#   each session has at least one label to predict</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="c1"># Selects a percentage of items to be masked (selected as labels)</span>
            <span class="n">probability_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                <span class="n">item_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlm_probability</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">probability_matrix</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">non_padded_mask</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">mask_labels</span><span class="p">,</span>
                <span class="n">item_ids</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">item_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">),</span>
            <span class="p">)</span>

            <span class="c1"># Set at least one item in the sequence to mask, so that the network</span>
            <span class="c1"># can learn something with this session</span>
            <span class="n">one_random_index_by_session</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
                <span class="n">non_padded_mask</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">one_random_index_by_session</span><span class="p">]</span> <span class="o">=</span> <span class="n">item_ids</span><span class="p">[</span>
                <span class="n">rows_ids</span><span class="p">,</span> <span class="n">one_random_index_by_session</span>
            <span class="p">]</span>
            <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>

            <span class="c1"># If a sequence has only masked labels, unmasks one of the labels</span>
            <span class="n">sequences_with_only_labels</span> <span class="o">=</span> <span class="n">mask_labels</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">non_padded_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">sampled_labels_to_unmask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
                <span class="n">mask_labels</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

            <span class="n">labels_to_unmask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span>
                <span class="n">sampled_labels_to_unmask</span><span class="p">,</span> <span class="n">sequences_with_only_labels</span>
            <span class="p">)</span>
            <span class="n">rows_to_unmask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">sequences_with_only_labels</span><span class="p">)</span>

            <span class="n">labels</span><span class="p">[</span><span class="n">rows_to_unmask</span><span class="p">,</span> <span class="n">labels_to_unmask</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
            <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_on_last_item_seq_only</span><span class="p">:</span>
                <span class="n">last_item_sessions</span> <span class="o">=</span> <span class="n">non_padded_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">labels</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span> <span class="o">=</span> <span class="n">item_ids</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span>
                <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">masking_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_all</span><span class="p">(</span><span class="n">item_ids</span><span class="p">)</span>
                <span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">targets</span>

        <span class="k">return</span> <span class="n">MaskingInfo</span><span class="p">(</span><span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<div class="viewcode-block" id="MaskedLanguageModeling.apply_mask_to_inputs"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.MaskedLanguageModeling.apply_mask_to_inputs">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">flags_parameters_docstrings</span><span class="o">=</span><span class="n">TRAINING_TESTING_FLAGS_DOCSTRING</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">apply_mask_to_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mask_schema</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">testing</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Control the masked positions in the inputs by replacing the true interaction</span>
<span class="sd">        by a learnable masked embedding.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs: torch.Tensor</span>
<span class="sd">            The 3-D tensor of interaction embeddings resulting from the ops:</span>
<span class="sd">            TabularFeatures + aggregation + projection(optional)</span>
<span class="sd">        schema: MaskingSchema</span>
<span class="sd">            The boolean mask indicating masked positions.</span>
<span class="sd">        {flags_parameters_docstrings}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">testing</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">training</span><span class="p">:</span>
            <span class="c1"># We extend the inputs with a [MASK] embeddings to take into account</span>
            <span class="c1"># the positional encode of the target</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">mask_schema</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">masked_item_embedding</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">inputs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">inputs</span></div></div>


<div class="viewcode-block" id="PermutationLanguageModeling"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.PermutationLanguageModeling">[docs]</a><span class="nd">@masking_registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;plm&quot;</span><span class="p">,</span> <span class="s2">&quot;permutation&quot;</span><span class="p">)</span>
<span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">mask_sequence_parameters</span><span class="o">=</span><span class="n">MASK_SEQUENCE_PARAMETERS_DOCSTRING</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">PermutationLanguageModeling</span><span class="p">(</span><span class="n">MaskSequence</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In Permutation Language Modeling (plm) you use a permutation factorization at the level of the</span>
<span class="sd">    self-attention layer to define the accessible bidirectional context.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    {mask_sequence_parameters}</span>
<span class="sd">    max_span_length: int</span>
<span class="sd">        maximum length of a span of masked items</span>
<span class="sd">    plm_probability: float</span>
<span class="sd">        The ratio of surrounding items to unmask to define the context of the span-based</span>
<span class="sd">        prediction segment of items</span>
<span class="sd">    permute_all: bool</span>
<span class="sd">        Compute partial span-based prediction (=False) or not.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">eval_on_last_item_seq_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">plm_probability</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">6</span><span class="p">,</span>
        <span class="n">max_span_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">permute_all</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PermutationLanguageModeling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
            <span class="n">eval_on_last_item_seq_only</span><span class="o">=</span><span class="n">eval_on_last_item_seq_only</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">plm_probability</span> <span class="o">=</span> <span class="n">plm_probability</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_span_length</span> <span class="o">=</span> <span class="n">max_span_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">permute_all</span> <span class="o">=</span> <span class="n">permute_all</span>

        <span class="c1"># additional masked scheme needed for XLNet-PLM task :</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_mapping</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perm_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_compute_masked_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_compute_masked_targets_extended</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare the attention masks needed for permutation language modeling</span>
<span class="sd">        The function is based on HuggingFace&#39;s transformers/data/data_collator.py</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        item_ids: torch.Tensor</span>
<span class="sd">            Sequence of input itemid (target) column.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        labels: torch.Tensor</span>
<span class="sd">            Sequence of masked item ids.</span>
<span class="sd">        mask_labels: torch.Tensor</span>
<span class="sd">            Masking schema for masked targets positions.</span>
<span class="sd">        perm_mask: torch.Tensor of shape (bs, seq_len, seq_len)</span>
<span class="sd">            The random factorization order attention mask for each target</span>
<span class="sd">        target_mapping: torch.Tensor of shape (bs, seq_len, seq_len) :</span>
<span class="sd">            Binary mask to specify the items to predict.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="n">item_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">non_padded_mask</span> <span class="o">=</span> <span class="n">item_ids</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>

        <span class="n">rows_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">item_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># During training:</span>
        <span class="c1"># Masks a span of consecutive items to be predicted according to plm_probability,</span>
        <span class="c1"># While ensuring that each session has at least one  item to predict</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">target_mapping</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">perm_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">permute_all</span><span class="p">:</span>
                <span class="c1"># Permute all non padded items</span>
                <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">non_padded_mask</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For each session select a span of consecutive item ids to be masked</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
                    <span class="c1"># Start from the beginning of the sequence by setting `cur_len = 0`</span>
                    <span class="c1"># (number of tokens processed so far).</span>
                    <span class="n">cur_len</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">max_len</span> <span class="o">=</span> <span class="n">non_padded_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span>  <span class="c1"># mask only non-padded items</span>
                    <span class="k">while</span> <span class="n">cur_len</span> <span class="o">&lt;</span> <span class="n">max_len</span><span class="p">:</span>
                        <span class="c1"># Sample a `span_length` from the interval `[1, max_span_length]`</span>
                        <span class="c1"># (length of span of tokens to be masked)</span>
                        <span class="n">span_length</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_span_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                        <span class="c1"># Reserve a context</span>
                        <span class="c1"># to surround span to be masked</span>
                        <span class="n">context_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">span_length</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">plm_probability</span><span class="p">)</span>
                        <span class="c1"># Sample a starting point `start_index`</span>
                        <span class="c1"># from the interval `[cur_len, cur_len + context_length - span_length]`</span>
                        <span class="n">start_index</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">cur_len</span>
                            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                                <span class="n">context_length</span> <span class="o">-</span> <span class="n">span_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>  <span class="c1"># type: ignore</span>
                            <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="n">start_index</span> <span class="o">&lt;</span> <span class="n">max_len</span><span class="p">:</span>
                            <span class="c1"># Mask the span of non-padded items</span>
                            <span class="c1">#   `start_index:start_index + span_length`</span>
                            <span class="n">mask_labels</span><span class="p">[</span>
                                <span class="n">i</span><span class="p">,</span> <span class="n">start_index</span> <span class="p">:</span> <span class="n">start_index</span> <span class="o">+</span> <span class="n">span_length</span>  <span class="c1"># type: ignore</span>
                            <span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                        <span class="c1"># Set `cur_len = cur_len + context_length`</span>
                        <span class="n">cur_len</span> <span class="o">+=</span> <span class="n">context_length</span>
                    <span class="c1"># if no item was masked:</span>
                    <span class="k">if</span> <span class="n">mask_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="c1"># Set at least one item in the sequence to mask, so that the network can</span>
                        <span class="c1"># learn something with this session</span>
                        <span class="n">one_random_index_by_session</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
                            <span class="n">non_padded_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                        <span class="n">mask_labels</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">one_random_index_by_session</span><span class="p">]</span> <span class="o">=</span> <span class="n">item_ids</span><span class="p">[</span>
                            <span class="n">i</span><span class="p">,</span> <span class="n">one_random_index_by_session</span>
                        <span class="p">]</span>
                    <span class="c1"># Since we&#39;re replacing non-masked tokens with padding_idxs in the labels tensor</span>
                    <span class="c1"># instead of skipping them altogether,</span>
                    <span class="c1"># the i-th predict corresponds to the i-th token.</span>
                    <span class="c1"># N.B: the loss function will be computed only on non paded items</span>
                    <span class="n">target_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

            <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_labels</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">item_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">))</span>

            <span class="c1"># If a sequence has only masked labels, unmasks one of the labels</span>
            <span class="n">sequences_with_only_labels</span> <span class="o">=</span> <span class="n">mask_labels</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">non_padded_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">sampled_labels_to_unmask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
                <span class="n">mask_labels</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

            <span class="n">labels_to_unmask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span>
                <span class="n">sampled_labels_to_unmask</span><span class="p">,</span> <span class="n">sequences_with_only_labels</span>
            <span class="p">)</span>
            <span class="n">rows_to_unmask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">sequences_with_only_labels</span><span class="p">)</span>

            <span class="n">labels</span><span class="p">[</span><span class="n">rows_to_unmask</span><span class="p">,</span> <span class="n">labels_to_unmask</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
            <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
                <span class="c1"># Generate permutation indices i.e.</span>
                <span class="c1">#  sample a random factorisation order for the sequence.</span>
                <span class="c1">#  This will determine which tokens a given token can attend to</span>
                <span class="c1"># (encoded in `perm_mask`).</span>
                <span class="c1"># Create a linear factorisation order</span>
                <span class="n">perm_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># randomly permute indices of each session</span>
                <span class="n">perm_index</span> <span class="o">=</span> <span class="n">perm_index</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))]</span>
                <span class="c1"># Set the permutation indices of non-masked (non-functional) tokens to the</span>
                <span class="c1"># smallest index (-1) so that:</span>
                <span class="c1"># (1) They can be seen by all other positions</span>
                <span class="c1"># (2) They cannot see masked positions, so there won&#39;t be information leak</span>
                <span class="n">perm_index</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="o">~</span><span class="n">mask_labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="c1"># The logic for whether the i-th token can attend on the j-th token</span>
                <span class="c1"># based on the factorisation order:</span>
                <span class="c1"># 0 (can attend):</span>
                <span class="c1"># If perm_index[i] &gt; perm_index[j] or j is neither masked nor a padded item</span>
                <span class="c1"># 1 (cannot attend):</span>
                <span class="c1"># If perm_index[i] &lt;= perm_index[j] and j is either masked or a padded item</span>
                <span class="n">perm_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">perm_index</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="o">&lt;=</span> <span class="n">perm_index</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
                <span class="p">)</span> <span class="o">&amp;</span> <span class="n">mask_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="c1"># During evaluation always mask the last item of the session</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_on_last_item_seq_only</span><span class="p">:</span>
                <span class="n">last_item_sessions</span> <span class="o">=</span> <span class="n">non_padded_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="n">labels</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span> <span class="o">=</span> <span class="n">item_ids</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span>
                <span class="n">mask_labels</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
                <span class="n">perm_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># Previous tokens don&#39;t see last non-padded token</span>
                <span class="n">perm_mask</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="p">:,</span> <span class="n">last_item_sessions</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="c1"># add causal mask to avoid attending to future when evaluating</span>
                <span class="n">causal_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">mask_up</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">causal_mask</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">temp_perm</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">mask_up</span><span class="o">.</span><span class="n">expand</span><span class="p">((</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span> <span class="o">+</span> <span class="n">perm_mask</span>
                <span class="p">)</span>
                <span class="n">perm_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">temp_perm</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="c1"># the i-th predict corresponds to the i-th token.</span>
                <span class="n">target_mapping</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">((</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># predict all next items</span>
                <span class="n">masking_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_all</span><span class="p">(</span><span class="n">item_ids</span><span class="p">)</span>
                <span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span> <span class="n">masking_info</span><span class="o">.</span><span class="n">targets</span>
                <span class="c1"># targets:  the i-th predict corresponds to the i-th item in the sequence.</span>
                <span class="n">target_mapping</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">target_mapping</span> <span class="o">=</span> <span class="n">target_mapping</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">)</span>
                <span class="c1"># perm_mask: causal mask</span>
                <span class="c1"># Perm mask:</span>
                <span class="n">perm_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># add causal mask to avoid attending to future when evaluating</span>
                <span class="n">causal_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">device</span><span class="o">=</span><span class="n">item_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">mask_up</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">causal_mask</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">temp_perm</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">mask_up</span><span class="o">.</span><span class="n">expand</span><span class="p">((</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span> <span class="o">+</span> <span class="n">perm_mask</span>
                <span class="p">)</span>
                <span class="n">perm_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">temp_perm</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">mask_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">target_mapping</span><span class="p">,</span> <span class="n">perm_mask</span>

<div class="viewcode-block" id="PermutationLanguageModeling.compute_masked_targets"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.PermutationLanguageModeling.compute_masked_targets">[docs]</a>    <span class="k">def</span> <span class="nf">compute_masked_targets</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">item_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MaskingInfo</span><span class="p">:</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_schema</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">masked_targets</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_mapping</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">perm_mask</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_masked_targets_extended</span><span class="p">(</span><span class="n">item_ids</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MaskingInfo</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_schema</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">masked_targets</span><span class="p">)</span></div>

<div class="viewcode-block" id="PermutationLanguageModeling.transformer_required_arguments"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.PermutationLanguageModeling.transformer_required_arguments">[docs]</a>    <span class="k">def</span> <span class="nf">transformer_required_arguments</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">target_mapping</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_mapping</span><span class="p">,</span> <span class="n">perm_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">perm_mask</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ReplacementLanguageModeling"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.ReplacementLanguageModeling">[docs]</a><span class="nd">@masking_registry</span><span class="o">.</span><span class="n">register_with_multiple_names</span><span class="p">(</span><span class="s2">&quot;rtd&quot;</span><span class="p">,</span> <span class="s2">&quot;replacement&quot;</span><span class="p">)</span>
<span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">mask_sequence_parameters</span><span class="o">=</span><span class="n">MASK_SEQUENCE_PARAMETERS_DOCSTRING</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ReplacementLanguageModeling</span><span class="p">(</span><span class="n">MaskedLanguageModeling</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Replacement Language Modeling (rtd) you use MLM to randomly select some items, but replace</span>
<span class="sd">    them by random tokens.</span>
<span class="sd">    Then, a discriminator model (that can share the weights with the generator or not), is asked</span>
<span class="sd">    to classify whether the item at each position belongs or not to the original sequence.</span>
<span class="sd">    The generator-discriminator architecture was jointly trained using Masked LM and RTD tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    {mask_sequence_parameters}</span>
<span class="sd">    sample_from_batch: bool</span>
<span class="sd">        Whether to sample replacement item ids from the same batch or not</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">eval_on_last_item_seq_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">sample_from_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ReplacementLanguageModeling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
            <span class="n">eval_on_last_item_seq_only</span><span class="o">=</span><span class="n">eval_on_last_item_seq_only</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sample_from_batch</span> <span class="o">=</span> <span class="n">sample_from_batch</span>

<div class="viewcode-block" id="ReplacementLanguageModeling.get_fake_tokens"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.ReplacementLanguageModeling.get_fake_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">get_fake_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">itemid_seq</span><span class="p">,</span> <span class="n">target_flat</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Second task of RTD is binary classification to train the discriminator.</span>
<span class="sd">        The task consists of generating fake data by replacing [MASK] positions with random items,</span>
<span class="sd">        ELECTRA discriminator learns to detect fake replacements.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        itemid_seq: torch.Tensor of shape (bs, max_seq_len)</span>
<span class="sd">            input sequence of item ids</span>
<span class="sd">        target_flat: torch.Tensor of shape (bs*max_seq_len)</span>
<span class="sd">            flattened masked label sequences</span>
<span class="sd">        logits: torch.Tensor of shape (#pos_item, vocab_size or #pos_item),</span>
<span class="sd">            mlm probabilities of positive items computed by the generator model.</span>
<span class="sd">            The logits are over the whole corpus if sample_from_batch = False,</span>
<span class="sd">            over the positive items (masked) of the current batch otherwise</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        corrupted_inputs: torch.Tensor of shape (bs, max_seq_len)</span>
<span class="sd">            input sequence of item ids with fake replacement</span>
<span class="sd">        discriminator_labels: torch.Tensor of shape (bs, max_seq_len)</span>
<span class="sd">            binary labels to distinguish between original and replaced items</span>
<span class="sd">        batch_updates: torch.Tensor of shape (#pos_item)</span>
<span class="sd">            the indices of replacement item within the current batch if sample_from_batch is enabled</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Generate fake interactions embeddings using metadatainfo in addition to item ids.</span>

        <span class="c1"># Replace only items that were masked during MLM</span>
        <span class="n">non_pad_mask</span> <span class="o">=</span> <span class="n">target_flat</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
        <span class="n">pos_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">target_flat</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="p">)</span>
        <span class="c1"># Sample random item ids</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_from_batch</span><span class="p">:</span>
            <span class="c1"># get batch indices for replacement items</span>
            <span class="n">batch_updates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_from_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="c1"># get item ids based on batch indices</span>
            <span class="n">updates</span> <span class="o">=</span> <span class="n">pos_labels</span><span class="p">[</span><span class="n">batch_updates</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># get replacement item ids directly from logits over the whole corpus</span>
            <span class="n">updates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_from_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">batch_updates</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Replace masked labels by replacement item ids</span>
        <span class="c1"># detach() is needed to not propagate the discriminator loss through generator</span>
        <span class="n">corrupted_labels</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">target_flat</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">updates</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># Build discriminator label : distinguish original token from replaced one</span>
        <span class="n">discriminator_labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">corrupted_labels</span> <span class="o">!=</span> <span class="n">target_flat</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">itemid_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># Build corrupted inputs : replacing [MASK] by sampled item</span>
        <span class="n">corrupted_inputs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">itemid_seq</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">updates</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">corrupted_inputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">itemid_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">discriminator_labels</span><span class="p">,</span>
            <span class="n">batch_updates</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ReplacementLanguageModeling.sample_from_softmax"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.torch.masking.ReplacementLanguageModeling.sample_from_softmax">[docs]</a>    <span class="k">def</span> <span class="nf">sample_from_softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sampling method for replacement token modeling (ELECTRA)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        logits: torch.Tensor(pos_item, vocab_size)</span>
<span class="sd">            scores of probability of masked positions returned  by the generator model</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        samples: torch.Tensor(#pos_item)</span>
<span class="sd">            ids of replacements items.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># add noise to logits to prevent from the case where the generator learn to exactly</span>
        <span class="c1"># retrieve the true item that was masked</span>
        <span class="n">uniform_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">gumbel_noise</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">uniform_noise</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">logits</span> <span class="o">+</span> <span class="n">gumbel_noise</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span></div></div>
</pre></div>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 2023, NVIDIA.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>