

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>transformers4rec.config.transformer &#8212; NVIDIA Merlin</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/versions.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/js/rtd-version-switcher.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/transformers4rec/config/transformer';</script>
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/_modules/transformers4rec/config/transformer.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVJ1Y1YJHK', {
        'anonymize_ip': false,
    });
  </script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,300&display=swap" rel="stylesheet">
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">NVIDIA Merlin</p>
  
</a></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../README.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../guide/recommender_system_guide.html">Recommender System Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/recommender_models.html">Recommender Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples/index.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/getting-started-movielens/index.html">Getting Started using the MovieLens Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/01-Download-Convert.html">MovieLens Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-TF.html">Getting Started MovieLens: Training with TensorFlow</a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-PyTorch.html">Training with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/04-Triton-Inference-with-HugeCTR.html">Serving the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/04-Triton-Inference-with-TF.html">Serve Recommendations from the TensorFlow Model</a></li>

</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/index.html">Deploying a Multi-Stage Recommender System</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/01-Building-Recommender-Systems-with-Merlin.html">Building the Recommender System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/02-Deploying-multi-stage-RecSys-with-Merlin-Systems.html">Deploying the Recommender System with Triton</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/sagemaker-tensorflow/index.html">Merlin and AWS SageMaker</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/sagemaker-tensorflow/sagemaker-merlin-tensorflow.html">Training and Serving Merlin on AWS SageMaker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/scaling-criteo/index.html">Scaling Large Datasets with Criteo</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/01-Download-Convert.html">Criteo Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/03-Training-with-Merlin-Models-TensorFlow.html">Training with Merlin Models and TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/04-Triton-Inference-with-HugeCTR.html">Deploy the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/04-Triton-Inference-with-Merlin-Models-TensorFlow.html">Deploy the TensorFlow Model with Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../support_matrix/index.html">Merlin Support Matrix</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_hugectr.html">Merlin HugeCTR Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_tensorflow.html">Merlin TensorFlow Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_pytorch.html">Merlin PyTorch Support Matrix</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.dag.html">merlin.dag</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.BaseOperator.html">merlin.dag.BaseOperator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.Graph.html">merlin.dag.Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.Node.html">merlin.dag.Node</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.ColumnSelector.html">merlin.dag.ColumnSelector</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_dataloader.html">merlin.loader</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tensorflow.Loader.html">merlin.dataloader.tensorflow.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tensorflow.KerasSequenceValidater.html">merlin.dataloader.tensorflow.KerasSequenceValidater</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.configure_tensorflow.html">merlin.dataloader.tf_utils.configure_tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns.html">merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.HAS_GPU.html">merlin.dataloader.tf_utils.HAS_GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.torch.Loader.html">merlin.dataloader.torch.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.torch.DLDataLoader.html">merlin.dataloader.torch.DLDataLoader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.jax.Loader.html">merlin.dataloader.jax.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.loader_base.LoaderBase.html">merlin.dataloader.loader_base.LoaderBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.loader_base.ChunkQueue.html">merlin.dataloader.loader_base.ChunkQueue</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.io.html">merlin.io</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.io.Dataset.html">merlin.io.Dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_models.html">merlin.models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DCNModel.html">merlin.models.tf.DCNModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DeepFMModel.html">merlin.models.tf.DeepFMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DLRMModel.html">merlin.models.tf.DLRMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.WideAndDeepModel.html">merlin.models.tf.WideAndDeepModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Encoder.html">merlin.models.tf.Encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.EmbeddingEncoder.html">merlin.models.tf.EmbeddingEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemRetrievalScorer.html">merlin.models.tf.ItemRetrievalScorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RetrievalModelV2.html">merlin.models.tf.RetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationModelV2.html">merlin.models.tf.MatrixFactorizationModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationModel.html">merlin.models.tf.MatrixFactorizationModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerModelV2.html">merlin.models.tf.TwoTowerModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerModel.html">merlin.models.tf.TwoTowerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.YoutubeDNNRetrievalModelV2.html">merlin.models.tf.YoutubeDNNRetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.YoutubeDNNRetrievalModel.html">merlin.models.tf.YoutubeDNNRetrievalModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Embeddings.html">merlin.models.tf.Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.EmbeddingTable.html">merlin.models.tf.EmbeddingTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AverageEmbeddingsByWeightFeature.html">merlin.models.tf.AverageEmbeddingsByWeightFeature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ReplaceMaskedEmbeddings.html">merlin.models.tf.ReplaceMaskedEmbeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.L2Norm.html">merlin.models.tf.L2Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InputBlockV2.html">merlin.models.tf.InputBlockV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InputBlock.html">merlin.models.tf.InputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Continuous.html">merlin.models.tf.Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousFeatures.html">merlin.models.tf.ContinuousFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousEmbedding.html">merlin.models.tf.ContinuousEmbedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousProjection.html">merlin.models.tf.ContinuousProjection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceEmbeddingFeatures.html">merlin.models.tf.SequenceEmbeddingFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DLRMBlock.html">merlin.models.tf.DLRMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MLPBlock.html">merlin.models.tf.MLPBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CrossBlock.html">merlin.models.tf.CrossBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerBlock.html">merlin.models.tf.TwoTowerBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationBlock.html">merlin.models.tf.MatrixFactorizationBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DotProductInteraction.html">merlin.models.tf.DotProductInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.FMBlock.html">merlin.models.tf.FMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.FMPairwiseInteraction.html">merlin.models.tf.FMPairwiseInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PredictionTasks.html">merlin.models.tf.PredictionTasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PredictionTask.html">merlin.models.tf.PredictionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BinaryClassificationTask.html">merlin.models.tf.BinaryClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MultiClassClassificationTask.html">merlin.models.tf.MultiClassClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RegressionTask.html">merlin.models.tf.RegressionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemRetrievalTask.html">merlin.models.tf.ItemRetrievalTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.OutputBlock.html">merlin.models.tf.OutputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ModelOutput.html">merlin.models.tf.ModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BinaryOutput.html">merlin.models.tf.BinaryOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CategoricalOutput.html">merlin.models.tf.CategoricalOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContrastiveOutput.html">merlin.models.tf.ContrastiveOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RegressionOutput.html">merlin.models.tf.RegressionOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ColumnBasedSampleWeight.html">merlin.models.tf.ColumnBasedSampleWeight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequentialBlock.html">merlin.models.tf.SequentialBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ParallelBlock.html">merlin.models.tf.ParallelBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ParallelPredictionBlock.html">merlin.models.tf.ParallelPredictionBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DenseResidualBlock.html">merlin.models.tf.DenseResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DualEncoderBlock.html">merlin.models.tf.DualEncoderBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ResidualBlock.html">merlin.models.tf.ResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TabularBlock.html">merlin.models.tf.TabularBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Filter.html">merlin.models.tf.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Cond.html">merlin.models.tf.Cond</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TopKEncoder.html">merlin.models.tf.TopKEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MultiOptimizer.html">merlin.models.tf.MultiOptimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.LazyAdam.html">merlin.models.tf.LazyAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.OptimizerBlocks.html">merlin.models.tf.OptimizerBlocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.split_embeddings_on_size.html">merlin.models.tf.split_embeddings_on_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CategoryEncoding.html">merlin.models.tf.CategoryEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MapValues.html">merlin.models.tf.MapValues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PrepareFeatures.html">merlin.models.tf.PrepareFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToSparse.html">merlin.models.tf.ToSparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToDense.html">merlin.models.tf.ToDense</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToTarget.html">merlin.models.tf.ToTarget</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToOneHot.html">merlin.models.tf.ToOneHot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.HashedCross.html">merlin.models.tf.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.HashedCrossAll.html">merlin.models.tf.HashedCrossAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BroadcastToSequence.html">merlin.models.tf.BroadcastToSequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictNext.html">merlin.models.tf.SequencePredictNext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictLast.html">merlin.models.tf.SequencePredictLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictRandom.html">merlin.models.tf.SequencePredictRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceTargetAsInput.html">merlin.models.tf.SequenceTargetAsInput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceMaskLast.html">merlin.models.tf.SequenceMaskLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceMaskRandom.html">merlin.models.tf.SequenceMaskRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ExpandDims.html">merlin.models.tf.ExpandDims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.StochasticSwapNoise.html">merlin.models.tf.StochasticSwapNoise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AsTabular.html">merlin.models.tf.AsTabular</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MMOEBlock.html">merlin.models.tf.MMOEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CGCBlock.html">merlin.models.tf.CGCBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PLEBlock.html">merlin.models.tf.PLEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Loader.html">merlin.models.tf.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AvgPrecisionAt.html">merlin.models.tf.AvgPrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MRRAt.html">merlin.models.tf.MRRAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.NDCGAt.html">merlin.models.tf.NDCGAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PrecisionAt.html">merlin.models.tf.PrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RecallAt.html">merlin.models.tf.RecallAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TopKMetricsAggregator.html">merlin.models.tf.TopKMetricsAggregator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemSampler.html">merlin.models.tf.ItemSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InBatchSampler.html">merlin.models.tf.InBatchSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PopularityBasedSampler.html">merlin.models.tf.PopularityBasedSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.CategoricalCrossEntropy.html">merlin.models.tf.losses.CategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.SparseCategoricalCrossEntropy.html">merlin.models.tf.losses.SparseCategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.BPRLoss.html">merlin.models.tf.losses.BPRLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.BPRmaxLoss.html">merlin.models.tf.losses.BPRmaxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.HingeLoss.html">merlin.models.tf.losses.HingeLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.LogisticLoss.html">merlin.models.tf.losses.LogisticLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1Loss.html">merlin.models.tf.losses.TOP1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1maxLoss.html">merlin.models.tf.losses.TOP1maxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1v2Loss.html">merlin.models.tf.losses.TOP1v2Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.select_targets.html">merlin.models.utils.schema_utils.select_targets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json.html">merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema.html">merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.create_categorical_column.html">merlin.models.utils.schema_utils.create_categorical_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.create_continuous_column.html">merlin.models.utils.schema_utils.create_continuous_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.filter_dict_by_schema.html">merlin.models.utils.schema_utils.filter_dict_by_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.categorical_cardinalities.html">merlin.models.utils.schema_utils.categorical_cardinalities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.categorical_domains.html">merlin.models.utils.schema_utils.categorical_domains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.get_embedding_sizes_from_schema.html">merlin.models.utils.schema_utils.get_embedding_sizes_from_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.get_embedding_size_from_cardinality.html">merlin.models.utils.schema_utils.get_embedding_size_from_cardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TensorInitializer.html">merlin.models.tf.TensorInitializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.filter_kwargs.html">merlin.models.utils.misc_utils.filter_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.safe_json.html">merlin.models.utils.misc_utils.safe_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_filenames.html">merlin.models.utils.misc_utils.get_filenames</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_label_feature_name.html">merlin.models.utils.misc_utils.get_label_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_timestamp_feature_name.html">merlin.models.utils.misc_utils.get_timestamp_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_parquet_files_names.html">merlin.models.utils.misc_utils.get_parquet_files_names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.Timing.html">merlin.models.utils.misc_utils.Timing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_object_size.html">merlin.models.utils.misc_utils.get_object_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.validate_dataset.html">merlin.models.utils.misc_utils.validate_dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.camelcase_to_snakecase.html">merlin.models.utils.registry.camelcase_to_snakecase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.snakecase_to_camelcase.html">merlin.models.utils.registry.snakecase_to_camelcase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.default_name.html">merlin.models.utils.registry.default_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.default_object_name.html">merlin.models.utils.registry.default_object_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.Registry.html">merlin.models.utils.registry.Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.RegistryMixin.html">merlin.models.utils.registry.RegistryMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.display_list_by_prefix.html">merlin.models.utils.registry.display_list_by_prefix</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.schema.html">merlin.schema</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.Schema.html">merlin.schema.Schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.ColumnSchema.html">merlin.schema.ColumnSchema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.Tags.html">merlin.schema.Tags</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_systems.html">merlin.systems</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.Ensemble.html">merlin.systems.dag.Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.workflow.TransformWorkflow.html">merlin.systems.dag.ops.workflow.TransformWorkflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.tensorflow.PredictTensorflow.html">merlin.systems.dag.ops.tensorflow.PredictTensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.fil.PredictForest.html">merlin.systems.dag.ops.fil.PredictForest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.implicit.PredictImplicit.html">merlin.systems.dag.ops.implicit.PredictImplicit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling.html">merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.session_filter.FilterCandidates.html">merlin.systems.dag.ops.session_filter.FilterCandidates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.unroll_features.UnrollFeatures.html">merlin.systems.dag.ops.unroll_features.UnrollFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.triton.convert_df_to_triton_input.html">merlin.systems.triton.convert_df_to_triton_input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.triton.convert_triton_output_to_df.html">merlin.systems.triton.convert_triton_output_to_df</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_nvtabular.html">nvtabular</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.workflow.workflow.Workflow.html">nvtabular.workflow.workflow.Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.workflow.workflow.WorkflowNode.html">nvtabular.workflow.workflow.WorkflowNode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Bucketize.html">nvtabular.ops.Bucketize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Categorify.html">nvtabular.ops.Categorify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.DropLowCardinality.html">nvtabular.ops.DropLowCardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.HashBucket.html">nvtabular.ops.HashBucket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.HashedCross.html">nvtabular.ops.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TargetEncoding.html">nvtabular.ops.TargetEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Clip.html">nvtabular.ops.Clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.LogOp.html">nvtabular.ops.LogOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Normalize.html">nvtabular.ops.Normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.NormalizeMinMax.html">nvtabular.ops.NormalizeMinMax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Dropna.html">nvtabular.ops.Dropna</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.FillMissing.html">nvtabular.ops.FillMissing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.FillMedian.html">nvtabular.ops.FillMedian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.DifferenceLag.html">nvtabular.ops.DifferenceLag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Filter.html">nvtabular.ops.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Groupby.html">nvtabular.ops.Groupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.JoinExternal.html">nvtabular.ops.JoinExternal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.JoinGroupby.html">nvtabular.ops.JoinGroupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddMetadata.html">nvtabular.ops.AddMetadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddProperties.html">nvtabular.ops.AddProperties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddTags.html">nvtabular.ops.AddTags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Rename.html">nvtabular.ops.Rename</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ReduceDtypeSize.html">nvtabular.ops.ReduceDtypeSize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsItemFeatures.html">nvtabular.ops.TagAsItemFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsItemID.html">nvtabular.ops.TagAsItemID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsUserFeatures.html">nvtabular.ops.TagAsUserFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsUserID.html">nvtabular.ops.TagAsUserID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ListSlice.html">nvtabular.ops.ListSlice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ValueCount.html">nvtabular.ops.ValueCount</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ColumnSimilarity.html">nvtabular.ops.ColumnSimilarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.LambdaOp.html">nvtabular.ops.LambdaOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Operator.html">nvtabular.ops.Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.StatOperator.html">nvtabular.ops.StatOperator</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_transformers4rec/modules.html">transformers4rec</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.html">transformers4rec package</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.config.html">transformers4rec.config package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.html">transformers4rec.torch package</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.block.html">transformers4rec.torch.block package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.features.html">transformers4rec.torch.features package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.model.html">transformers4rec.torch.model package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.tabular.html">transformers4rec.torch.tabular package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.utils.html">transformers4rec.torch.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.utils.html">transformers4rec.utils package</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.html">merlin_standard_lib package</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.proto.html">merlin_standard_lib.proto package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.schema.html">merlin_standard_lib.schema package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.utils.html">merlin_standard_lib.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-merlin-ecosystem-nav" aria-label="Merlin Ecosystem Nav">
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul class="nav bd-sidenav">
      <li class="toctree-l1"><a class="reference external" href="/core/">Core</a></li>
      <li class="toctree-l1"><a class="reference external" href="/models/">Models</a></li>
      <li class="toctree-l1"><a class="reference external" href="/systems/">Systems</a></li>
      <li class="toctree-l1"><a class="reference external" href="/NVTabular/">NVTabular</a></li>
      <li class="toctree-l1"><a class="reference external" href="/Transformers4Rec/">Transformers4Rec</a></li>
      <li class="toctree-l1"><a class="reference external" href="/dataloader/">Dataloader</a></li>
      <li class="toctree-l1"><a class="reference external" href="/HugetCTR/">HugeCTR</a></li>
    </ul>
  </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for transformers4rec.config.transformer</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright (c) 2021, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">merlin.models.utils.doc_utils</span> <span class="kn">import</span> <span class="n">docstring_parameter</span>
<span class="kn">from</span> <span class="nn">merlin.models.utils.registry</span> <span class="kn">import</span> <span class="n">Registry</span>

<span class="n">transformer_registry</span><span class="p">:</span> <span class="n">Registry</span> <span class="o">=</span> <span class="n">Registry</span><span class="p">(</span><span class="s2">&quot;transformers&quot;</span><span class="p">)</span>


<span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;        </span>
<span class="s2">        d_model: int</span>
<span class="s2">            The  hidden dimension of the transformer layer.</span>
<span class="s2">        n_head: int</span>
<span class="s2">            The number of attention heads in each transformer layer.</span>
<span class="s2">        n_layer: int</span>
<span class="s2">            The number of transformer layers to stack.</span>
<span class="s2">        total_seq_length: int</span>
<span class="s2">            The maximum sequence length.</span>
<span class="s2">        hidden_act: str, optional</span>
<span class="s2">            The activation function in the hidden layers.</span>
<span class="s2">            By default &#39;gelu&#39;</span>
<span class="s2">        initializer_range: float, optional</span>
<span class="s2">            The standard deviation of the `truncated_normal_initializer`</span>
<span class="s2">            for initializing all transformer&#39;s weights parameters.</span>
<span class="s2">            By default 0.01</span>
<span class="s2">        layer_norm_eps: float, optional</span>
<span class="s2">            The epsilon used by the layer normalization layers.</span>
<span class="s2">            By default 0.03</span>
<span class="s2">        dropout: float, optional</span>
<span class="s2">            The dropout probability. By default 0.3</span>
<span class="s2">        pad_token: int, optional</span>
<span class="s2">            The padding token ID. By default 0</span>
<span class="s2">        log_attention_weights: bool, optional</span>
<span class="s2">            Whether to log attention weights. By default False</span>
<span class="s2">&quot;&quot;&quot;</span>


<div class="viewcode-block" id="T4RecConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.T4RecConfig">[docs]</a><span class="k">class</span> <span class="nc">T4RecConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A class responsible for setting the configuration of the transformers class</span>
<span class="sd">    from Hugging Face and returning the corresponding T4Rec model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="T4RecConfig.to_huggingface_torch_model"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.T4RecConfig.to_huggingface_torch_model">[docs]</a>    <span class="k">def</span> <span class="nf">to_huggingface_torch_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a Hugging Face transformer model based on</span>
<span class="sd">        the configuration parameters of the class.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transformers.PreTrainedModel</span>
<span class="sd">            The Hugging Face transformer model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_cls</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">MODEL_MAPPING</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">transformers_config_cls</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">model_cls</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="T4RecConfig.to_torch_model"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.T4RecConfig.to_torch_model">[docs]</a>    <span class="k">def</span> <span class="nf">to_torch_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_features</span><span class="p">,</span>
        <span class="o">*</span><span class="n">prediction_task</span><span class="p">,</span>
        <span class="n">task_blocks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">task_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">loss_reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Links the Hugging Face transformer model to the given input block and prediction tasks,</span>
<span class="sd">        and returns a T4Rec model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_features: torch4rec.TabularSequenceFeatures</span>
<span class="sd">            The sequential block that represents the input features and</span>
<span class="sd">            defines the masking strategy for training and evaluation.</span>
<span class="sd">        prediction_task: torch4rec.PredictionTask</span>
<span class="sd">            One or multiple prediction tasks.</span>
<span class="sd">        task_blocks: list, optional</span>
<span class="sd">            List of task-specific blocks that we apply on top of the HF transformer&#39;s output.</span>
<span class="sd">        task_weights: list, optional</span>
<span class="sd">            List of the weights to use for combining the tasks losses.</span>
<span class="sd">        loss_reduction: str, optional</span>
<span class="sd">            The reduction to apply to the prediction losses, possible values are:</span>
<span class="sd">                &#39;none&#39;: no reduction will be applied,</span>
<span class="sd">                &#39;mean&#39;: the weighted mean of the output is taken,</span>
<span class="sd">                &#39;sum&#39;: the output will be summed.</span>
<span class="sd">            By default: &#39;mean&#39;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch4rec.Model</span>
<span class="sd">            The T4Rec torch model.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If input block or prediction task is of the wrong type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">torch4rec</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="n">torch4rec</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`input_features` must an instance of SequentialTabularFeatures&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">torch4rec</span><span class="o">.</span><span class="n">PredictionTask</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">prediction_task</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`task` is of the wrong type, please provide one or multiple &quot;</span>
                <span class="s2">&quot;instance(s) of PredictionTask&quot;</span>
            <span class="p">)</span>

        <span class="n">body</span> <span class="o">=</span> <span class="n">torch4rec</span><span class="o">.</span><span class="n">SequentialBlock</span><span class="p">(</span>
            <span class="n">input_features</span><span class="p">,</span> <span class="n">torch4rec</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">input_features</span><span class="o">.</span><span class="n">masking</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">torch4rec</span><span class="o">.</span><span class="n">Head</span><span class="p">(</span>
            <span class="n">body</span><span class="p">,</span>
            <span class="o">*</span><span class="n">prediction_task</span><span class="p">,</span>
            <span class="n">task_blocks</span><span class="o">=</span><span class="n">task_blocks</span><span class="p">,</span>
            <span class="n">task_weights</span><span class="o">=</span><span class="n">task_weights</span><span class="p">,</span>
            <span class="n">loss_reduction</span><span class="o">=</span><span class="n">loss_reduction</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to_model</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">transformers_config_cls</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__bases__</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<div class="viewcode-block" id="T4RecConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.T4RecConfig.build">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>


<div class="viewcode-block" id="ReformerConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.ReformerConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;reformer&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ReformerConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ReformerConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.ReformerConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for Reformer layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ReformerConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.ReformerConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">axial_pos_shape_first_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of ReformerConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>
<span class="sd">        axial_pos_shape_first_dim: int, optional</span>
<span class="sd">            The first dimension of the axial position encodings.</span>
<span class="sd">            During training, the product of the position dims has to be equal to the sequence length.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ReformerConfig</span>
<span class="sd">            An instance of ReformerConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># To account for target positions at inference mode, we extend the maximum sequence length.</span>
        <span class="n">total_seq_length</span> <span class="o">=</span> <span class="n">total_seq_length</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">attention_head_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">attn_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="s2">&quot;lsh&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_layer</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_layer</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;local&quot;</span><span class="p">],</span>
            <span class="n">num_hidden_layers</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">feed_forward_size</span><span class="o">=</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">num_attention_heads</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">hidden_act</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">lsh_attention_probs_dropout_prob</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">max_position_embeddings</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">axial_pos_embds_dim</span><span class="o">=</span><span class="p">[</span>
                <span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                <span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="n">axial_pos_shape</span><span class="o">=</span><span class="p">[</span>
                <span class="n">axial_pos_shape_first_dim</span><span class="p">,</span>
                <span class="n">total_seq_length</span> <span class="o">//</span> <span class="n">axial_pos_shape_first_dim</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="GPT2Config"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.GPT2Config">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;gtp2&quot;</span><span class="p">)</span>
<span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">GPT2Config</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">GPT2Config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.GPT2Config from Hugging Face.</span>
<span class="sd">    It handles configuration for GPT2 layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GPT2Config.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.GPT2Config.build">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of GPT2Config with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        GPT2Config</span>
<span class="sd">            An instance of GPT2Config.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">n_embd</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">n_inner</span><span class="o">=</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">activation_function</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">resid_pdrop</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">embd_pdrop</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">attn_pdrop</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">n_positions</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">n_ctx</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="LongformerConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.LongformerConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;longformer&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LongformerConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">LongformerConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.LongformerConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for LongformerConfig layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LongformerConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.LongformerConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of LongformerConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        LongformerConfig</span>
<span class="sd">            An instance of LongformerConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># To account for target positions at inference mode, we extend the maximum sequence length.</span>
        <span class="n">total_seq_length</span> <span class="o">=</span> <span class="n">total_seq_length</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">num_hidden_layers</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">num_attention_heads</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">hidden_act</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">attention_window</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="ElectraConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.ElectraConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;electra&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ElectraConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ElectraConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.ElectraConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for ElectraConfig layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ElectraConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.ElectraConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of ElectraConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ElectraConfig</span>
<span class="sd">            An instance of ElectraConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># To account for target positions at inference mode, we extend the maximum sequence length.</span>
        <span class="n">total_seq_length</span> <span class="o">=</span> <span class="n">total_seq_length</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">embedding_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">num_hidden_layers</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">num_attention_heads</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">intermediate_size</span><span class="o">=</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">hidden_act</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">max_position_embeddings</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="AlbertConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.AlbertConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;albert&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">AlbertConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AlbertConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.AlbertConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for AlbertConfig layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AlbertConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.AlbertConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of AlbertConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        AlbertConfig</span>
<span class="sd">            An instance of AlbertConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># To account for target positions at inference mode, we extend the maximum sequence length.</span>
        <span class="n">total_seq_length</span> <span class="o">=</span> <span class="n">total_seq_length</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">num_attention_heads</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">num_hidden_layers</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">hidden_act</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">intermediate_size</span><span class="o">=</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">max_position_embeddings</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">embedding_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>  <span class="c1"># should be same as dimension of the input to ALBERT</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="XLNetConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.XLNetConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;xlnet&quot;</span><span class="p">)</span>
<span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">XLNetConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.XLNetConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for XLNetConfig layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="XLNetConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.XLNetConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">attn_type</span><span class="o">=</span><span class="s2">&quot;bi&quot;</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">mem_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of XLNetConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>
<span class="sd">        mem_len: int,</span>
<span class="sd">            The number of tokens to be cached. Pre-computed key/value pairs</span>
<span class="sd">            from a previous forward pass are stored and won&#39;t be re-computed.</span>
<span class="sd">            This parameter is especially useful for long sequence modeling where</span>
<span class="sd">            different batches may truncate the entire sequence.</span>
<span class="sd">            Tasks like user-aware recommendation could benefit from this feature.</span>
<span class="sd">            By default, this parameter is set to 1, which means no caching is used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        XLNetConfig</span>
<span class="sd">            An instance of XLNetConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">d_inner</span><span class="o">=</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">attn_type</span><span class="o">=</span><span class="n">attn_type</span><span class="p">,</span>
            <span class="n">ff_activation</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">mem_len</span><span class="o">=</span><span class="n">mem_len</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="BertConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.config.html#transformers4rec.config.transformer.BertConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;bert&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">BertConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">BertConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.BertConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for BertConfig layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BertConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.config.html#transformers4rec.config.transformer.BertConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of BertConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        BertConfig</span>
<span class="sd">            An instance of BertConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># To account for target positions at inference mode, we extend the maximum sequence length.</span>
        <span class="n">total_seq_length</span> <span class="o">=</span> <span class="n">total_seq_length</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">num_hidden_layers</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">num_attention_heads</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">hidden_act</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">max_position_embeddings</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="RobertaConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.config.html#transformers4rec.config.transformer.RobertaConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;roberta&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RobertaConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">RobertaConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers.RobertaConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for RobertaConfig layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RobertaConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.config.html#transformers4rec.config.transformer.RobertaConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of RobertaConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        RobertaConfig</span>
<span class="sd">            An instance of RobertaConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># To account for target positions at inference mode, we extend the maximum sequence length.</span>
        <span class="n">total_seq_length</span> <span class="o">=</span> <span class="n">total_seq_length</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">num_hidden_layers</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">num_attention_heads</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">hidden_act</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">max_position_embeddings</span><span class="o">=</span><span class="n">total_seq_length</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="TransfoXLConfig"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.TransfoXLConfig">[docs]</a><span class="nd">@transformer_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;transfo-xl&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TransfoXLConfig</span><span class="p">(</span><span class="n">T4RecConfig</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TransfoXLConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass of T4RecConfig and transformers. TransfoXLConfig from Hugging Face.</span>
<span class="sd">    It handles configuration for TransfoXLConfig layers in the context of T4Rec models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransfoXLConfig.build"><a class="viewcode-back" href="../../../api_transformers4rec/transformers4rec.torch.html#transformers4rec.config.transformer.TransfoXLConfig.build">[docs]</a>    <span class="nd">@docstring_parameter</span><span class="p">(</span><span class="n">transformer_cfg_parameters</span><span class="o">=</span><span class="n">TRANSFORMER_CONFIG_PARAMETER_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">n_head</span><span class="p">,</span>
        <span class="n">n_layer</span><span class="p">,</span>
        <span class="n">total_seq_length</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">log_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an instance of TransfoXLConfig with the given parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        {transformer_cfg_parameters}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        TransfoXLConfig</span>
<span class="sd">            An instance of TransfoXLConfig.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">d_embed</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
            <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span>
            <span class="n">d_inner</span><span class="o">=</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">hidden_act</span><span class="o">=</span><span class="n">hidden_act</span><span class="p">,</span>
            <span class="n">untie_r</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">attn_type</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">initializer_range</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">,</span>
            <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">log_attention_weights</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># As the input_embeds will be fed in the forward function, limits the memory reserved by the internal input embedding table, which will not be used</span>
            <span class="n">mem_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># We do not use mems, because we feed the full sequence to the Transformer models and not sliding segments (which is useful for the long sequences in NLP. As setting mem_len to 0 leads to NaN in loss, we set it to one, to minimize the computing overhead)</span>
            <span class="n">div_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># Disables adaptative input (embeddings), because the embeddings are managed by TabularFeatures</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div></div>
</pre></div>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 2023, NVIDIA.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>