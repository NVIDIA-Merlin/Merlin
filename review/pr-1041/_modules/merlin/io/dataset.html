

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>merlin.io.dataset &#8212; NVIDIA Merlin</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/versions.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/js/rtd-version-switcher.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/merlin/io/dataset';</script>
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/_modules/merlin/io/dataset.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVJ1Y1YJHK', {
        'anonymize_ip': false,
    });
  </script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,300&display=swap" rel="stylesheet">
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">NVIDIA Merlin</p>
  
</a></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../README.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../guide/recommender_system_guide.html">Recommender System Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/recommender_models.html">Recommender Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples/index.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/getting-started-movielens/index.html">Getting Started using the MovieLens Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/01-Download-Convert.html">MovieLens Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-TF.html">Getting Started MovieLens: Training with TensorFlow</a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/03-Training-with-PyTorch.html">Training with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/04-Triton-Inference-with-HugeCTR.html">Serving the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/getting-started-movielens/04-Triton-Inference-with-TF.html">Serve Recommendations from the TensorFlow Model</a></li>

</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/index.html">Deploying a Multi-Stage Recommender System</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/01-Building-Recommender-Systems-with-Merlin.html">Building the Recommender System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Building-and-deploying-multi-stage-RecSys/02-Deploying-multi-stage-RecSys-with-Merlin-Systems.html">Deploying the Recommender System with Triton</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/sagemaker-tensorflow/index.html">Merlin and AWS SageMaker</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/sagemaker-tensorflow/sagemaker-merlin-tensorflow.html">Training and Serving Merlin on AWS SageMaker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../examples/scaling-criteo/index.html">Scaling Large Datasets with Criteo</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/01-Download-Convert.html">Criteo Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/03-Training-with-Merlin-Models-TensorFlow.html">Training with Merlin Models and TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/04-Triton-Inference-with-HugeCTR.html">Deploy the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/scaling-criteo/04-Triton-Inference-with-Merlin-Models-TensorFlow.html">Deploy the TensorFlow Model with Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../support_matrix/index.html">Merlin Support Matrix</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_hugectr.html">Merlin HugeCTR Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_tensorflow.html">Merlin TensorFlow Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_pytorch.html">Merlin PyTorch Support Matrix</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.dag.html">merlin.dag</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.BaseOperator.html">merlin.dag.BaseOperator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.Graph.html">merlin.dag.Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.Node.html">merlin.dag.Node</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.dag.ColumnSelector.html">merlin.dag.ColumnSelector</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_dataloader.html">merlin.loader</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tensorflow.Loader.html">merlin.dataloader.tensorflow.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tensorflow.KerasSequenceValidater.html">merlin.dataloader.tensorflow.KerasSequenceValidater</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.configure_tensorflow.html">merlin.dataloader.tf_utils.configure_tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns.html">merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.tf_utils.HAS_GPU.html">merlin.dataloader.tf_utils.HAS_GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.torch.Loader.html">merlin.dataloader.torch.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.torch.DLDataLoader.html">merlin.dataloader.torch.DLDataLoader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.jax.Loader.html">merlin.dataloader.jax.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.loader_base.LoaderBase.html">merlin.dataloader.loader_base.LoaderBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.dataloader.loader_base.ChunkQueue.html">merlin.dataloader.loader_base.ChunkQueue</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.io.html">merlin.io</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.io.Dataset.html">merlin.io.Dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_models.html">merlin.models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DCNModel.html">merlin.models.tf.DCNModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DeepFMModel.html">merlin.models.tf.DeepFMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DLRMModel.html">merlin.models.tf.DLRMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.WideAndDeepModel.html">merlin.models.tf.WideAndDeepModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Encoder.html">merlin.models.tf.Encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.EmbeddingEncoder.html">merlin.models.tf.EmbeddingEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemRetrievalScorer.html">merlin.models.tf.ItemRetrievalScorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RetrievalModelV2.html">merlin.models.tf.RetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationModelV2.html">merlin.models.tf.MatrixFactorizationModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationModel.html">merlin.models.tf.MatrixFactorizationModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerModelV2.html">merlin.models.tf.TwoTowerModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerModel.html">merlin.models.tf.TwoTowerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.YoutubeDNNRetrievalModelV2.html">merlin.models.tf.YoutubeDNNRetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.YoutubeDNNRetrievalModel.html">merlin.models.tf.YoutubeDNNRetrievalModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Embeddings.html">merlin.models.tf.Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.EmbeddingTable.html">merlin.models.tf.EmbeddingTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AverageEmbeddingsByWeightFeature.html">merlin.models.tf.AverageEmbeddingsByWeightFeature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ReplaceMaskedEmbeddings.html">merlin.models.tf.ReplaceMaskedEmbeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.L2Norm.html">merlin.models.tf.L2Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InputBlockV2.html">merlin.models.tf.InputBlockV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InputBlock.html">merlin.models.tf.InputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Continuous.html">merlin.models.tf.Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousFeatures.html">merlin.models.tf.ContinuousFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousEmbedding.html">merlin.models.tf.ContinuousEmbedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContinuousProjection.html">merlin.models.tf.ContinuousProjection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceEmbeddingFeatures.html">merlin.models.tf.SequenceEmbeddingFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DLRMBlock.html">merlin.models.tf.DLRMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MLPBlock.html">merlin.models.tf.MLPBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CrossBlock.html">merlin.models.tf.CrossBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TwoTowerBlock.html">merlin.models.tf.TwoTowerBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MatrixFactorizationBlock.html">merlin.models.tf.MatrixFactorizationBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DotProductInteraction.html">merlin.models.tf.DotProductInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.FMBlock.html">merlin.models.tf.FMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.FMPairwiseInteraction.html">merlin.models.tf.FMPairwiseInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PredictionTasks.html">merlin.models.tf.PredictionTasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PredictionTask.html">merlin.models.tf.PredictionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BinaryClassificationTask.html">merlin.models.tf.BinaryClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MultiClassClassificationTask.html">merlin.models.tf.MultiClassClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RegressionTask.html">merlin.models.tf.RegressionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemRetrievalTask.html">merlin.models.tf.ItemRetrievalTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.OutputBlock.html">merlin.models.tf.OutputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ModelOutput.html">merlin.models.tf.ModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BinaryOutput.html">merlin.models.tf.BinaryOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CategoricalOutput.html">merlin.models.tf.CategoricalOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ContrastiveOutput.html">merlin.models.tf.ContrastiveOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RegressionOutput.html">merlin.models.tf.RegressionOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ColumnBasedSampleWeight.html">merlin.models.tf.ColumnBasedSampleWeight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequentialBlock.html">merlin.models.tf.SequentialBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ParallelBlock.html">merlin.models.tf.ParallelBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ParallelPredictionBlock.html">merlin.models.tf.ParallelPredictionBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DenseResidualBlock.html">merlin.models.tf.DenseResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.DualEncoderBlock.html">merlin.models.tf.DualEncoderBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ResidualBlock.html">merlin.models.tf.ResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TabularBlock.html">merlin.models.tf.TabularBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Filter.html">merlin.models.tf.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Cond.html">merlin.models.tf.Cond</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TopKEncoder.html">merlin.models.tf.TopKEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MultiOptimizer.html">merlin.models.tf.MultiOptimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.LazyAdam.html">merlin.models.tf.LazyAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.OptimizerBlocks.html">merlin.models.tf.OptimizerBlocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.split_embeddings_on_size.html">merlin.models.tf.split_embeddings_on_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CategoryEncoding.html">merlin.models.tf.CategoryEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MapValues.html">merlin.models.tf.MapValues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PrepareFeatures.html">merlin.models.tf.PrepareFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToSparse.html">merlin.models.tf.ToSparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToDense.html">merlin.models.tf.ToDense</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToTarget.html">merlin.models.tf.ToTarget</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ToOneHot.html">merlin.models.tf.ToOneHot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.HashedCross.html">merlin.models.tf.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.HashedCrossAll.html">merlin.models.tf.HashedCrossAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.BroadcastToSequence.html">merlin.models.tf.BroadcastToSequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictNext.html">merlin.models.tf.SequencePredictNext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictLast.html">merlin.models.tf.SequencePredictLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequencePredictRandom.html">merlin.models.tf.SequencePredictRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceTargetAsInput.html">merlin.models.tf.SequenceTargetAsInput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceMaskLast.html">merlin.models.tf.SequenceMaskLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.SequenceMaskRandom.html">merlin.models.tf.SequenceMaskRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ExpandDims.html">merlin.models.tf.ExpandDims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.StochasticSwapNoise.html">merlin.models.tf.StochasticSwapNoise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AsTabular.html">merlin.models.tf.AsTabular</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MMOEBlock.html">merlin.models.tf.MMOEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.CGCBlock.html">merlin.models.tf.CGCBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PLEBlock.html">merlin.models.tf.PLEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.Loader.html">merlin.models.tf.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.AvgPrecisionAt.html">merlin.models.tf.AvgPrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.MRRAt.html">merlin.models.tf.MRRAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.NDCGAt.html">merlin.models.tf.NDCGAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PrecisionAt.html">merlin.models.tf.PrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.RecallAt.html">merlin.models.tf.RecallAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TopKMetricsAggregator.html">merlin.models.tf.TopKMetricsAggregator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.ItemSampler.html">merlin.models.tf.ItemSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.InBatchSampler.html">merlin.models.tf.InBatchSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.PopularityBasedSampler.html">merlin.models.tf.PopularityBasedSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.CategoricalCrossEntropy.html">merlin.models.tf.losses.CategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.SparseCategoricalCrossEntropy.html">merlin.models.tf.losses.SparseCategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.BPRLoss.html">merlin.models.tf.losses.BPRLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.BPRmaxLoss.html">merlin.models.tf.losses.BPRmaxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.HingeLoss.html">merlin.models.tf.losses.HingeLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.LogisticLoss.html">merlin.models.tf.losses.LogisticLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1Loss.html">merlin.models.tf.losses.TOP1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1maxLoss.html">merlin.models.tf.losses.TOP1maxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.losses.TOP1v2Loss.html">merlin.models.tf.losses.TOP1v2Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.select_targets.html">merlin.models.utils.schema_utils.select_targets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json.html">merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema.html">merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.create_categorical_column.html">merlin.models.utils.schema_utils.create_categorical_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.create_continuous_column.html">merlin.models.utils.schema_utils.create_continuous_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.filter_dict_by_schema.html">merlin.models.utils.schema_utils.filter_dict_by_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.categorical_cardinalities.html">merlin.models.utils.schema_utils.categorical_cardinalities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.categorical_domains.html">merlin.models.utils.schema_utils.categorical_domains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.get_embedding_sizes_from_schema.html">merlin.models.utils.schema_utils.get_embedding_sizes_from_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.schema_utils.get_embedding_size_from_cardinality.html">merlin.models.utils.schema_utils.get_embedding_size_from_cardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.tf.TensorInitializer.html">merlin.models.tf.TensorInitializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.filter_kwargs.html">merlin.models.utils.misc_utils.filter_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.safe_json.html">merlin.models.utils.misc_utils.safe_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_filenames.html">merlin.models.utils.misc_utils.get_filenames</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_label_feature_name.html">merlin.models.utils.misc_utils.get_label_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_timestamp_feature_name.html">merlin.models.utils.misc_utils.get_timestamp_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_parquet_files_names.html">merlin.models.utils.misc_utils.get_parquet_files_names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.Timing.html">merlin.models.utils.misc_utils.Timing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.get_object_size.html">merlin.models.utils.misc_utils.get_object_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.misc_utils.validate_dataset.html">merlin.models.utils.misc_utils.validate_dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.camelcase_to_snakecase.html">merlin.models.utils.registry.camelcase_to_snakecase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.snakecase_to_camelcase.html">merlin.models.utils.registry.snakecase_to_camelcase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.default_name.html">merlin.models.utils.registry.default_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.default_object_name.html">merlin.models.utils.registry.default_object_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.Registry.html">merlin.models.utils.registry.Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.RegistryMixin.html">merlin.models.utils.registry.RegistryMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.models.utils.registry.display_list_by_prefix.html">merlin.models.utils.registry.display_list_by_prefix</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_core/merlin.schema.html">merlin.schema</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.Schema.html">merlin.schema.Schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.ColumnSchema.html">merlin.schema.ColumnSchema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_core/generated/merlin.schema.Tags.html">merlin.schema.Tags</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_systems.html">merlin.systems</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.Ensemble.html">merlin.systems.dag.Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.workflow.TransformWorkflow.html">merlin.systems.dag.ops.workflow.TransformWorkflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.tensorflow.PredictTensorflow.html">merlin.systems.dag.ops.tensorflow.PredictTensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.fil.PredictForest.html">merlin.systems.dag.ops.fil.PredictForest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.implicit.PredictImplicit.html">merlin.systems.dag.ops.implicit.PredictImplicit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling.html">merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.session_filter.FilterCandidates.html">merlin.systems.dag.ops.session_filter.FilterCandidates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.dag.ops.unroll_features.UnrollFeatures.html">merlin.systems.dag.ops.unroll_features.UnrollFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.triton.convert_df_to_triton_input.html">merlin.systems.triton.convert_df_to_triton_input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/merlin.systems.triton.convert_triton_output_to_df.html">merlin.systems.triton.convert_triton_output_to_df</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_nvtabular.html">nvtabular</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.workflow.workflow.Workflow.html">nvtabular.workflow.workflow.Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.workflow.workflow.WorkflowNode.html">nvtabular.workflow.workflow.WorkflowNode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Bucketize.html">nvtabular.ops.Bucketize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Categorify.html">nvtabular.ops.Categorify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.DropLowCardinality.html">nvtabular.ops.DropLowCardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.HashBucket.html">nvtabular.ops.HashBucket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.HashedCross.html">nvtabular.ops.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TargetEncoding.html">nvtabular.ops.TargetEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Clip.html">nvtabular.ops.Clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.LogOp.html">nvtabular.ops.LogOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Normalize.html">nvtabular.ops.Normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.NormalizeMinMax.html">nvtabular.ops.NormalizeMinMax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Dropna.html">nvtabular.ops.Dropna</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.FillMissing.html">nvtabular.ops.FillMissing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.FillMedian.html">nvtabular.ops.FillMedian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.DifferenceLag.html">nvtabular.ops.DifferenceLag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Filter.html">nvtabular.ops.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Groupby.html">nvtabular.ops.Groupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.JoinExternal.html">nvtabular.ops.JoinExternal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.JoinGroupby.html">nvtabular.ops.JoinGroupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddMetadata.html">nvtabular.ops.AddMetadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddProperties.html">nvtabular.ops.AddProperties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.AddTags.html">nvtabular.ops.AddTags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Rename.html">nvtabular.ops.Rename</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ReduceDtypeSize.html">nvtabular.ops.ReduceDtypeSize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsItemFeatures.html">nvtabular.ops.TagAsItemFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsItemID.html">nvtabular.ops.TagAsItemID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsUserFeatures.html">nvtabular.ops.TagAsUserFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.TagAsUserID.html">nvtabular.ops.TagAsUserID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ListSlice.html">nvtabular.ops.ListSlice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ValueCount.html">nvtabular.ops.ValueCount</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.ColumnSimilarity.html">nvtabular.ops.ColumnSimilarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.LambdaOp.html">nvtabular.ops.LambdaOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.Operator.html">nvtabular.ops.Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/nvtabular.ops.StatOperator.html">nvtabular.ops.StatOperator</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_transformers4rec/modules.html">transformers4rec</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.html">transformers4rec package</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.config.html">transformers4rec.config package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.html">transformers4rec.torch package</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.block.html">transformers4rec.torch.block package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.features.html">transformers4rec.torch.features package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.model.html">transformers4rec.torch.model package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.tabular.html">transformers4rec.torch.tabular package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.torch.utils.html">transformers4rec.torch.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/transformers4rec.utils.html">transformers4rec.utils package</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.html">merlin_standard_lib package</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.proto.html">merlin_standard_lib.proto package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.schema.html">merlin_standard_lib.schema package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_transformers4rec/merlin_standard_lib.utils.html">merlin_standard_lib.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-merlin-ecosystem-nav" aria-label="Merlin Ecosystem Nav">
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul class="nav bd-sidenav">
      <li class="toctree-l1"><a class="reference external" href="/core/">Core</a></li>
      <li class="toctree-l1"><a class="reference external" href="/models/">Models</a></li>
      <li class="toctree-l1"><a class="reference external" href="/systems/">Systems</a></li>
      <li class="toctree-l1"><a class="reference external" href="/NVTabular/">NVTabular</a></li>
      <li class="toctree-l1"><a class="reference external" href="/Transformers4Rec/">Transformers4Rec</a></li>
      <li class="toctree-l1"><a class="reference external" href="/dataloader/">Dataloader</a></li>
      <li class="toctree-l1"><a class="reference external" href="/HugetCTR/">HugeCTR</a></li>
    </ul>
  </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for merlin.io.dataset</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">dask</span>
<span class="kn">import</span> <span class="nn">distributed</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">dask.base</span> <span class="kn">import</span> <span class="n">tokenize</span>
<span class="kn">from</span> <span class="nn">dask.dataframe.core</span> <span class="kn">import</span> <span class="n">new_dd_object</span>
<span class="kn">from</span> <span class="nn">dask.highlevelgraph</span> <span class="kn">import</span> <span class="n">HighLevelGraph</span>
<span class="kn">from</span> <span class="nn">dask.utils</span> <span class="kn">import</span> <span class="n">natural_sort_key</span><span class="p">,</span> <span class="n">parse_bytes</span>
<span class="kn">from</span> <span class="nn">fsspec.core</span> <span class="kn">import</span> <span class="n">get_fs_token_paths</span>
<span class="kn">from</span> <span class="nn">fsspec.utils</span> <span class="kn">import</span> <span class="n">stringify_path</span>
<span class="kn">from</span> <span class="nn">npy_append_array</span> <span class="kn">import</span> <span class="n">NpyAppendArray</span>

<span class="kn">from</span> <span class="nn">merlin.core.compat</span> <span class="kn">import</span> <span class="n">HAS_GPU</span><span class="p">,</span> <span class="n">cudf</span><span class="p">,</span> <span class="n">dask_cudf</span><span class="p">,</span> <span class="n">device_mem_size</span>
<span class="kn">from</span> <span class="nn">merlin.core.dispatch</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">convert_data</span><span class="p">,</span>
    <span class="n">dataframe_columnwise_explode</span><span class="p">,</span>
    <span class="n">hex_to_int</span><span class="p">,</span>
    <span class="n">is_dataframe_object</span><span class="p">,</span>
    <span class="n">is_list_dtype</span><span class="p">,</span>
    <span class="n">list_val_dtype</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">merlin.core.utils</span> <span class="kn">import</span> <span class="n">global_dask_client</span><span class="p">,</span> <span class="n">set_client_deprecated</span>
<span class="kn">from</span> <span class="nn">merlin.dtypes.shape</span> <span class="kn">import</span> <span class="n">DefaultShapes</span>
<span class="kn">from</span> <span class="nn">merlin.io.csv</span> <span class="kn">import</span> <span class="n">CSVDatasetEngine</span>
<span class="kn">from</span> <span class="nn">merlin.io.dask</span> <span class="kn">import</span> <span class="n">_ddf_to_dataset</span><span class="p">,</span> <span class="n">_simple_shuffle</span>
<span class="kn">from</span> <span class="nn">merlin.io.dataframe_engine</span> <span class="kn">import</span> <span class="n">DataFrameDatasetEngine</span>
<span class="kn">from</span> <span class="nn">merlin.io.dataframe_iter</span> <span class="kn">import</span> <span class="n">DataFrameIter</span>
<span class="kn">from</span> <span class="nn">merlin.io.parquet</span> <span class="kn">import</span> <span class="n">ParquetDatasetEngine</span>
<span class="kn">from</span> <span class="nn">merlin.io.shuffle</span> <span class="kn">import</span> <span class="n">_check_shuffle_arg</span>
<span class="kn">from</span> <span class="nn">merlin.schema</span> <span class="kn">import</span> <span class="n">ColumnSchema</span><span class="p">,</span> <span class="n">Schema</span>
<span class="kn">from</span> <span class="nn">merlin.schema.io.tensorflow_metadata</span> <span class="kn">import</span> <span class="n">TensorflowMetadata</span>

<span class="n">MERLIN_METADATA_DIR_NAME</span> <span class="o">=</span> <span class="s2">&quot;.merlin&quot;</span>
<span class="n">LOG</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;merlin&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="Dataset"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset">[docs]</a><span class="k">class</span> <span class="nc">Dataset</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Universal external-data wrapper for NVTabular</span>

<span class="sd">    The NVTabular `Workflow` and `DataLoader`-related APIs require all</span>
<span class="sd">    external data to be converted to the universal `Dataset` type.  The</span>
<span class="sd">    main purpose of this class is to abstract away the raw format of the</span>
<span class="sd">    data, and to allow other NVTabular classes to reliably materialize a</span>
<span class="sd">    `dask_cudf.DataFrame` collection (and/or collection-based iterator)</span>
<span class="sd">    on demand.</span>

<span class="sd">    A new `Dataset` object can be initialized from a variety of different</span>
<span class="sd">    raw-data formats. To initialize an object from a directory path or</span>
<span class="sd">    file list, the `engine` argument should be used to specify either</span>
<span class="sd">    &quot;parquet&quot; or &quot;csv&quot; format.  If the first argument contains a list</span>
<span class="sd">    of files with a suffix of either &quot;parquet&quot; or &quot;csv&quot;, the engine can</span>
<span class="sd">    be inferred::</span>

<span class="sd">        # Initialize Dataset with a parquet-dataset directory.</span>
<span class="sd">        # must specify engine=&quot;parquet&quot;</span>
<span class="sd">        dataset = Dataset(&quot;/path/to/data_pq&quot;, engine=&quot;parquet&quot;)</span>

<span class="sd">        # Initialize Dataset with list of csv files.</span>
<span class="sd">        # engine=&quot;csv&quot; argument is optional</span>
<span class="sd">        dataset = Dataset([&quot;file_0.csv&quot;, &quot;file_1.csv&quot;])</span>

<span class="sd">    Since NVTabular leverages `fsspec` as a file-system interface,</span>
<span class="sd">    the underlying data can be stored either locally, or in a remote/cloud</span>
<span class="sd">    data store.  To read from remote storage, like gds or s3, the</span>
<span class="sd">    appropriate protocol should be prepended to the `Dataset` path</span>
<span class="sd">    argument(s), and any special backend parameters should be passed</span>
<span class="sd">    in a `storage_options` dictionary::</span>

<span class="sd">        # Initialize Dataset with s3 parquet data</span>
<span class="sd">        dataset = Dataset(</span>
<span class="sd">            &quot;s3://bucket/path&quot;,</span>
<span class="sd">            engine=&quot;parquet&quot;,</span>
<span class="sd">            storage_options={&#39;anon&#39;: True, &#39;use_ssl&#39;: False},</span>
<span class="sd">        )</span>

<span class="sd">    By default, both parquet and csv-based data will be converted to</span>
<span class="sd">    a Dask-DataFrame collection with a maximum partition size of</span>
<span class="sd">    roughly 12.5 percent of the total memory on a single device.  The</span>
<span class="sd">    partition size can be changed to a different fraction of total</span>
<span class="sd">    memory on a single device with the `part_mem_fraction` argument.</span>
<span class="sd">    Alternatively, a specific byte size can be specified with the</span>
<span class="sd">    `part_size` argument::</span>

<span class="sd">        # Dataset partitions will be ~10% single-GPU memory (or smaller)</span>
<span class="sd">        dataset = Dataset(&quot;bigfile.parquet&quot;, part_mem_fraction=0.1)</span>

<span class="sd">        # Dataset partitions will be ~1GB (or smaller)</span>
<span class="sd">        dataset = Dataset(&quot;bigfile.parquet&quot;, part_size=&quot;1GB&quot;)</span>

<span class="sd">    Note that, if both the fractional and literal options are used</span>
<span class="sd">    at the same time, `part_size` will take precedence.  Also, for</span>
<span class="sd">    parquet-formatted data, the partitioning is done at the row-</span>
<span class="sd">    group level, and the byte-size of the first row-group (after</span>
<span class="sd">    CuDF conversion) is used to map all other partitions.</span>
<span class="sd">    Therefore, if the distribution of row-group sizes is not</span>
<span class="sd">    uniform, the partition sizes will not be balanced.</span>

<span class="sd">    In addition to handling data stored on disk, a `Dataset` object</span>
<span class="sd">    can also be initialized from an existing CuDF/Pandas DataFrame,</span>
<span class="sd">    or from a Dask-DataFrame collection (e.g. `dask_cudf.DataFrame`).</span>
<span class="sd">    For these in-memory formats, the size/number of partitions will</span>
<span class="sd">    not be modified.  That is, a CuDF/Pandas DataFrame (or PyArrow</span>
<span class="sd">    Table) will produce a single-partition collection, while the</span>
<span class="sd">    number/size of a Dask-DataFrame collection will be preserved::</span>

<span class="sd">        # Initialize from CuDF DataFrame (creates 1 partition)</span>
<span class="sd">        gdf = cudf.DataFrame(...)</span>
<span class="sd">        dataset = Dataset(gdf)</span>

<span class="sd">        # Initialize from Dask-CuDF DataFrame (preserves partitions)</span>
<span class="sd">        ddf = dask_cudf.read_parquet(...)</span>
<span class="sd">        dataset = Dataset(ddf)</span>

<span class="sd">    Since the `Dataset` API can both ingest and output a Dask</span>
<span class="sd">    collection, it is straightforward to transform data either before</span>
<span class="sd">    or after an NVTabular workflow is executed. This means that some</span>
<span class="sd">    complex pre-processing operations, that are not yet supported</span>
<span class="sd">    in NVTabular, can still be accomplished with the Dask-CuDF API::</span>

<span class="sd">        # Sort input data before final Dataset initialization</span>
<span class="sd">        # Warning: Global sorting requires significant device memory!</span>
<span class="sd">        ddf = Dataset(&quot;/path/to/data_pq&quot;, engine=&quot;parquet&quot;).to_ddf()</span>
<span class="sd">        ddf = ddf.sort_values(&quot;user_rank&quot;, ignore_index=True)</span>
<span class="sd">        dataset = Dataset(ddf)</span>

<span class="sd">    `Dataset Optimization Tips (DOTs)`</span>

<span class="sd">    The NVTabular dataset should be created from Parquet files in order</span>
<span class="sd">    to get the best possible performance, preferably with a row group size</span>
<span class="sd">    of around 128MB.  While NVTabular also supports reading from CSV files,</span>
<span class="sd">    reading CSV can be over twice as slow as reading from Parquet. Take a</span>
<span class="sd">    look at this notebook_ for an example of transforming the original Criteo</span>
<span class="sd">    CSV dataset into a new Parquet dataset optimized for use with NVTabular.</span>

<span class="sd">    .. _notebook: https://github.com/NVIDIA/NVTabular/blob/main/examples/optimize_criteo.ipynb</span>


<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    path_or_source : str, list of str, or &lt;dask.dataframe|cudf|pd&gt;.DataFrame</span>
<span class="sd">        Dataset path (or list of paths), or a DataFrame. If string,</span>
<span class="sd">        should specify a specific file or directory path. If this is a</span>
<span class="sd">        directory path, the directory structure must be flat (nested</span>
<span class="sd">        directories are not yet supported).</span>
<span class="sd">    engine : str or DatasetEngine</span>
<span class="sd">        DatasetEngine object or string identifier of engine. Current</span>
<span class="sd">        string options include: (&quot;parquet&quot;, &quot;csv&quot;, &quot;avro&quot;). This argument</span>
<span class="sd">        is ignored if path_or_source is a DataFrame type.</span>
<span class="sd">    npartitions : int</span>
<span class="sd">        Desired number of Dask-collection partitions to produce in</span>
<span class="sd">        the ``to_ddf`` method when ``path_or_source`` corresponds to a</span>
<span class="sd">        DataFrame type.  This argument is ignored for file-based</span>
<span class="sd">        ``path_or_source`` input.</span>
<span class="sd">    part_size : str or int</span>
<span class="sd">        Desired size (in bytes) of each Dask partition.</span>
<span class="sd">        If None, part_mem_fraction will be used to calculate the</span>
<span class="sd">        partition size.  Note that the underlying engine may allow</span>
<span class="sd">        other custom kwargs to override this argument. This argument</span>
<span class="sd">        is ignored if path_or_source is a DataFrame type.</span>
<span class="sd">    part_mem_fraction : float (default 0.125)</span>
<span class="sd">        Fractional size of desired dask partitions (relative</span>
<span class="sd">        to GPU memory capacity). Ignored if part_size is passed</span>
<span class="sd">        directly. Note that the underlying engine may allow other</span>
<span class="sd">        custom kwargs to override this argument. This argument</span>
<span class="sd">        is ignored if path_or_source is a DataFrame type. If</span>
<span class="sd">        ``cpu=True``, this value will be relative to the total</span>
<span class="sd">        host memory detected by the client process.</span>
<span class="sd">    storage_options: None or dict</span>
<span class="sd">        Further parameters to pass to the bytes backend. This argument</span>
<span class="sd">        is ignored if path_or_source is a DataFrame type.</span>
<span class="sd">    cpu : bool</span>
<span class="sd">        WARNING: Experimental Feature!</span>
<span class="sd">        Whether NVTabular should keep all data in cpu memory when</span>
<span class="sd">        the Dataset is converted to an internal Dask collection. The</span>
<span class="sd">        default value is False, unless ``cudf`` and ``dask_cudf``</span>
<span class="sd">        are not installed (in which case the default is True). In the</span>
<span class="sd">        future, if True, NVTabular will NOT use any available GPU</span>
<span class="sd">        devices for down-stream processing.</span>
<span class="sd">        NOTE: Down-stream ops and output do not yet support a</span>
<span class="sd">        Dataset generated with ``cpu=True``.</span>
<span class="sd">    base_dataset : Dataset</span>
<span class="sd">        Optional reference to the original &quot;base&quot; Dataset object used</span>
<span class="sd">        to construct the current Dataset instance.  This object is</span>
<span class="sd">        used to preserve file-partition mapping information.</span>
<span class="sd">    schema : Schema</span>
<span class="sd">        Optional argument, to support custom user defined Schemas.</span>
<span class="sd">        This overrides the derived schema behavior.</span>
<span class="sd">    **kwargs :</span>
<span class="sd">        Key-word arguments to pass through to Dask.dataframe IO function.</span>
<span class="sd">        For the Parquet engine(s), notable arguments include `filters`</span>
<span class="sd">        and `aggregate_files` (the latter is experimental).</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Dataset.__init__"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path_or_source</span><span class="p">,</span>
        <span class="n">engine</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">npartitions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">part_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">part_mem_fraction</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">storage_options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">client</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">cpu</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">base_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">schema</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;unsupported schema type for merlin.io.Dataset: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Deprecate `client`</span>
        <span class="k">if</span> <span class="n">client</span> <span class="o">!=</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="n">set_client_deprecated</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">=</span> <span class="n">dtypes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span>

        <span class="c1"># Cache for &quot;real&quot; (sampled) metadata</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_real_meta</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Check if we are keeping data in host or gpu device memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span> <span class="o">=</span> <span class="n">cpu</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">HAS_GPU</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot initialize Dataset on GPU. &quot;</span>
                    <span class="s2">&quot;No devices detected (with pynvml). &quot;</span>
                    <span class="s2">&quot;Check that pynvml can be initialized. &quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">cudf</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot initialize Dataset on GPU. &quot;</span>
                    <span class="s2">&quot;cudf package not found. &quot;</span>
                    <span class="s2">&quot;Check that cudf is installed in this environment and can be imported.  &quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span> <span class="o">=</span> <span class="n">cudf</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">HAS_GPU</span>

        <span class="c1"># Keep track of base dataset (optional)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_dataset</span> <span class="o">=</span> <span class="n">base_dataset</span> <span class="ow">or</span> <span class="bp">self</span>

        <span class="c1"># For now, lets warn the user that &quot;cpu mode&quot; is experimental</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Initializing an NVTabular Dataset in CPU mode.&quot;</span>
                <span class="s2">&quot;This is an experimental feature with extremely limited support!&quot;</span>
            <span class="p">)</span>

        <span class="n">npartitions</span> <span class="o">=</span> <span class="n">npartitions</span> <span class="ow">or</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">,</span> <span class="n">dask</span><span class="o">.</span><span class="n">dataframe</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">or</span> <span class="n">is_dataframe_object</span><span class="p">(</span>
            <span class="n">path_or_source</span>
        <span class="p">):</span>
            <span class="c1"># User is passing in a &lt;dask.dataframe|cudf|pd&gt;.DataFrame</span>
            <span class="c1"># Use DataFrameDatasetEngine</span>
            <span class="n">_path_or_source</span> <span class="o">=</span> <span class="n">convert_data</span><span class="p">(</span>
                <span class="n">path_or_source</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span> <span class="n">to_collection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">npartitions</span><span class="o">=</span><span class="n">npartitions</span>
            <span class="p">)</span>
            <span class="c1"># Check if this is a collection that has now moved between host &lt;-&gt; device</span>
            <span class="n">moved_collection</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">,</span> <span class="n">dask</span><span class="o">.</span><span class="n">dataframe</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_path_or_source</span><span class="o">.</span><span class="n">_meta</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">path_or_source</span><span class="o">.</span><span class="n">_meta</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">part_size</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;part_size is ignored for DataFrame input.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">part_mem_fraction</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;part_mem_fraction is ignored for DataFrame input.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">engine</span> <span class="o">=</span> <span class="n">DataFrameDatasetEngine</span><span class="p">(</span>
                <span class="n">_path_or_source</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span> <span class="n">moved_collection</span><span class="o">=</span><span class="n">moved_collection</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">part_size</span><span class="p">:</span>
                <span class="c1"># If a specific partition size is given, use it directly</span>
                <span class="n">part_size</span> <span class="o">=</span> <span class="n">parse_bytes</span><span class="p">(</span><span class="n">part_size</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># If a fractional partition size is given, calculate part_size</span>
                <span class="n">part_mem_fraction</span> <span class="o">=</span> <span class="n">part_mem_fraction</span> <span class="ow">or</span> <span class="mf">0.125</span>
                <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;</span> <span class="n">part_mem_fraction</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
                <span class="k">if</span> <span class="n">part_mem_fraction</span> <span class="o">&gt;</span> <span class="mf">0.25</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s2">&quot;Using very large partitions sizes for Dask. &quot;</span>
                        <span class="s2">&quot;Memory-related errors are likely.&quot;</span>
                    <span class="p">)</span>
                <span class="n">part_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">device_mem_size</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;total&quot;</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">)</span> <span class="o">*</span> <span class="n">part_mem_fraction</span><span class="p">)</span>

            <span class="c1"># Engine-agnostic path handling</span>
            <span class="n">paths</span> <span class="o">=</span> <span class="n">stringify_path</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">paths</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">paths</span><span class="p">]</span>
            <span class="n">paths</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">paths</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">natural_sort_key</span><span class="p">)</span>

            <span class="n">storage_options</span> <span class="o">=</span> <span class="n">storage_options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="c1"># If engine is not provided, try to infer from end of paths[0]</span>
            <span class="k">if</span> <span class="n">engine</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">engine</span> <span class="o">=</span> <span class="n">paths</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">engine</span> <span class="o">==</span> <span class="s2">&quot;parquet&quot;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">engine</span> <span class="o">=</span> <span class="n">ParquetDatasetEngine</span><span class="p">(</span>
                        <span class="n">paths</span><span class="p">,</span> <span class="n">part_size</span><span class="p">,</span> <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">engine</span> <span class="o">==</span> <span class="s2">&quot;csv&quot;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">engine</span> <span class="o">=</span> <span class="n">CSVDatasetEngine</span><span class="p">(</span>
                        <span class="n">paths</span><span class="p">,</span> <span class="n">part_size</span><span class="p">,</span> <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">engine</span> <span class="o">==</span> <span class="s2">&quot;avro&quot;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="kn">from</span> <span class="nn">merlin.io.avro</span> <span class="kn">import</span> <span class="n">AvroDatasetEngine</span>
                    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;Failed to import AvroDatasetEngine. Make sure uavro is installed.&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">engine</span> <span class="o">=</span> <span class="n">AvroDatasetEngine</span><span class="p">(</span>
                        <span class="n">paths</span><span class="p">,</span> <span class="n">part_size</span><span class="p">,</span> <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only parquet, csv, and avro supported (for now).&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">engine</span> <span class="o">=</span> <span class="n">engine</span><span class="p">(</span>
                    <span class="n">paths</span><span class="p">,</span> <span class="n">part_size</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span> <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span>
                <span class="p">)</span>

        <span class="c1"># load in schema or infer if not available</span>
        <span class="c1"># path is always a list at this point</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">)):</span>
                <span class="n">path_or_source</span> <span class="o">=</span> <span class="p">[</span><span class="n">Path</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">)):</span>
                <span class="c1"># list of paths to files</span>
                <span class="n">schema_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path_or_source</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">schema_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
                    <span class="n">schema_path</span> <span class="o">=</span> <span class="n">schema_path</span><span class="o">.</span><span class="n">parent</span>

                <span class="n">pbtxt_deprecated_warning</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;Found schema.pbtxt. Loading schema automatically from &quot;</span>
                    <span class="s2">&quot;schema.pbtxt is deprecated and will be removed in the &quot;</span>
                    <span class="s2">&quot;future. Re-run workflow to generate .merlin/schema.json.&quot;</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="p">(</span><span class="n">schema_path</span> <span class="o">/</span> <span class="n">MERLIN_METADATA_DIR_NAME</span> <span class="o">/</span> <span class="s2">&quot;schema.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="n">schema</span> <span class="o">=</span> <span class="n">TensorflowMetadata</span><span class="o">.</span><span class="n">from_json_file</span><span class="p">(</span>
                        <span class="n">schema_path</span> <span class="o">/</span> <span class="n">MERLIN_METADATA_DIR_NAME</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">to_merlin_schema</span><span class="p">()</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">schema_path</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="n">MERLIN_METADATA_DIR_NAME</span> <span class="o">/</span> <span class="s2">&quot;schema.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="n">schema</span> <span class="o">=</span> <span class="n">TensorflowMetadata</span><span class="o">.</span><span class="n">from_json_file</span><span class="p">(</span>
                        <span class="n">schema_path</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="n">MERLIN_METADATA_DIR_NAME</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">to_merlin_schema</span><span class="p">()</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">schema_path</span> <span class="o">/</span> <span class="s2">&quot;schema.pbtxt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">pbtxt_deprecated_warning</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
                    <span class="n">schema</span> <span class="o">=</span> <span class="n">TensorflowMetadata</span><span class="o">.</span><span class="n">from_proto_text_file</span><span class="p">(</span><span class="n">schema_path</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">to_merlin_schema</span><span class="p">()</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">schema_path</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s2">&quot;schema.pbtxt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">pbtxt_deprecated_warning</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
                    <span class="n">schema</span> <span class="o">=</span> <span class="n">TensorflowMetadata</span><span class="o">.</span><span class="n">from_proto_text_file</span><span class="p">(</span><span class="n">schema_path</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">to_merlin_schema</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">infer_schema</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># df with no schema</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">infer_schema</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.to_ddf"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.to_ddf">[docs]</a>    <span class="k">def</span> <span class="nf">to_ddf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert `Dataset` object to `dask_cudf.DataFrame`</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        columns : str or list(str); default None</span>
<span class="sd">            Columns to include in output `DataFrame`. If not specified,</span>
<span class="sd">            the output will contain all known columns in the Dataset.</span>
<span class="sd">        shuffle : bool; default False</span>
<span class="sd">            Whether to shuffle the order of partitions in the output</span>
<span class="sd">            `dask_cudf.DataFrame`.  Note that this does not shuffle</span>
<span class="sd">            the rows within each partition. This is because the data</span>
<span class="sd">            is not actually loaded into memory for this operation.</span>
<span class="sd">        seed : int; Optional</span>
<span class="sd">            The random seed to use if `shuffle=True`.  If nothing</span>
<span class="sd">            is specified, the current system time will be used by the</span>
<span class="sd">            `random` std library.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Use DatasetEngine to create ddf</span>
        <span class="n">ddf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

        <span class="c1"># Shuffle the partitions of ddf (optional)</span>
        <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">and</span> <span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Start with ordered partitions</span>
            <span class="n">inds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span><span class="p">))</span>

            <span class="c1"># Use random std library to reorder partitions</span>
            <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">inds</span><span class="p">)</span>

            <span class="c1"># Construct new high-level graph (HLG)</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">_name</span>
            <span class="n">new_name</span> <span class="o">=</span> <span class="s2">&quot;shuffle-partitions-&quot;</span> <span class="o">+</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">ddf</span><span class="p">)</span>
            <span class="n">dsk</span> <span class="o">=</span> <span class="p">{(</span><span class="n">new_name</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">ind</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inds</span><span class="p">)}</span>

            <span class="n">new_graph</span> <span class="o">=</span> <span class="n">HighLevelGraph</span><span class="o">.</span><span class="n">from_collections</span><span class="p">(</span><span class="n">new_name</span><span class="p">,</span> <span class="n">dsk</span><span class="p">,</span> <span class="n">dependencies</span><span class="o">=</span><span class="p">[</span><span class="n">ddf</span><span class="p">])</span>

            <span class="c1"># Convert the HLG to a Dask collection</span>
            <span class="n">divisions</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">ddf</span> <span class="o">=</span> <span class="n">new_dd_object</span><span class="p">(</span><span class="n">new_graph</span><span class="p">,</span> <span class="n">new_name</span><span class="p">,</span> <span class="n">ddf</span><span class="o">.</span><span class="n">_meta</span><span class="p">,</span> <span class="n">divisions</span><span class="p">)</span>

        <span class="c1"># Special dtype conversion (optional)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">:</span>
            <span class="n">_meta</span> <span class="o">=</span> <span class="n">_set_dtypes</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">_meta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">)</span>
            <span class="n">ddf</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">map_partitions</span><span class="p">(</span><span class="n">_set_dtypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="n">_meta</span><span class="p">)</span>

        <span class="n">dask_client</span> <span class="o">=</span> <span class="n">global_dask_client</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">dask_client</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># pylint: disable=unidiomatic-typecheck</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">dask_cudf</span>
                <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ddf</span><span class="p">,</span> <span class="n">dask_cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span>
                <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">dask_client</span><span class="o">.</span><span class="n">cluster</span><span class="p">)</span> <span class="ow">is</span> <span class="n">distributed</span><span class="o">.</span><span class="n">LocalCluster</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;`dask_cudf.DataFrame` is incompatible with `distributed.LocalCluster`. &quot;</span>
                    <span class="s2">&quot;Please setup a `dask_cuda.LocalCUDACluster` instead. &quot;</span>
                    <span class="s2">&quot;Or to run on CPU instead, &quot;</span>
                    <span class="s2">&quot;provide the parameter `cpu=True` when creating the `Dataset`. &quot;</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">ddf</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">file_partition_map</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">_file_partition_map</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">partition_lens</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">_partition_lens</span>

<div class="viewcode-block" id="Dataset.to_cpu"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.to_cpu">[docs]</a>    <span class="k">def</span> <span class="nf">to_cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Changing an NVTabular Dataset to CPU mode.&quot;</span>
            <span class="s2">&quot;This is an experimental feature with extremely limited support!&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">to_cpu</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.to_gpu"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.to_gpu">[docs]</a>    <span class="k">def</span> <span class="nf">to_gpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">()</span></div>

<div class="viewcode-block" id="Dataset.shuffle_by_keys"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.shuffle_by_keys">[docs]</a>    <span class="k">def</span> <span class="nf">shuffle_by_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">hive_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">npartitions</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shuffle the in-memory Dataset so that all unique-key</span>
<span class="sd">        combinations are moved to the same partition.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        keys : list(str)</span>
<span class="sd">            Column names to shuffle by.</span>
<span class="sd">        hive_data : bool; default None</span>
<span class="sd">            Whether the dataset is backed by a hive-partitioned</span>
<span class="sd">            dataset (with the keys encoded in the directory structure).</span>
<span class="sd">            By default, the Dataset&#39;s `file_partition_map` property will</span>
<span class="sd">            be inspected to infer this setting. When `hive_data` is True,</span>
<span class="sd">            the number of output partitions will correspond to the number</span>
<span class="sd">            of unique key combinations in the dataset.</span>
<span class="sd">        npartitions : int; default None</span>
<span class="sd">            Number of partitions in the output Dataset. For hive-partitioned</span>
<span class="sd">            data, this value should be &lt;= the number of unique key</span>
<span class="sd">            combinations (the default), otherwise it will be ignored. For</span>
<span class="sd">            data that is not hive-partitioned, the ``npartitions`` input</span>
<span class="sd">            should be &lt;= the original partition count, otherwise it will be</span>
<span class="sd">            ignored.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Make sure we are dealing with a list</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">keys</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="k">else</span> <span class="n">keys</span>

        <span class="c1"># Start with default ddf</span>
        <span class="n">ddf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">npartitions</span><span class="p">:</span>
            <span class="n">npartitions</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span><span class="p">,</span> <span class="n">npartitions</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">hive_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span><span class="p">:</span>
            <span class="c1"># The keys may be encoded in the directory names.</span>
            <span class="c1"># Let&#39;s use the file_partition_map to extract this info.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_partition_map</span>
            <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">_mapping</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">hive_data</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Failed to extract hive-partition mapping!&quot;</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

            <span class="c1"># If we have a `_mapping` available, check if the</span>
            <span class="c1"># file names include information about all our keys</span>
            <span class="n">hive_mapping</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_mapping</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">sep</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">_key</span><span class="p">,</span> <span class="n">_val</span> <span class="o">=</span> <span class="n">part</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                            <span class="k">continue</span>
                        <span class="k">if</span> <span class="n">_key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                            <span class="n">hive_mapping</span><span class="p">[</span><span class="n">_key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_val</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">hive_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">keys</span><span class="p">):</span>
                <span class="c1"># Generate hive-mapping DataFrame summary</span>
                <span class="n">hive_mapping</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">_meta</span><span class="p">)(</span><span class="n">hive_mapping</span><span class="p">)</span>
                <span class="n">cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">hive_mapping</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                    <span class="n">typ</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">_meta</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">typ</span> <span class="o">==</span> <span class="s2">&quot;category&quot;</span><span class="p">:</span>
                            <span class="c1"># Cannot cast directly to categorical unless we</span>
                            <span class="c1"># first cast to the underlying dtype of the categories</span>
                            <span class="n">hive_mapping</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">hive_mapping</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">typ</span><span class="o">.</span><span class="n">categories</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                        <span class="n">hive_mapping</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">hive_mapping</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">typ</span><span class="p">)</span>

                <span class="c1"># Generate simple-shuffle plan</span>
                <span class="n">target_mapping</span> <span class="o">=</span> <span class="n">hive_mapping</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">target_mapping</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;_partition&quot;</span>
                <span class="n">hive_mapping</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;_sort&quot;</span>
                <span class="n">target_mapping</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">plan</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">hive_mapping</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
                    <span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">target_mapping</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="n">cols</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;_sort&quot;</span><span class="p">)[</span><span class="s2">&quot;_partition&quot;</span><span class="p">]</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="s2">&quot;to_pandas&quot;</span><span class="p">):</span>
                    <span class="n">plan</span> <span class="o">=</span> <span class="n">plan</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

                <span class="c1"># Deal with repartitioning</span>
                <span class="k">if</span> <span class="n">npartitions</span> <span class="ow">and</span> <span class="n">npartitions</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_mapping</span><span class="p">):</span>
                    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">npartitions</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">divs</span> <span class="o">=</span> <span class="n">plan</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
                    <span class="n">partitions</span> <span class="o">=</span> <span class="n">divs</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="n">partitions</span><span class="p">[(</span><span class="n">plan</span> <span class="o">&gt;=</span> <span class="n">divs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">values</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">divs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>
                    <span class="n">plan</span> <span class="o">=</span> <span class="n">partitions</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">plan</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">plan</span><span class="o">.</span><span class="n">unique</span><span class="p">()):</span>
                    <span class="n">plan</span> <span class="o">=</span> <span class="n">plan</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Plan is a unique 1:1 ddf partition mapping.</span>
                    <span class="c1"># We already have shuffled data.</span>
                    <span class="k">return</span> <span class="bp">self</span>

                <span class="c1"># TODO: We should avoid shuffling the original ddf and</span>
                <span class="c1"># instead construct a new (more-efficent) graph to read</span>
                <span class="c1"># multiple files from each partition directory at once.</span>
                <span class="c1"># Generally speaking, we can optimize this code path</span>
                <span class="c1"># much further.</span>
                <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">_simple_shuffle</span><span class="p">(</span><span class="n">ddf</span><span class="p">,</span> <span class="n">plan</span><span class="p">))</span>

        <span class="c1"># Fall back to dask.dataframe algorithm</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">npartitions</span><span class="o">=</span><span class="n">npartitions</span><span class="p">))</span></div>

<div class="viewcode-block" id="Dataset.repartition"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.repartition">[docs]</a>    <span class="k">def</span> <span class="nf">repartition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">npartitions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">partition_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Repartition the underlying ddf, and return a new Dataset</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        npartitions : int; default None</span>
<span class="sd">            Number of partitions in output ``Dataset``. Only used if</span>
<span class="sd">            ``partition_size`` isnt specified.</span>
<span class="sd">        partition_size : int or str; default None</span>
<span class="sd">            Max number of bytes of memory for each partition. Use</span>
<span class="sd">            numbers or strings like &#39;5MB&#39;. If specified, ``npartitions``</span>
<span class="sd">            will be ignored.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span>
            <span class="o">.</span><span class="n">clear_divisions</span><span class="p">()</span>
            <span class="o">.</span><span class="n">repartition</span><span class="p">(</span>
                <span class="n">npartitions</span><span class="o">=</span><span class="n">npartitions</span><span class="p">,</span>
                <span class="n">partition_size</span><span class="o">=</span><span class="n">partition_size</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">schema</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span>
            <span class="n">cpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.merge"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.merge">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Merge two Dataset objects</span>

<span class="sd">        Produces a new Dataset object. If the ``cpu`` Dataset attributes</span>
<span class="sd">        do not match, the right side will be modified. See Dask-Dataframe</span>
<span class="sd">        ``merge`` documentation for more information. Example usage::</span>

<span class="sd">            ds_1 = Dataset(&quot;file.parquet&quot;)</span>
<span class="sd">            ds_2 = Dataset(cudf.DataFrame(...))</span>
<span class="sd">            ds_merged = Dataset.merge(ds_1, ds_2, on=&quot;foo&quot;, how=&quot;inner&quot;)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        left : Dataset</span>
<span class="sd">            Left-side Dataset object.</span>
<span class="sd">        right : Dataset</span>
<span class="sd">            Right-side Dataset object.</span>
<span class="sd">        **kwargs :</span>
<span class="sd">            Key-word arguments to be passed through to Dask-Dataframe.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Ensure both Dataset objects are either cudf or pandas based</span>
        <span class="k">if</span> <span class="n">left</span><span class="o">.</span><span class="n">cpu</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">right</span><span class="o">.</span><span class="n">cpu</span><span class="p">:</span>
            <span class="n">_right</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">right</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">())</span>
            <span class="n">_right</span><span class="o">.</span><span class="n">to_cpu</span><span class="p">()</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">left</span><span class="o">.</span><span class="n">cpu</span> <span class="ow">and</span> <span class="n">right</span><span class="o">.</span><span class="n">cpu</span><span class="p">:</span>
            <span class="n">_right</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">right</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">())</span>
            <span class="n">_right</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">left</span><span class="o">.</span><span class="n">cpu</span> <span class="o">==</span> <span class="n">right</span><span class="o">.</span><span class="n">cpu</span><span class="p">:</span>
            <span class="c1"># both left and right are already cudf / pandas df</span>
            <span class="n">_right</span> <span class="o">=</span> <span class="n">right</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">left</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span>
            <span class="o">.</span><span class="n">clear_divisions</span><span class="p">()</span>
            <span class="o">.</span><span class="n">merge</span><span class="p">(</span>
                <span class="n">_right</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">clear_divisions</span><span class="p">(),</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_iter"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.to_iter">[docs]</a>    <span class="k">def</span> <span class="nf">to_iter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_file_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert `Dataset` object to a `cudf.DataFrame` iterator.</span>

<span class="sd">        Note that this method will use `to_ddf` to produce a</span>
<span class="sd">        `dask_cudf.DataFrame`, and materialize a single partition for</span>
<span class="sd">        each iteration.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        columns : str or list(str); default None</span>
<span class="sd">            Columns to include in each `DataFrame`. If not specified,</span>
<span class="sd">            the outputs will contain all known columns in the Dataset.</span>
<span class="sd">        indices : list(int); default None</span>
<span class="sd">            A specific list of partition indices to iterate over. If</span>
<span class="sd">            nothing is specified, all partitions will be returned in</span>
<span class="sd">            order (or the shuffled order, if `shuffle=True`).</span>
<span class="sd">        shuffle : bool; default False</span>
<span class="sd">            Whether to shuffle the order of `dask_cudf.DataFrame`</span>
<span class="sd">            partitions used by the iterator.  If the `indices`</span>
<span class="sd">            argument is specified, those indices correspond to the</span>
<span class="sd">            partition indices AFTER the shuffle operation.</span>
<span class="sd">        seed : int; Optional</span>
<span class="sd">            The random seed to use if `shuffle=True`.  If nothing</span>
<span class="sd">            is specified, the current system time will be used by the</span>
<span class="sd">            `random` std library.</span>
<span class="sd">        use_file_metadata : bool; Optional</span>
<span class="sd">            Whether to allow the returned ``DataFrameIter`` object to</span>
<span class="sd">            use file metadata from the ``base_dataset`` to estimate</span>
<span class="sd">            the row-count. By default, the file-metadata</span>
<span class="sd">            optimization will only be used if the current Dataset is</span>
<span class="sd">            backed by a file-based engine. Otherwise, it is possible</span>
<span class="sd">            that an intermediate transform has modified the row-count.</span>
<span class="sd">        epochs : int</span>
<span class="sd">            Number of dataset passes to include within a single iterator.</span>
<span class="sd">            This option is used for multi-epoch data-loading. Default is 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">columns</span><span class="p">]</span>

        <span class="c1"># Try to extract the row-size metadata</span>
        <span class="c1"># if we are not shuffling</span>
        <span class="n">partition_lens_meta</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">shuffle</span> <span class="ow">and</span> <span class="n">use_file_metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span><span class="p">:</span>
            <span class="c1"># We are allowed to use file metadata to calculate</span>
            <span class="c1"># partition sizes.  If `use_file_metadata` is None,</span>
            <span class="c1"># we only use metadata if `self` is backed by a</span>
            <span class="c1"># file-based engine (like &quot;parquet&quot;).  Otherwise,</span>
            <span class="c1"># we cannot be &quot;sure&quot; that the metadata row-count</span>
            <span class="c1"># is correct.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">use_file_metadata</span><span class="p">:</span>
                    <span class="n">partition_lens_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_dataset</span><span class="o">.</span><span class="n">partition_lens</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">partition_lens_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">partition_lens</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">pass</span>

        <span class="k">return</span> <span class="n">DataFrameIter</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">),</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
            <span class="n">partition_lens</span><span class="o">=</span><span class="n">partition_lens_meta</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_parquet"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.to_parquet">[docs]</a>    <span class="k">def</span> <span class="nf">to_parquet</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output_path</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">preserve_files</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">output_files</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_files_per_proc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">row_group_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">cats</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">conts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">suffix</span><span class="o">=</span><span class="s2">&quot;.parquet&quot;</span><span class="p">,</span>
        <span class="n">partition_on</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;subgraph&quot;</span><span class="p">,</span>
        <span class="n">write_hugectr_keyset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes out to a parquet dataset</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        output_path : string</span>
<span class="sd">            Path to write processed/shuffled output data</span>
<span class="sd">        shuffle : merlin.io.Shuffle enum</span>
<span class="sd">            How to shuffle the output dataset. For all options,</span>
<span class="sd">            other than `None` (which means no shuffling), the partitions</span>
<span class="sd">            of the underlying dataset/ddf will be randomly ordered. If</span>
<span class="sd">            `PER_PARTITION` is specified, each worker/process will also</span>
<span class="sd">            shuffle the rows within each partition before splitting and</span>
<span class="sd">            appending the data to a number (`out_files_per_proc`) of output</span>
<span class="sd">            files. Output files are distinctly mapped to each worker process.</span>
<span class="sd">            If `PER_WORKER` is specified, each worker will follow the same</span>
<span class="sd">            procedure as `PER_PARTITION`, but will re-shuffle each file after</span>
<span class="sd">            all data is persisted.  This results in a full shuffle of the</span>
<span class="sd">            data processed by each worker.  To improve performance, this option</span>
<span class="sd">            currently uses host-memory `BytesIO` objects for the intermediate</span>
<span class="sd">            persist stage. The `FULL` option is not yet implemented.</span>
<span class="sd">        partition_on : str or list(str)</span>
<span class="sd">            Columns to use for hive-partitioning.  If this option is used,</span>
<span class="sd">            `preserve_files`, `output_files`, and `out_files_per_proc`</span>
<span class="sd">            cannot be specified, and `method` will be ignored.  Also, the</span>
<span class="sd">            `PER_WORKER` shuffle will not be supported.</span>
<span class="sd">        preserve_files : bool</span>
<span class="sd">            Whether to preserve the original file-to-partition mapping of</span>
<span class="sd">            the base dataset. This option requires `method=&quot;subgraph&quot;`, and is</span>
<span class="sd">            only available if the base dataset is known, and if it corresponds</span>
<span class="sd">            to csv or parquet format. If True, the `out_files_per_proc` option</span>
<span class="sd">            will be ignored. Default is False.</span>
<span class="sd">        output_files : dict, list or int</span>
<span class="sd">            The total number of desired output files. This option requires</span>
<span class="sd">            `method=&quot;subgraph&quot;`. When `out_files_per_proc=None`, the default</span>
<span class="sd">            is the number of underlying Dask partitions. When `out_files_per_proc`</span>
<span class="sd">            is set to an integer, the default is the product of that integer and</span>
<span class="sd">            the total number of workers in the Dask cluster. For further output-file</span>
<span class="sd">            control, this argument may also be used to pass a dictionary mapping</span>
<span class="sd">            the output file names to partition indices, or a list of desired</span>
<span class="sd">            output-file names.</span>
<span class="sd">        out_files_per_proc : integer</span>
<span class="sd">            Number of output files that each process will use to shuffle an input</span>
<span class="sd">            partition. Default is 1. If `method=&quot;worker&quot;`, the total number of output</span>
<span class="sd">            files will always be the total number of Dask workers, multiplied by this</span>
<span class="sd">            argument. If `method=&quot;subgraph&quot;`, the total number of files is determined</span>
<span class="sd">            by `output_files` (and `out_files_per_proc` must be 1 if a dictionary is</span>
<span class="sd">            specified).</span>
<span class="sd">        row_group_size : integer</span>
<span class="sd">            Maximum number of rows to include in each Parquet row-group. By default,</span>
<span class="sd">            the maximum row-group size will be chosen by the backend Parquet engine</span>
<span class="sd">            (cudf or pyarrow). Note that cudf currently prohibits this value from</span>
<span class="sd">            being less than `5000` rows. If smaller row-groups are necessary, try</span>
<span class="sd">            calling `to_cpu()` before writing to disk.</span>
<span class="sd">        num_threads : integer</span>
<span class="sd">            Number of IO threads to use for writing the output dataset.</span>
<span class="sd">            For `0` (default), no dedicated IO threads will be used.</span>
<span class="sd">        dtypes : dict</span>
<span class="sd">            Dictionary containing desired datatypes for output columns.</span>
<span class="sd">            Keys are column names, values are datatypes.</span>
<span class="sd">        suffix : str or False</span>
<span class="sd">            File-name extension to use for all output files. This argument</span>
<span class="sd">            is ignored if a specific list of file names is specified using</span>
<span class="sd">            the ``output_files`` option. If ``preserve_files=True``, this</span>
<span class="sd">            suffix will be appended to the original name of each file,</span>
<span class="sd">            unless the original extension is &quot;.csv&quot;, &quot;.parquet&quot;, &quot;.avro&quot;,</span>
<span class="sd">            or &quot;.orc&quot; (in which case the old extension will be replaced).</span>
<span class="sd">        cats : list of str, optional</span>
<span class="sd">            List of categorical columns</span>
<span class="sd">        conts : list of str, optional</span>
<span class="sd">            List of continuous columns</span>
<span class="sd">        labels : list of str, optional</span>
<span class="sd">            List of label columns</span>
<span class="sd">        method : {&quot;subgraph&quot;, &quot;worker&quot;}</span>
<span class="sd">            General algorithm to use for the parallel graph execution. In order</span>
<span class="sd">            to minimize memory pressure, `to_parquet` will use a `&quot;subgraph&quot;` by</span>
<span class="sd">            default. This means that we segment the full Dask task graph into a</span>
<span class="sd">            distinct subgraph for each output file (or output-file group). Then,</span>
<span class="sd">            each of these subgraphs is executed, in full, by the same worker (as</span>
<span class="sd">            a single large task). In some cases, it may be more ideal to prioritize</span>
<span class="sd">            concurrency. In that case, a worker-based approach can be used by</span>
<span class="sd">            specifying `method=&quot;worker&quot;`.</span>
<span class="sd">        write_hugectr_keyset : bool, optional</span>
<span class="sd">            Whether to write a HugeCTR keyset output file (&quot;_hugectr.keyset&quot;).</span>
<span class="sd">            Writing this file can be very slow, and should only be done if you</span>
<span class="sd">            are planning to ingest the output data with HugeCTR. Default is False.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">preserve_partitions</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">partition_on</span><span class="p">:</span>
            <span class="c1"># Check that the user is not expecting a specific output-file</span>
            <span class="c1"># count/structure that is not supported</span>
            <span class="k">if</span> <span class="n">output_files</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`output_files` not supported when `partition_on` is used.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">out_files_per_proc</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`out_files_per_proc` not supported when `partition_on` is used.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">preserve_files</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`preserve_files` not supported when `partition_on` is used.&quot;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Check that method (algorithm) is valid</span>
            <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;subgraph&quot;</span><span class="p">,</span> <span class="s2">&quot;worker&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2"> not a recognized method for `Dataset.to_parquet`&quot;</span><span class="p">)</span>

            <span class="c1"># Deal with method-specific defaults</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;worker&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">output_files</span> <span class="ow">or</span> <span class="n">preserve_files</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;output_files and preserve_files require `method=&#39;subgraph&#39;`&quot;</span><span class="p">)</span>
                <span class="n">output_files</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="n">preserve_files</span> <span class="ow">and</span> <span class="n">output_files</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot specify both preserve_files and output_files.&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">output_files</span> <span class="ow">or</span> <span class="n">preserve_files</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">out_files_per_proc</span><span class="p">:</span>
                    <span class="c1"># Default &quot;subgraph&quot; behavior - Set output_files to the</span>
                    <span class="c1"># total umber of workers, multiplied by out_files_per_proc</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">nworkers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">global_dask_client</span><span class="p">()</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">workers</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                        <span class="n">nworkers</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="n">output_files</span> <span class="o">=</span> <span class="n">nworkers</span> <span class="o">*</span> <span class="n">out_files_per_proc</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Preserve original Dask partitions if output_files,</span>
                    <span class="c1"># preserve_files AND out_files_per_proc are all None</span>
                    <span class="n">preserve_partitions</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Replace None/False suffix argument with &quot;&quot;</span>
        <span class="n">suffix</span> <span class="o">=</span> <span class="n">suffix</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># Check shuffle argument</span>
        <span class="n">shuffle</span> <span class="o">=</span> <span class="n">_check_shuffle_arg</span><span class="p">(</span><span class="n">shuffle</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_files</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">output_files</span> <span class="ow">and</span> <span class="n">preserve_files</span><span class="p">):</span>
            <span class="c1"># Do not shuffle partitions if we are preserving files or</span>
            <span class="c1"># if a specific file-partition mapping is already specified</span>
            <span class="n">ddf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ddf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>

        <span class="c1"># Check if partitions should be preserved</span>
        <span class="k">if</span> <span class="n">preserve_partitions</span><span class="p">:</span>
            <span class="n">output_files</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span>

        <span class="c1"># Deal with `method==&quot;subgraph&quot;`.</span>
        <span class="c1"># Convert `output_files` argument to a dict mapping</span>
        <span class="k">if</span> <span class="n">output_files</span><span class="p">:</span>
            <span class="c1">#   NOTES on `output_files`:</span>
            <span class="c1">#</span>
            <span class="c1"># - If a list of file names is specified, a contiguous range of</span>
            <span class="c1">#   output partitions will be mapped to each file. The same</span>
            <span class="c1">#   procedure is used if an integer is specified, but the file</span>
            <span class="c1">#   names will be written as &quot;part_*&quot;.</span>
            <span class="c1">#</span>
            <span class="c1"># - When `output_files` is used, the `output_files_per_proc`</span>
            <span class="c1">#   argument will be interpreted as the desired number of output</span>
            <span class="c1">#   files to write within the same task at run time (enabling</span>
            <span class="c1">#   input partitions to be shuffled into multiple output files).</span>
            <span class="c1">#</span>
            <span class="c1"># - Passing a list or integer to `output_files` will preserve</span>
            <span class="c1">#   the original ordering of the input data as long as</span>
            <span class="c1">#   `out_files_per_proc` is set to `1` (or `None`), and</span>
            <span class="c1">#   `shuffle==None`.</span>
            <span class="c1">#</span>
            <span class="c1"># - If a dictionary is specified, excluded partition indices</span>
            <span class="c1">#   will not be written to disk.</span>
            <span class="c1">#</span>
            <span class="c1"># - To map multiple output files to a range of input partitions,</span>
            <span class="c1">#   dictionary-input keys should correspond to a tuple of file</span>
            <span class="c1">#   names.</span>

            <span class="c1"># Use out_files_per_proc to calculate how</span>
            <span class="c1"># many output files should be written within the</span>
            <span class="c1"># same subgraph.  Note that we must a</span>
            <span class="n">files_per_task</span> <span class="o">=</span> <span class="n">out_files_per_proc</span> <span class="ow">or</span> <span class="mi">1</span>
            <span class="n">required_npartitions</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_files</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">required_npartitions</span> <span class="o">=</span> <span class="n">output_files</span>
                <span class="n">files_per_task</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">files_per_task</span><span class="p">,</span> <span class="n">output_files</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_files</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">required_npartitions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_files</span><span class="p">)</span>
                <span class="n">files_per_task</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">files_per_task</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_files</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">out_files_per_proc</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot specify out_files_per_proc if output_files is &quot;</span>
                    <span class="s2">&quot;defined as a dictionary mapping. Please define each &quot;</span>
                    <span class="s2">&quot;key in output_files as a tuple of file names if you &quot;</span>
                    <span class="s2">&quot;wish to have those files written by the same process.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Repartition ddf if necessary</span>
            <span class="k">if</span> <span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span> <span class="o">&lt;</span> <span class="n">required_npartitions</span><span class="p">:</span>
                <span class="n">ddf</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">clear_divisions</span><span class="p">()</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">npartitions</span><span class="o">=</span><span class="n">required_npartitions</span><span class="p">)</span>

            <span class="c1"># Construct an output_files dictionary if necessary</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_files</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">output_files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;part_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">suffix</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">output_files</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_files</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">new</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">file_count</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">split</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_files</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_files</span><span class="p">),</span> <span class="n">files_per_task</span><span class="p">):</span>
                    <span class="n">fns</span> <span class="o">=</span> <span class="n">output_files</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">files_per_task</span><span class="p">]</span>
                    <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">split</span>
                    <span class="n">stop</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">split</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">fns</span><span class="p">),</span> <span class="n">ddf</span><span class="o">.</span><span class="n">npartitions</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="n">stop</span><span class="p">:</span>
                        <span class="n">new</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">fns</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span>
                        <span class="n">file_count</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fns</span><span class="p">)</span>
                <span class="c1"># let user know they will not have expected number of output files.</span>
                <span class="k">if</span> <span class="n">file_count</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_files</span><span class="p">):</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Only creating </span><span class="si">{</span><span class="n">file_count</span><span class="si">}</span><span class="s2"> files. Did not have enough &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;partitions to create </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">output_files</span><span class="p">)</span><span class="si">}</span><span class="s2"> files.&quot;</span>
                    <span class="p">)</span>
                <span class="n">output_files</span> <span class="o">=</span> <span class="n">new</span>
                <span class="n">suffix</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>  <span class="c1"># Don&#39;t add a suffix later - Names already include it</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_files</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">output_files</span><span class="p">)</span><span class="si">}</span><span class="s2"> not a supported type for `output_files`.&quot;</span><span class="p">)</span>

        <span class="c1"># If we are preserving files, use the stored dictionary,</span>
        <span class="c1"># or use file_partition_map to extract the mapping</span>
        <span class="k">elif</span> <span class="n">preserve_files</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_output_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_dataset</span><span class="o">.</span><span class="n">file_partition_map</span>
            <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`to_parquet(..., preserve_files=True)` is not currently supported &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;for datasets with a </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_dataset</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span><span class="si">}</span><span class="s2"> engine. Check &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;that `dataset.base_dataset` is backed by csv or parquet files.&quot;</span>
                <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
            <span class="k">if</span> <span class="n">suffix</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="n">output_files</span> <span class="o">=</span> <span class="n">_output_files</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_files</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">fn</span><span class="p">,</span> <span class="n">rgs</span> <span class="ow">in</span> <span class="n">_output_files</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">split_fn</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">split_fn</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;parquet&quot;</span><span class="p">,</span> <span class="s2">&quot;avro&quot;</span><span class="p">,</span> <span class="s2">&quot;orc&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">):</span>
                        <span class="n">output_files</span><span class="p">[</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">split_fn</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">]</span> <span class="o">=</span> <span class="n">rgs</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">output_files</span><span class="p">[</span><span class="n">fn</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">]</span> <span class="o">=</span> <span class="n">rgs</span>
            <span class="n">suffix</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>  <span class="c1"># Don&#39;t add a suffix later - Names already include it</span>

        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">dtypes</span><span class="p">:</span>
            <span class="n">_meta</span> <span class="o">=</span> <span class="n">_set_dtypes</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">_meta</span><span class="p">,</span> <span class="n">dtypes</span><span class="p">)</span>
            <span class="n">ddf</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">map_partitions</span><span class="p">(</span><span class="n">_set_dtypes</span><span class="p">,</span> <span class="n">dtypes</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="n">_meta</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">col_name</span><span class="p">,</span> <span class="n">col_dtype</span> <span class="ow">in</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">schema</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">schema</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span><span class="o">.</span><span class="n">with_dtype</span><span class="p">(</span><span class="n">col_dtype</span><span class="p">)</span>

        <span class="n">fs</span> <span class="o">=</span> <span class="n">get_fs_token_paths</span><span class="p">(</span><span class="n">output_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">fs</span><span class="o">.</span><span class="n">mkdirs</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">output_path</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">tf_metadata</span> <span class="o">=</span> <span class="n">TensorflowMetadata</span><span class="o">.</span><span class="n">from_merlin_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
        <span class="n">tf_metadata</span><span class="o">.</span><span class="n">to_proto_text_file</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>

        <span class="n">metadata_path</span> <span class="o">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">sep</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">output_path</span><span class="p">),</span> <span class="n">MERLIN_METADATA_DIR_NAME</span><span class="p">])</span>
        <span class="n">fs</span><span class="o">.</span><span class="n">mkdirs</span><span class="p">(</span><span class="n">metadata_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">tf_metadata</span><span class="o">.</span><span class="n">to_json_file</span><span class="p">(</span><span class="n">metadata_path</span><span class="p">)</span>

        <span class="c1"># Output dask_cudf DataFrame to dataset</span>
        <span class="n">_ddf_to_dataset</span><span class="p">(</span>
            <span class="n">ddf</span><span class="p">,</span>
            <span class="n">fs</span><span class="p">,</span>
            <span class="n">output_path</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="p">,</span>
            <span class="n">output_files</span><span class="p">,</span>
            <span class="n">out_files_per_proc</span><span class="p">,</span>
            <span class="n">cats</span> <span class="ow">or</span> <span class="p">[],</span>
            <span class="n">conts</span> <span class="ow">or</span> <span class="p">[],</span>
            <span class="n">labels</span> <span class="ow">or</span> <span class="p">[],</span>
            <span class="s2">&quot;parquet&quot;</span><span class="p">,</span>
            <span class="n">num_threads</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span>
            <span class="n">suffix</span><span class="o">=</span><span class="n">suffix</span><span class="p">,</span>
            <span class="n">row_group_size</span><span class="o">=</span><span class="n">row_group_size</span><span class="p">,</span>
            <span class="n">partition_on</span><span class="o">=</span><span class="n">partition_on</span><span class="p">,</span>
            <span class="n">schema</span><span class="o">=</span><span class="n">schema</span> <span class="k">if</span> <span class="n">write_hugectr_keyset</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_hugectr"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.to_hugectr">[docs]</a>    <span class="k">def</span> <span class="nf">to_hugectr</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output_path</span><span class="p">,</span>
        <span class="n">cats</span><span class="p">,</span>
        <span class="n">conts</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">file_partition_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_files_per_proc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_threads</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes out to a hugectr dataset</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        output_path : string</span>
<span class="sd">            Path to write processed/shuffled output data</span>
<span class="sd">        cats : list of str</span>
<span class="sd">            List of categorical columns</span>
<span class="sd">        conts : list of str</span>
<span class="sd">            List of continuous columns</span>
<span class="sd">        labels : list of str</span>
<span class="sd">            List of label columns</span>
<span class="sd">        shuffle : merlin.io.Shuffle, optional</span>
<span class="sd">            How to shuffle the output dataset. Shuffling is only</span>
<span class="sd">            performed if the data is written to disk. For all options,</span>
<span class="sd">            other than `None` (which means no shuffling), the partitions</span>
<span class="sd">            of the underlying dataset/ddf will be randomly ordered. If</span>
<span class="sd">            `PER_PARTITION` is specified, each worker/process will also</span>
<span class="sd">            shuffle the rows within each partition before splitting and</span>
<span class="sd">            appending the data to a number (`out_files_per_proc`) of output</span>
<span class="sd">            files. Output files are distinctly mapped to each worker process.</span>
<span class="sd">            If `PER_WORKER` is specified, each worker will follow the same</span>
<span class="sd">            procedure as `PER_PARTITION`, but will re-shuffle each file after</span>
<span class="sd">            all data is persisted.  This results in a full shuffle of the</span>
<span class="sd">            data processed by each worker.  To improve performance, this option</span>
<span class="sd">            currently uses host-memory `BytesIO` objects for the intermediate</span>
<span class="sd">            persist stage. The `FULL` option is not yet implemented.</span>
<span class="sd">        file_partition_map : dict</span>
<span class="sd">            Dictionary mapping of output file names to partition indices</span>
<span class="sd">            that should be written to that file name.  If this argument</span>
<span class="sd">            is passed, only the partitions included in the dictionary</span>
<span class="sd">            will be written to disk, and the `output_files_per_proc` argument</span>
<span class="sd">            will be ignored.</span>
<span class="sd">        out_files_per_proc : integer</span>
<span class="sd">            Number of files to create (per process) after</span>
<span class="sd">            shuffling the data</span>
<span class="sd">        num_threads : integer</span>
<span class="sd">            Number of IO threads to use for writing the output dataset.</span>
<span class="sd">            For `0` (default), no dedicated IO threads will be used.</span>
<span class="sd">        dtypes : dict</span>
<span class="sd">            Dictionary containing desired datatypes for output columns.</span>
<span class="sd">            Keys are column names, values are datatypes.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># For now, we must move to the GPU to</span>
        <span class="c1"># write an output dataset.</span>
        <span class="c1"># TODO: Support CPU-mode output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_gpu</span><span class="p">()</span>

        <span class="n">shuffle</span> <span class="o">=</span> <span class="n">_check_shuffle_arg</span><span class="p">(</span><span class="n">shuffle</span><span class="p">)</span>
        <span class="n">ddf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dtypes</span><span class="p">:</span>
            <span class="n">_meta</span> <span class="o">=</span> <span class="n">_set_dtypes</span><span class="p">(</span><span class="n">ddf</span><span class="o">.</span><span class="n">_meta</span><span class="p">,</span> <span class="n">dtypes</span><span class="p">)</span>
            <span class="n">ddf</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">map_partitions</span><span class="p">(</span><span class="n">_set_dtypes</span><span class="p">,</span> <span class="n">dtypes</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="n">_meta</span><span class="p">)</span>

        <span class="n">fs</span> <span class="o">=</span> <span class="n">get_fs_token_paths</span><span class="p">(</span><span class="n">output_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">fs</span><span class="o">.</span><span class="n">mkdirs</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>

        <span class="c1"># Output dask_cudf DataFrame to dataset,</span>
        <span class="n">_ddf_to_dataset</span><span class="p">(</span>
            <span class="n">ddf</span><span class="p">,</span>
            <span class="n">fs</span><span class="p">,</span>
            <span class="n">output_path</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="p">,</span>
            <span class="n">file_partition_map</span><span class="p">,</span>
            <span class="n">out_files_per_proc</span><span class="p">,</span>
            <span class="n">cats</span><span class="p">,</span>
            <span class="n">conts</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">,</span>
            <span class="s2">&quot;hugectr&quot;</span><span class="p">,</span>
            <span class="n">num_threads</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">,</span>
            <span class="n">schema</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.to_npy"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.to_npy">[docs]</a>    <span class="k">def</span> <span class="nf">to_npy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">append</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a dataset into an npy file, can append if data is larger than memory</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        output_file : str</span>
<span class="sd">            The output file path for the resulting npy file</span>
<span class="sd">        append : bool, optional</span>
<span class="sd">            Enables append mode for larger that memory data, by default False</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">append</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">itr</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">to_iter</span><span class="p">())</span>
            <span class="k">with</span> <span class="n">NpyAppendArray</span><span class="p">(</span><span class="n">output_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">nf</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">itr</span><span class="p">:</span>
                    <span class="n">to_write</span> <span class="o">=</span> <span class="n">dataframe_columnwise_explode</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
                    <span class="c1"># after the explode there may not be object series anymore</span>
                    <span class="k">if</span> <span class="s2">&quot;object&quot;</span> <span class="ow">in</span> <span class="n">to_write</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">values</span> <span class="ow">and</span> <span class="n">append</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Cannot append object columns&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">to_write</span><span class="o">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot convert data because null values were detected&quot;</span><span class="p">)</span>
                    <span class="n">nf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">to_write</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">to_write</span> <span class="o">=</span> <span class="n">dataframe_columnwise_explode</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">compute</span><span class="p">())</span>
            <span class="k">if</span> <span class="s2">&quot;object&quot;</span> <span class="ow">in</span> <span class="n">to_write</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">values</span> <span class="ow">and</span> <span class="n">append</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Cannot append object columns&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">to_write</span><span class="o">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot convert data because null values were detected&quot;</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="n">to_write</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">num_rows</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">npartitions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">npartitions</span>

<div class="viewcode-block" id="Dataset.validate_dataset"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.validate_dataset">[docs]</a>    <span class="k">def</span> <span class="nf">validate_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate for efficient processing.</span>

<span class="sd">        The purpose of this method is to validate that the Dataset object</span>
<span class="sd">        meets the minimal requirements for efficient NVTabular processing.</span>
<span class="sd">        For now, this criteria requires the data to be in parquet format.</span>

<span class="sd">        Example Usage::</span>

<span class="sd">            dataset = Dataset(&quot;/path/to/data_pq&quot;, engine=&quot;parquet&quot;)</span>
<span class="sd">            assert validate_dataset(dataset)</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        **kwargs :</span>
<span class="sd">            Key-word arguments to pass down to the engine&#39;s validate_dataset</span>
<span class="sd">            method. For the recommended parquet format, these arguments</span>
<span class="sd">            include `add_metadata_file`, `row_group_max_size`, `file_min_size`,</span>
<span class="sd">            and `require_metadata_file`. For more information, see</span>
<span class="sd">            `ParquetDatasetEngine.validate_dataset`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        valid : bool</span>
<span class="sd">            `True` if the input dataset is valid for efficient NVTabular</span>
<span class="sd">            processing.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check that the dataset format is Parquet</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">,</span> <span class="n">ParquetDatasetEngine</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;NVTabular is optimized for the parquet format. Please use &quot;</span>
                <span class="s2">&quot;the to_parquet method to convert your dataset.&quot;</span>
            <span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Early return</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">validate_dataset</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.regenerate_dataset"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.regenerate_dataset">[docs]</a>    <span class="k">def</span> <span class="nf">regenerate_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output_path</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span><span class="p">,</span>
        <span class="n">compute</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;EXPERIMENTAL:</span>
<span class="sd">        Regenerate an NVTabular Dataset for efficient processing by writing</span>
<span class="sd">        out new Parquet files. In contrast to default ``to_parquet`` behavior,</span>
<span class="sd">        this method preserves the original ordering.</span>

<span class="sd">        Example Usage::</span>

<span class="sd">            dataset = Dataset(&quot;/path/to/data_pq&quot;, engine=&quot;parquet&quot;)</span>
<span class="sd">            dataset.regenerate_dataset(</span>
<span class="sd">                out_path, part_size=&quot;1MiB&quot;, file_size=&quot;10MiB&quot;</span>
<span class="sd">            )</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        output_path : string</span>
<span class="sd">            Root directory path to use for the new (regenerated) dataset.</span>
<span class="sd">        columns : list(string), optional</span>
<span class="sd">            Subset of columns to include in the regenerated dataset.</span>
<span class="sd">        output_format : string, optional</span>
<span class="sd">            Format to use for regenerated dataset.  Only &quot;parquet&quot; (default)</span>
<span class="sd">            is currently supported.</span>
<span class="sd">        compute : bool, optional</span>
<span class="sd">            Whether to compute the task graph or to return a Delayed object.</span>
<span class="sd">            By default, the graph will be executed.</span>
<span class="sd">        **kwargs :</span>
<span class="sd">            Key-word arguments to pass down to the engine&#39;s regenerate_dataset</span>
<span class="sd">            method. See `ParquetDatasetEngine.regenerate_dataset` for more</span>
<span class="sd">            information.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        result : int or Delayed</span>
<span class="sd">            If `compute=True` (default), the return value will be an integer</span>
<span class="sd">            corresponding to the number of generated data files.  If `False`,</span>
<span class="sd">            the returned value will be a `Delayed` object.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check that the desired output format is Parquet</span>
        <span class="k">if</span> <span class="n">output_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;parquet&quot;</span><span class="p">]:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;NVTabular is optimized for the parquet format. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_format</span><span class="si">}</span><span class="s2"> is not yet a supported output format for &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;regenerate_dataset.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">ParquetDatasetEngine</span><span class="o">.</span><span class="n">regenerate_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_path</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">compute</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="Dataset.infer_schema"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.infer_schema">[docs]</a>    <span class="k">def</span> <span class="nf">infer_schema</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a schema containing the column names and inferred dtypes of the Dataset</span>

<span class="sd">        Args:</span>
<span class="sd">            n (int, optional): Number of rows to sample to infer the dtypes. Defaults to 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">dtypes</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">dtypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_dtypes</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">annotate_lists</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">column_schemas</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">column</span><span class="p">,</span> <span class="n">dtype_info</span> <span class="ow">in</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">dtype_val</span> <span class="o">=</span> <span class="n">dtype_info</span><span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">]</span>

            <span class="n">dims</span> <span class="o">=</span> <span class="n">DefaultShapes</span><span class="o">.</span><span class="n">LIST</span> <span class="k">if</span> <span class="n">dtype_info</span><span class="p">[</span><span class="s2">&quot;is_list&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="n">DefaultShapes</span><span class="o">.</span><span class="n">SCALAR</span>
            <span class="n">col_schema</span> <span class="o">=</span> <span class="n">ColumnSchema</span><span class="p">(</span><span class="n">column</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_val</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">)</span>

            <span class="n">column_schemas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">col_schema</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">(</span><span class="n">column_schemas</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span></div>

<div class="viewcode-block" id="Dataset.sample_dtypes"><a class="viewcode-back" href="../../../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset.sample_dtypes">[docs]</a>    <span class="k">def</span> <span class="nf">sample_dtypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">annotate_lists</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the real dtypes of the Dataset</span>

<span class="sd">        Use cached metadata if this operation was</span>
<span class="sd">        already performed. Otherwise, call down to the</span>
<span class="sd">        underlying engine for sampling logic.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_real_meta</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_real_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">sample_data</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">:</span>
                <span class="n">_real_meta</span> <span class="o">=</span> <span class="n">_set_dtypes</span><span class="p">(</span><span class="n">_real_meta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_real_meta</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">_real_meta</span>

        <span class="k">if</span> <span class="n">annotate_lists</span><span class="p">:</span>
            <span class="n">_real_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_real_meta</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
            <span class="n">annotated</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">_real_meta</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="n">is_list</span> <span class="o">=</span> <span class="n">is_list_dtype</span><span class="p">(</span><span class="n">_real_meta</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">list_val_dtype</span><span class="p">(</span><span class="n">_real_meta</span><span class="p">[</span><span class="n">col</span><span class="p">])</span> <span class="k">if</span> <span class="n">is_list</span> <span class="k">else</span> <span class="n">_real_meta</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
                <span class="n">annotated</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;is_list&quot;</span><span class="p">:</span> <span class="n">is_list</span><span class="p">}</span>

            <span class="k">return</span> <span class="n">annotated</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_real_meta</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_bind_dd_method</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Bind Dask-Dataframe method to the Dataset class&quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">meth</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">_meth</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">(),</span> <span class="n">name</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">_meth</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">meth</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">name</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">meth</span><span class="p">)</span></div>


<span class="c1"># Bind (simple) Dask-Dataframe Methods</span>
<span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;compute&quot;</span><span class="p">,</span> <span class="s2">&quot;persist&quot;</span><span class="p">,</span> <span class="s2">&quot;head&quot;</span><span class="p">,</span> <span class="s2">&quot;tail&quot;</span><span class="p">]:</span>
    <span class="n">Dataset</span><span class="o">.</span><span class="n">_bind_dd_method</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_set_dtypes</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">dtypes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s2">&quot;hex&quot;</span> <span class="ow">in</span> <span class="n">dtype</span><span class="p">):</span>
            <span class="n">chunk</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">hex_to_int</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chunk</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">chunk</span>
</pre></div>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 2023, NVIDIA.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>