<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>merlin.models.tf.models.retrieval &mdash; Merlin  documentation</title><link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/_modules/merlin/models/tf/models/retrieval.html" />
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../../../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            Merlin
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../guide/recommender_system_guide.html">Recommender System Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api_overview.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../support_matrix/index.html">Merlin Support Matrix</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">Merlin</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">merlin.models.tf.models.retrieval</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for merlin.models.tf.models.retrieval</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">merlin.models.tf.blocks.mlp</span> <span class="kn">import</span> <span class="n">MLPBlock</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.blocks.retrieval.matrix_factorization</span> <span class="kn">import</span> <span class="n">QueryItemIdsEmbeddingsBlock</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.blocks.retrieval.two_tower</span> <span class="kn">import</span> <span class="n">TwoTowerBlock</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.blocks.sampling.base</span> <span class="kn">import</span> <span class="n">ItemSampler</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.core.base</span> <span class="kn">import</span> <span class="n">Block</span><span class="p">,</span> <span class="n">BlockType</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.core.combinators</span> <span class="kn">import</span> <span class="n">ParallelBlock</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.core.encoder</span> <span class="kn">import</span> <span class="n">EmbeddingEncoder</span><span class="p">,</span> <span class="n">Encoder</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.inputs.base</span> <span class="kn">import</span> <span class="n">InputBlock</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.inputs.embedding</span> <span class="kn">import</span> <span class="n">EmbeddingOptions</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.models.base</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">RetrievalModel</span><span class="p">,</span> <span class="n">RetrievalModelV2</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.models.utils</span> <span class="kn">import</span> <span class="n">parse_prediction_tasks</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.outputs.base</span> <span class="kn">import</span> <span class="n">DotProduct</span><span class="p">,</span> <span class="n">ModelOutput</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.outputs.contrastive</span> <span class="kn">import</span> <span class="n">ContrastiveOutput</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.outputs.sampling.base</span> <span class="kn">import</span> <span class="n">ItemSamplersType</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.outputs.sampling.popularity</span> <span class="kn">import</span> <span class="n">PopularityBasedSamplerV2</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.prediction_tasks.base</span> <span class="kn">import</span> <span class="n">ParallelPredictionBlock</span><span class="p">,</span> <span class="n">PredictionTask</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.prediction_tasks.next_item</span> <span class="kn">import</span> <span class="n">NextItemPredictionTask</span>
<span class="kn">from</span> <span class="nn">merlin.models.tf.prediction_tasks.retrieval</span> <span class="kn">import</span> <span class="n">ItemRetrievalTask</span>
<span class="kn">from</span> <span class="nn">merlin.models.utils.schema_utils</span> <span class="kn">import</span> <span class="n">categorical_cardinalities</span>
<span class="kn">from</span> <span class="nn">merlin.schema</span> <span class="kn">import</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">Tags</span>


<div class="viewcode-block" id="MatrixFactorizationModel"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.MatrixFactorizationModel.html#merlin.models.tf.MatrixFactorizationModel">[docs]</a><span class="k">def</span> <span class="nf">MatrixFactorizationModel</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">query_id_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">USER_ID</span><span class="p">,</span>
    <span class="n">item_id_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">ITEM_ID</span><span class="p">,</span>
    <span class="n">embeddings_initializers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings_l2_reg</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">post</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BlockType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prediction_tasks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">PredictionTask</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionTask</span><span class="p">],</span> <span class="n">ParallelPredictionBlock</span><span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logits_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">samplers</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ItemSampler</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RetrievalModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds a matrix factorization model.</span>

<span class="sd">    Example Usage::</span>
<span class="sd">        mf = MatrixFactorizationModel(schema, dim=128)</span>
<span class="sd">        mf.compile(optimizer=&quot;adam&quot;)</span>
<span class="sd">        mf.fit(train_data, epochs=10)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    schema: Schema</span>
<span class="sd">        The `Schema` with the input features</span>
<span class="sd">    dim: int</span>
<span class="sd">        The dimension of the embeddings.</span>
<span class="sd">    query_id_tag : Tag</span>
<span class="sd">        The tag to select query features, by default `Tags.USER`</span>
<span class="sd">    item_id_tag : Tag</span>
<span class="sd">        The tag to select item features, by default `Tags.ITEM`</span>
<span class="sd">    embeddings_initializers : Optional[Dict[str, Callable[[Any], None]]] = None</span>
<span class="sd">        An initializer function or a dict where keys are feature names and values are</span>
<span class="sd">        callable to initialize embedding tables</span>
<span class="sd">    embeddings_l2_reg: float = 0.0</span>
<span class="sd">        Factor for L2 regularization of the embeddings vectors (from the current batch only)</span>
<span class="sd">    post: Optional[Block], optional</span>
<span class="sd">        The optional `Block` to apply on both outputs of Two-tower model</span>
<span class="sd">    prediction_tasks: optional</span>
<span class="sd">        The optional `PredictionTask` or list of `PredictionTask` to apply on the model.</span>
<span class="sd">    logits_temperature: float</span>
<span class="sd">        Parameter used to reduce model overconfidence, so that logits / T.</span>
<span class="sd">        Defaults to 1.</span>
<span class="sd">    samplers: List[ItemSampler]</span>
<span class="sd">        List of samplers for negative sampling, by default `[InBatchSampler()]`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    RetrievalModel</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">prediction_tasks</span><span class="p">:</span>
        <span class="n">prediction_tasks</span> <span class="o">=</span> <span class="n">ItemRetrievalTask</span><span class="p">(</span>
            <span class="n">schema</span><span class="p">,</span>
            <span class="n">logits_temperature</span><span class="o">=</span><span class="n">logits_temperature</span><span class="p">,</span>
            <span class="n">samplers</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">samplers</span><span class="p">),</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">prediction_tasks</span> <span class="o">=</span> <span class="n">parse_prediction_tasks</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">prediction_tasks</span><span class="p">)</span>
    <span class="n">mf</span> <span class="o">=</span> <span class="n">QueryItemIdsEmbeddingsBlock</span><span class="p">(</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
        <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
        <span class="n">query_id_tag</span><span class="o">=</span><span class="n">query_id_tag</span><span class="p">,</span>
        <span class="n">item_id_tag</span><span class="o">=</span><span class="n">item_id_tag</span><span class="p">,</span>
        <span class="n">embeddings_initializers</span><span class="o">=</span><span class="n">embeddings_initializers</span><span class="p">,</span>
        <span class="n">embeddings_l2_reg</span><span class="o">=</span><span class="n">embeddings_l2_reg</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">RetrievalModel</span><span class="p">(</span><span class="n">mf</span><span class="p">,</span> <span class="n">prediction_tasks</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span></div>


<div class="viewcode-block" id="TwoTowerModel"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.TwoTowerModel.html#merlin.models.tf.TwoTowerModel">[docs]</a><span class="k">def</span> <span class="nf">TwoTowerModel</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span>
    <span class="n">query_tower</span><span class="p">:</span> <span class="n">Block</span><span class="p">,</span>
    <span class="n">item_tower</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Block</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">query_tower_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">USER</span><span class="p">,</span>
    <span class="n">item_tower_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">ITEM</span><span class="p">,</span>
    <span class="n">embedding_options</span><span class="p">:</span> <span class="n">EmbeddingOptions</span> <span class="o">=</span> <span class="n">EmbeddingOptions</span><span class="p">(</span>
        <span class="n">embedding_dims</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding_dim_default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">infer_embedding_sizes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">infer_embedding_sizes_multiplier</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">post</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BlockType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prediction_tasks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">PredictionTask</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionTask</span><span class="p">],</span> <span class="n">ParallelPredictionBlock</span><span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logits_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">samplers</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ItemSampler</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RetrievalModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds the Two-tower architecture, as proposed in [1].</span>

<span class="sd">    Example Usage::</span>
<span class="sd">        two_tower = TwoTowerModel(schema, MLPBlock([256, 64]))</span>
<span class="sd">        two_tower.compile(optimizer=&quot;adam&quot;)</span>
<span class="sd">        two_tower.fit(train_data, epochs=10)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Yi, Xinyang, et al.</span>
<span class="sd">        &quot;Sampling-bias-corrected neural modeling for large corpus item recommendations.&quot;</span>
<span class="sd">        Proceedings of the 13th ACM Conference on Recommender Systems. 2019.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    schema: Schema</span>
<span class="sd">        The `Schema` with the input features</span>
<span class="sd">    query_tower: Block</span>
<span class="sd">        The `Block` that combines user features</span>
<span class="sd">    item_tower: Optional[Block], optional</span>
<span class="sd">        The optional `Block` that combines items features.</span>
<span class="sd">        If not provided, a copy of the query_tower is used.</span>
<span class="sd">    query_tower_tag: Tag</span>
<span class="sd">        The tag to select query features, by default `Tags.USER`</span>
<span class="sd">    item_tower_tag: Tag</span>
<span class="sd">        The tag to select item features, by default `Tags.ITEM`</span>
<span class="sd">    embedding_options : EmbeddingOptions</span>
<span class="sd">        Options for the input embeddings.</span>
<span class="sd">        - embedding_dims: Optional[Dict[str, int]] - The dimension of the</span>
<span class="sd">        embedding table for each feature (key), by default {}</span>
<span class="sd">        - embedding_dim_default: int - Default dimension of the embedding</span>
<span class="sd">        table, when the feature is not found in ``embedding_dims``, by default 64</span>
<span class="sd">        - infer_embedding_sizes : bool, Automatically defines the embedding</span>
<span class="sd">        dimension from the feature cardinality in the schema, by default False</span>
<span class="sd">        - infer_embedding_sizes_multiplier: int. Multiplier used by the heuristic</span>
<span class="sd">        to infer the embedding dimension from its cardinality. Generally</span>
<span class="sd">        reasonable values range between 2.0 and 10.0. By default 2.0.</span>
<span class="sd">    post: Optional[Block], optional</span>
<span class="sd">        The optional `Block` to apply on both outputs of Two-tower model</span>
<span class="sd">    prediction_tasks: optional</span>
<span class="sd">        The optional `PredictionTask` or list of `PredictionTask` to apply on the model.</span>
<span class="sd">    logits_temperature: float</span>
<span class="sd">        Parameter used to reduce model overconfidence, so that logits / T.</span>
<span class="sd">        Defaults to 1.</span>
<span class="sd">    loss: Optional[LossType]</span>
<span class="sd">        Loss function.</span>
<span class="sd">        Defaults to `categorical_crossentropy`.</span>
<span class="sd">    samplers: List[ItemSampler]</span>
<span class="sd">        List of samplers for negative sampling, by default `[InBatchSampler()]`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    RetrievalModel</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">prediction_tasks</span><span class="p">:</span>
        <span class="n">prediction_tasks</span> <span class="o">=</span> <span class="n">ItemRetrievalTask</span><span class="p">(</span>
            <span class="n">schema</span><span class="p">,</span>
            <span class="n">logits_temperature</span><span class="o">=</span><span class="n">logits_temperature</span><span class="p">,</span>
            <span class="n">samplers</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">samplers</span><span class="p">),</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">prediction_tasks</span> <span class="o">=</span> <span class="n">parse_prediction_tasks</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">prediction_tasks</span><span class="p">)</span>
    <span class="n">two_tower</span> <span class="o">=</span> <span class="n">TwoTowerBlock</span><span class="p">(</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
        <span class="n">query_tower</span><span class="o">=</span><span class="n">query_tower</span><span class="p">,</span>
        <span class="n">item_tower</span><span class="o">=</span><span class="n">item_tower</span><span class="p">,</span>
        <span class="n">query_tower_tag</span><span class="o">=</span><span class="n">query_tower_tag</span><span class="p">,</span>
        <span class="n">item_tower_tag</span><span class="o">=</span><span class="n">item_tower_tag</span><span class="p">,</span>
        <span class="n">embedding_options</span><span class="o">=</span><span class="n">embedding_options</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">RetrievalModel</span><span class="p">(</span><span class="n">two_tower</span><span class="p">,</span> <span class="n">prediction_tasks</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span></div>


<div class="viewcode-block" id="YoutubeDNNRetrievalModel"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.YoutubeDNNRetrievalModel.html#merlin.models.tf.YoutubeDNNRetrievalModel">[docs]</a><span class="k">def</span> <span class="nf">YoutubeDNNRetrievalModel</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;concat&quot;</span><span class="p">,</span>
    <span class="n">top_block</span><span class="p">:</span> <span class="n">Block</span> <span class="o">=</span> <span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]),</span>
    <span class="n">l2_normalization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">extra_pre_call</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Block</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_block</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Block</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logits_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">sampled_softmax</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">num_sampled</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">min_sampled_id</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">embedding_options</span><span class="p">:</span> <span class="n">EmbeddingOptions</span> <span class="o">=</span> <span class="n">EmbeddingOptions</span><span class="p">(</span>
        <span class="n">embedding_dims</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding_dim_default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">infer_embedding_sizes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">infer_embedding_sizes_multiplier</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build the Youtube-DNN retrieval model.</span>
<span class="sd">    More details of the architecture can be found in [1]_.</span>
<span class="sd">    The sampled_softmax is enabled by default [2]_ [3]_ [4]_.</span>

<span class="sd">    Example Usage::</span>
<span class="sd">        model = YoutubeDNNRetrievalModel(schema, num_sampled=100)</span>
<span class="sd">        model.compile(optimizer=&quot;adam&quot;)</span>
<span class="sd">        model.fit(train_data, epochs=10)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Covington, Paul, Jay Adams, and Emre Sargin.</span>
<span class="sd">        &quot;Deep neural networks for youtube recommendations.&quot;</span>
<span class="sd">        Proceedings of the 10th ACM conference on recommender systems. 2016.</span>

<span class="sd">    .. [2] Yoshua Bengio and Jean-Sébastien Sénécal. 2003. Quick Training of Probabilistic</span>
<span class="sd">       Neural Nets by Importance Sampling. In Proceedings of the conference on Artificial</span>
<span class="sd">       Intelligence and Statistics (AISTATS).</span>

<span class="sd">    .. [3] Y. Bengio and J. S. Senecal. 2008. Adaptive Importance Sampling to Accelerate</span>
<span class="sd">       Training of a Neural Probabilistic Language Model. Trans. Neur. Netw. 19, 4 (April</span>
<span class="sd">       2008), 713–722. https://doi.org/10.1109/TNN.2007.912312</span>

<span class="sd">    .. [4] Jean, Sébastien, et al. &quot;On using very large target vocabulary for neural</span>
<span class="sd">        machine translation.&quot; arXiv preprint arXiv:1412.2007 (2014).</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    schema: Schema</span>
<span class="sd">        The `Schema` with the input features</span>
<span class="sd">    aggregation: str</span>
<span class="sd">        The aggregation method to use for the sequence of features.</span>
<span class="sd">        Defaults to `concat`.</span>
<span class="sd">    top_block: Block</span>
<span class="sd">        The `Block` that combines the top features</span>
<span class="sd">    l2_normalization: bool</span>
<span class="sd">        Whether to apply L2 normalization before computing dot interactions.</span>
<span class="sd">        Defaults to True.</span>
<span class="sd">    extra_pre_call: Optional[Block]</span>
<span class="sd">        The optional `Block` to apply before the model.</span>
<span class="sd">    task_block: Optional[Block]</span>
<span class="sd">        The optional `Block` to apply on the model.</span>
<span class="sd">    logits_temperature: float</span>
<span class="sd">        Parameter used to reduce model overconfidence, so that logits / T.</span>
<span class="sd">        Defaults to 1.</span>
<span class="sd">    sampled_softmax: bool</span>
<span class="sd">        Compute the logits scores over all items of the catalog or</span>
<span class="sd">        generate a subset of candidates</span>
<span class="sd">        Defaults to False</span>
<span class="sd">    num_sampled: int</span>
<span class="sd">        When sampled_softmax is enabled, specify the number of</span>
<span class="sd">        negative candidates to generate for each batch.</span>
<span class="sd">        Defaults to 100</span>
<span class="sd">    min_sampled_id: int</span>
<span class="sd">        The minimum id value to be sampled with sampled softmax.</span>
<span class="sd">        Useful to ignore the first categorical</span>
<span class="sd">        encoded ids, which are usually reserved for &lt;nulls&gt;,</span>
<span class="sd">        out-of-vocabulary or padding. Defaults to 0.</span>
<span class="sd">    embedding_options : EmbeddingOptions, optional</span>
<span class="sd">        An EmbeddingOptions instance, which allows for a number of</span>
<span class="sd">        options for the embedding table, by default EmbeddingOptions()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">InputBlock</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">aggregation</span><span class="o">=</span><span class="n">aggregation</span><span class="p">,</span>
        <span class="n">embedding_options</span><span class="o">=</span><span class="n">embedding_options</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">task</span> <span class="o">=</span> <span class="n">NextItemPredictionTask</span><span class="p">(</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
        <span class="n">weight_tying</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">extra_pre_call</span><span class="o">=</span><span class="n">extra_pre_call</span><span class="p">,</span>
        <span class="n">task_block</span><span class="o">=</span><span class="n">task_block</span><span class="p">,</span>
        <span class="n">logits_temperature</span><span class="o">=</span><span class="n">logits_temperature</span><span class="p">,</span>
        <span class="n">l2_normalization</span><span class="o">=</span><span class="n">l2_normalization</span><span class="p">,</span>
        <span class="n">sampled_softmax</span><span class="o">=</span><span class="n">sampled_softmax</span><span class="p">,</span>
        <span class="n">num_sampled</span><span class="o">=</span><span class="n">num_sampled</span><span class="p">,</span>
        <span class="n">min_sampled_id</span><span class="o">=</span><span class="n">min_sampled_id</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># TODO: Figure out how to make this fit as</span>
    <span class="c1"># a RetrievalModel (which must have a RetrievalBlock)</span>
    <span class="k">return</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">top_block</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span></div>


<div class="viewcode-block" id="MatrixFactorizationModelV2"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.MatrixFactorizationModelV2.html#merlin.models.tf.MatrixFactorizationModelV2">[docs]</a><span class="k">def</span> <span class="nf">MatrixFactorizationModelV2</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">query_id_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">USER_ID</span><span class="p">,</span>
    <span class="n">candidate_id_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">ITEM_ID</span><span class="p">,</span>
    <span class="n">embeddings_initializers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">embeddings_l2_batch_regularization</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">post</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BlockType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">ModelOutput</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ModelOutput</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">negative_samplers</span><span class="p">:</span> <span class="n">ItemSamplersType</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logits_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RetrievalModelV2</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds a matrix factorization (MF) model.</span>

<span class="sd">    Example Usage::</span>
<span class="sd">        mf = MatrixFactorizationModelV2(schema, dim=128)</span>
<span class="sd">        mf.compile(optimizer=&quot;adam&quot;)</span>
<span class="sd">        mf.fit(train_data, epochs=10)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    schema: Schema</span>
<span class="sd">        The `Schema` with the input features</span>
<span class="sd">    dim: int</span>
<span class="sd">        The dimension of the embeddings.</span>
<span class="sd">    query_id_tag : Tag</span>
<span class="sd">        The tag to select query-id feature, by default `Tags.USER_ID`</span>
<span class="sd">    candidate_id_tag : Tag</span>
<span class="sd">        The tag to select candidate-id feature, by default `Tags.ITEM_ID`</span>
<span class="sd">    embeddings_initializers : Optional[Dict[str, Callable[[Any], None]]] = None</span>
<span class="sd">        An initializer function or a dict where keys are feature names and values are</span>
<span class="sd">        callable to initialize embedding tables</span>
<span class="sd">    embeddings_l2_batch_regularization: Union[float, Dict[str, float]] = 0.0</span>
<span class="sd">        Factor for L2 regularization of the embeddings vectors (from the current batch only)</span>
<span class="sd">        If a dictionary is provided, the keys are the query-id and candidate-id names and</span>
<span class="sd">        the values are the regularization factor.</span>
<span class="sd">    post: Optional[Block], optional</span>
<span class="sd">        The optional `Block` to apply on both outputs of the MF towers.</span>
<span class="sd">    outputs: optional</span>
<span class="sd">        The optional `ModelOutput` or list of `ModelOutput` to apply on the MF model.</span>
<span class="sd">    negative_samplers: List[ItemSampler]</span>
<span class="sd">        List of samplers for negative sampling, by default None</span>
<span class="sd">        If the `outputs` and `negative_samplers` are not specified the Matrix Factorization model</span>
<span class="sd">        is trained with contrastive learning and `in-batch` negative sampling strategy.</span>
<span class="sd">    logits_temperature: float</span>
<span class="sd">        Parameter used to reduce model overconfidence, so that logits / T.</span>
<span class="sd">        Defaults to 1.</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    RetrievalModelV2</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">query</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">query_id_tag</span><span class="p">)</span>
    <span class="n">candidate</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">candidate_id_tag</span><span class="p">)</span>

    <span class="n">query_encoder</span> <span class="o">=</span> <span class="n">EmbeddingEncoder</span><span class="p">(</span>
        <span class="n">query</span><span class="p">,</span>
        <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
        <span class="n">embeddings_initializer</span><span class="o">=</span><span class="n">embeddings_initializers</span><span class="p">,</span>
        <span class="n">embeddings_l2_batch_regularization</span><span class="o">=</span><span class="n">embeddings_l2_batch_regularization</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">candidate_encoder</span> <span class="o">=</span> <span class="n">EmbeddingEncoder</span><span class="p">(</span>
        <span class="n">candidate</span><span class="p">,</span>
        <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
        <span class="n">embeddings_initializer</span><span class="o">=</span><span class="n">embeddings_initializers</span><span class="p">,</span>
        <span class="n">embeddings_l2_batch_regularization</span><span class="o">=</span><span class="n">embeddings_l2_batch_regularization</span><span class="p">,</span>
        <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">outputs</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">negative_samplers</span><span class="p">:</span>
            <span class="n">negative_samplers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;in-batch&quot;</span><span class="p">]</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">ContrastiveOutput</span><span class="p">(</span>
            <span class="n">to_call</span><span class="o">=</span><span class="n">DotProduct</span><span class="p">(),</span>
            <span class="n">negative_samplers</span><span class="o">=</span><span class="n">negative_samplers</span><span class="p">,</span>
            <span class="n">logits_temperature</span><span class="o">=</span><span class="n">logits_temperature</span><span class="p">,</span>
            <span class="n">schema</span><span class="o">=</span><span class="n">candidate</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">ParallelBlock</span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">RetrievalModelV2</span><span class="p">(</span>
        <span class="n">query</span><span class="o">=</span><span class="n">query_encoder</span><span class="p">,</span>
        <span class="n">candidate</span><span class="o">=</span><span class="n">candidate_encoder</span><span class="p">,</span>
        <span class="n">output</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span></div>


<div class="viewcode-block" id="TwoTowerModelV2"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.TwoTowerModelV2.html#merlin.models.tf.TwoTowerModelV2">[docs]</a><span class="k">def</span> <span class="nf">TwoTowerModelV2</span><span class="p">(</span>
    <span class="n">query_tower</span><span class="p">:</span> <span class="n">Encoder</span><span class="p">,</span>
    <span class="n">candidate_tower</span><span class="p">:</span> <span class="n">Encoder</span><span class="p">,</span>
    <span class="n">candidate_id_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">ITEM_ID</span><span class="p">,</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">ModelOutput</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ModelOutput</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logits_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">negative_samplers</span><span class="p">:</span> <span class="n">ItemSamplersType</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RetrievalModelV2</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds the Two-tower architecture, as proposed in [1].</span>

<span class="sd">    Example Usage::</span>
<span class="sd">        query = mm.Encoder(user_schema, mm.MLPBlock([128]))</span>
<span class="sd">        candidate = mm.Encoder(item_schema, mm.MLPBlock([128]))</span>
<span class="sd">        model = TwoTowerModel(query, candidate)</span>
<span class="sd">        two_tower.compile(optimizer=&quot;adam&quot;)</span>
<span class="sd">        two_tower.fit(train_data, epochs=10)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Yi, Xinyang, et al.</span>
<span class="sd">        &quot;Sampling-bias-corrected neural modeling for large corpus item recommendations.&quot;</span>
<span class="sd">        Proceedings of the 13th ACM Conference on Recommender Systems. 2019.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    query_tower: Encoder</span>
<span class="sd">        The layer that encodes query features</span>
<span class="sd">    candidate_tower: Encoder</span>
<span class="sd">        The  layer that encodes candidates features</span>
<span class="sd">    candidate_id_tag: Tag, optional</span>
<span class="sd">        The tag to select candidate-id feature, by default `Tags.ITEM_ID`</span>
<span class="sd">    outputs:  Union[ModelOutput, List[ModelOutput]], optional</span>
<span class="sd">        The optional `ModelOutput` or list of `ModelOutput` to apply on the model.</span>
<span class="sd">    logits_temperature: float</span>
<span class="sd">        Parameter used to reduce model overconfidence, so that logits / T.</span>
<span class="sd">        Defaults to 1.</span>
<span class="sd">    negative_samplers: List[ItemSampler]</span>
<span class="sd">        List of samplers for negative sampling, by default None</span>
<span class="sd">        If the `outputs` and `negative_samplers` are not specified the two tower model</span>
<span class="sd">        is trained with contrastive learning and `in-batch` negative sampling strategy.</span>
<span class="sd">    schema: Schema</span>
<span class="sd">        A schema with all input features fed to the two-tower model.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    RetrievalModelV2</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">query_tower</span><span class="p">,</span> <span class="n">Encoder</span><span class="p">),</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;The query tower should be an instance of `Encoder` class&quot;</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">candidate_tower</span><span class="p">,</span> <span class="n">Encoder</span><span class="p">),</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;The query tower should be an instance of `Encoder` class&quot;</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">outputs</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">negative_samplers</span><span class="p">:</span>
            <span class="n">negative_samplers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;in-batch&quot;</span><span class="p">]</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">ContrastiveOutput</span><span class="p">(</span>
            <span class="n">to_call</span><span class="o">=</span><span class="n">DotProduct</span><span class="p">(),</span>
            <span class="n">negative_samplers</span><span class="o">=</span><span class="n">negative_samplers</span><span class="p">,</span>
            <span class="n">logits_temperature</span><span class="o">=</span><span class="n">logits_temperature</span><span class="p">,</span>
            <span class="n">schema</span><span class="o">=</span><span class="n">candidate_tower</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">candidate_id_tag</span><span class="p">),</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">ParallelBlock</span><span class="p">(</span><span class="o">*</span><span class="n">outputs</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">RetrievalModelV2</span><span class="p">(</span>
        <span class="n">query</span><span class="o">=</span><span class="n">query_tower</span><span class="p">,</span>
        <span class="n">candidate</span><span class="o">=</span><span class="n">candidate_tower</span><span class="p">,</span>
        <span class="n">output</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span></div>


<div class="viewcode-block" id="YoutubeDNNRetrievalModelV2"><a class="viewcode-back" href="../../../../../generated/merlin.models.tf.YoutubeDNNRetrievalModelV2.html#merlin.models.tf.YoutubeDNNRetrievalModelV2">[docs]</a><span class="k">def</span> <span class="nf">YoutubeDNNRetrievalModelV2</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">:</span> <span class="n">Schema</span><span class="p">,</span>
    <span class="n">candidate_id_tag</span><span class="o">=</span><span class="n">Tags</span><span class="o">.</span><span class="n">ITEM_ID</span><span class="p">,</span>
    <span class="n">top_block</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">]</span> <span class="o">=</span> <span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]),</span>
    <span class="n">post</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">ModelOutput</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ModelOutput</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logits_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">num_sampled</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">min_sampled_id</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RetrievalModelV2</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build the Youtube-DNN retrieval model.</span>
<span class="sd">    More details of the architecture can be found in [1]_.</span>
<span class="sd">    Training with sampled_softmax is enabled by default [2]_ [3]_ [4]_.</span>

<span class="sd">    Example Usage::</span>
<span class="sd">        model = YoutubeDNNRetrievalModelV2(schema, num_sampled=100)</span>
<span class="sd">        model.compile(optimizer=&quot;adam&quot;)</span>
<span class="sd">        model.fit(train_data, epochs=10)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Covington, Paul, Jay Adams, and Emre Sargin.</span>
<span class="sd">        &quot;Deep neural networks for youtube recommendations.&quot;</span>
<span class="sd">        Proceedings of the 10th ACM conference on recommender systems. 2016.</span>

<span class="sd">    .. [2] Yoshua Bengio and Jean-Sébastien Sénécal. 2003. Quick Training of Probabilistic</span>
<span class="sd">       Neural Nets by Importance Sampling. In Proceedings of the conference on Artificial</span>
<span class="sd">       Intelligence and Statistics (AISTATS).</span>

<span class="sd">    .. [3] Y. Bengio and J. S. Senecal. 2008. Adaptive Importance Sampling to Accelerate</span>
<span class="sd">       Training of a Neural Probabilistic Language Model. Trans. Neur. Netw. 19, 4 (April</span>
<span class="sd">       2008), 713–722. https://doi.org/10.1109/TNN.2007.912312</span>

<span class="sd">    .. [4] Jean, Sébastien, et al. &quot;On using very large target vocabulary for neural</span>
<span class="sd">        machine translation.&quot; arXiv preprint arXiv:1412.2007 (2014).</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    schema: Schema</span>
<span class="sd">        The `Schema` with the input features</span>
<span class="sd">    candidate_id_tag : Tag</span>
<span class="sd">        The tag to select candidate-id feature, by default `Tags.ITEM_ID`</span>
<span class="sd">    top_block: tf.keras.layers.Layer</span>
<span class="sd">        The hidden layers to apply on top of the features representation</span>
<span class="sd">        vector.</span>
<span class="sd">    inputs: tf.keras.layers.Layer, optional</span>
<span class="sd">        The input layer to encode input features (sparse and context features)</span>
<span class="sd">        If not specified, the input layer is inferred from the schema</span>
<span class="sd">        By default None</span>
<span class="sd">    post: Optional[tf.keras.layers.Layer], optional</span>
<span class="sd">        The optional layer to apply on top of the query encoder.</span>
<span class="sd">    outputs : Union[ModelOutput, List[ModelOutput]], optional</span>
<span class="sd">        Specifies the model&#39;s outputs. If not specified, the outputs will be inferred.</span>
<span class="sd">    logits_temperature: float, optional</span>
<span class="sd">        Parameter used to reduce model overconfidence, so that logits / T.</span>
<span class="sd">        Defaults to 1.</span>
<span class="sd">    num_sampled: int, optional</span>
<span class="sd">        When sampled_softmax is enabled, specify the number of</span>
<span class="sd">        negative candidates to generate for each batch.</span>
<span class="sd">        By default 100</span>
<span class="sd">    min_sampled_id: int, optional</span>
<span class="sd">        The minimum id value to be sampled with sampled softmax.</span>
<span class="sd">        Useful to ignore the first categorical</span>
<span class="sd">        encoded ids, which are usually reserved for &lt;nulls&gt;,</span>
<span class="sd">        out-of-vocabulary or padding.</span>
<span class="sd">        By default 0.</span>

<span class="sd">    Returns</span>
<span class="sd">    --------</span>
<span class="sd">    RetrievalModelV2</span>
<span class="sd">        The constructed Youtube-DNN based retrieval model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">inputs</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">schema</span>

    <span class="n">candidate</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">candidate_id_tag</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">candidate</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The schema should contain a feature tagged as `</span><span class="si">{</span><span class="n">candidate_id_tag</span><span class="si">}</span><span class="s2">`&quot;</span><span class="p">)</span>

    <span class="n">query</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">top_block</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">outputs</span><span class="p">:</span>
        <span class="n">cardinalities</span> <span class="o">=</span> <span class="n">categorical_cardinalities</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span>
        <span class="n">candidate</span> <span class="o">=</span> <span class="n">candidate</span><span class="o">.</span><span class="n">first</span>
        <span class="n">candidate_table</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">first</span><span class="p">[</span><span class="s2">&quot;categorical&quot;</span><span class="p">][</span><span class="n">candidate</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">cardinalities</span><span class="p">[</span><span class="n">candidate</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">ContrastiveOutput</span><span class="p">(</span>
            <span class="n">to_call</span><span class="o">=</span><span class="n">candidate_table</span><span class="p">,</span>
            <span class="n">logits_temperature</span><span class="o">=</span><span class="n">logits_temperature</span><span class="p">,</span>
            <span class="n">post</span><span class="o">=</span><span class="n">post</span><span class="p">,</span>
            <span class="n">negative_samplers</span><span class="o">=</span><span class="n">PopularityBasedSamplerV2</span><span class="p">(</span>
                <span class="n">max_num_samples</span><span class="o">=</span><span class="n">num_sampled</span><span class="p">,</span> <span class="n">max_id</span><span class="o">=</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">min_id</span><span class="o">=</span><span class="n">min_sampled_id</span>
            <span class="p">),</span>
            <span class="n">logq_sampling_correction</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">RetrievalModelV2</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>