

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>transformers4rec.torch package &#8212; NVIDIA Merlin</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/versions.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../_static/js/rtd-version-switcher.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api_transformers4rec/transformers4rec.torch';</script>
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/api_transformers4rec/transformers4rec.torch.html" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="transformers4rec.torch.block package" href="transformers4rec.torch.block.html" />
    <link rel="prev" title="transformers4rec.config package" href="transformers4rec.config.html" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVJ1Y1YJHK', {
        'anonymize_ip': false,
    });
  </script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,300&display=swap" rel="stylesheet">
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">NVIDIA Merlin</p>
  
</a></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../guide/recommender_system_guide.html">Recommender System Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../guide/recommender_models.html">Recommender Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../examples/index.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/getting-started-movielens/index.html">Getting Started using the MovieLens Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/01-Download-Convert.html">MovieLens Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/03-Training-with-TF.html">Getting Started MovieLens: Training with TensorFlow</a></li>


<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/03-Training-with-PyTorch.html">Training with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/04-Triton-Inference-with-HugeCTR.html">Serving the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/04-Triton-Inference-with-TF.html">Serve Recommendations from the TensorFlow Model</a></li>

</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/Building-and-deploying-multi-stage-RecSys/index.html">Deploying a Multi-Stage Recommender System</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/Building-and-deploying-multi-stage-RecSys/01-Building-Recommender-Systems-with-Merlin.html">Building the Recommender System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/Building-and-deploying-multi-stage-RecSys/02-Deploying-multi-stage-RecSys-with-Merlin-Systems.html">Deploying the Recommender System with Triton</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/sagemaker-tensorflow/index.html">Merlin and AWS SageMaker</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/sagemaker-tensorflow/sagemaker-merlin-tensorflow.html">Training and Serving Merlin on AWS SageMaker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/scaling-criteo/index.html">Scaling Large Datasets with Criteo</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/01-Download-Convert.html">Criteo Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/03-Training-with-Merlin-Models-TensorFlow.html">Training with Merlin Models and TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/04-Triton-Inference-with-HugeCTR.html">Deploy the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/04-Triton-Inference-with-Merlin-Models-TensorFlow.html">Deploy the TensorFlow Model with Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../containers.html">Merlin Containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../support_matrix/index.html">Merlin Support Matrix</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../support_matrix/support_matrix_merlin_hugectr.html">Merlin HugeCTR Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../support_matrix/support_matrix_merlin_tensorflow.html">Merlin TensorFlow Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../support_matrix/support_matrix_merlin_pytorch.html">Merlin PyTorch Support Matrix</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API documentation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_core/merlin.dag.html">merlin.dag</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.BaseOperator.html">merlin.dag.BaseOperator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.Graph.html">merlin.dag.Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.Node.html">merlin.dag.Node</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.ColumnSelector.html">merlin.dag.ColumnSelector</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_dataloader.html">merlin.loader</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tensorflow.Loader.html">merlin.dataloader.tensorflow.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tensorflow.KerasSequenceValidater.html">merlin.dataloader.tensorflow.KerasSequenceValidater</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tf_utils.configure_tensorflow.html">merlin.dataloader.tf_utils.configure_tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns.html">merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tf_utils.HAS_GPU.html">merlin.dataloader.tf_utils.HAS_GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.torch.Loader.html">merlin.dataloader.torch.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.torch.DLDataLoader.html">merlin.dataloader.torch.DLDataLoader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.jax.Loader.html">merlin.dataloader.jax.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.loader_base.LoaderBase.html">merlin.dataloader.loader_base.LoaderBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.loader_base.ChunkQueue.html">merlin.dataloader.loader_base.ChunkQueue</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_core/merlin.io.html">merlin.io</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html">merlin.io.Dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_models.html">merlin.models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DCNModel.html">merlin.models.tf.DCNModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DeepFMModel.html">merlin.models.tf.DeepFMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DLRMModel.html">merlin.models.tf.DLRMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.WideAndDeepModel.html">merlin.models.tf.WideAndDeepModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Encoder.html">merlin.models.tf.Encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.EmbeddingEncoder.html">merlin.models.tf.EmbeddingEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ItemRetrievalScorer.html">merlin.models.tf.ItemRetrievalScorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RetrievalModelV2.html">merlin.models.tf.RetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MatrixFactorizationModelV2.html">merlin.models.tf.MatrixFactorizationModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MatrixFactorizationModel.html">merlin.models.tf.MatrixFactorizationModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TwoTowerModelV2.html">merlin.models.tf.TwoTowerModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TwoTowerModel.html">merlin.models.tf.TwoTowerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.YoutubeDNNRetrievalModelV2.html">merlin.models.tf.YoutubeDNNRetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.YoutubeDNNRetrievalModel.html">merlin.models.tf.YoutubeDNNRetrievalModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Embeddings.html">merlin.models.tf.Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.EmbeddingTable.html">merlin.models.tf.EmbeddingTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.AverageEmbeddingsByWeightFeature.html">merlin.models.tf.AverageEmbeddingsByWeightFeature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ReplaceMaskedEmbeddings.html">merlin.models.tf.ReplaceMaskedEmbeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.L2Norm.html">merlin.models.tf.L2Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.InputBlockV2.html">merlin.models.tf.InputBlockV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.InputBlock.html">merlin.models.tf.InputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Continuous.html">merlin.models.tf.Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContinuousFeatures.html">merlin.models.tf.ContinuousFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContinuousEmbedding.html">merlin.models.tf.ContinuousEmbedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContinuousProjection.html">merlin.models.tf.ContinuousProjection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceEmbeddingFeatures.html">merlin.models.tf.SequenceEmbeddingFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DLRMBlock.html">merlin.models.tf.DLRMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MLPBlock.html">merlin.models.tf.MLPBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CrossBlock.html">merlin.models.tf.CrossBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TwoTowerBlock.html">merlin.models.tf.TwoTowerBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MatrixFactorizationBlock.html">merlin.models.tf.MatrixFactorizationBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DotProductInteraction.html">merlin.models.tf.DotProductInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.FMBlock.html">merlin.models.tf.FMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.FMPairwiseInteraction.html">merlin.models.tf.FMPairwiseInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PredictionTasks.html">merlin.models.tf.PredictionTasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PredictionTask.html">merlin.models.tf.PredictionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.BinaryClassificationTask.html">merlin.models.tf.BinaryClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MultiClassClassificationTask.html">merlin.models.tf.MultiClassClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RegressionTask.html">merlin.models.tf.RegressionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ItemRetrievalTask.html">merlin.models.tf.ItemRetrievalTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.OutputBlock.html">merlin.models.tf.OutputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ModelOutput.html">merlin.models.tf.ModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.BinaryOutput.html">merlin.models.tf.BinaryOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CategoricalOutput.html">merlin.models.tf.CategoricalOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContrastiveOutput.html">merlin.models.tf.ContrastiveOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RegressionOutput.html">merlin.models.tf.RegressionOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ColumnBasedSampleWeight.html">merlin.models.tf.ColumnBasedSampleWeight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequentialBlock.html">merlin.models.tf.SequentialBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ParallelBlock.html">merlin.models.tf.ParallelBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ParallelPredictionBlock.html">merlin.models.tf.ParallelPredictionBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DenseResidualBlock.html">merlin.models.tf.DenseResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DualEncoderBlock.html">merlin.models.tf.DualEncoderBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ResidualBlock.html">merlin.models.tf.ResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TabularBlock.html">merlin.models.tf.TabularBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Filter.html">merlin.models.tf.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Cond.html">merlin.models.tf.Cond</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TopKEncoder.html">merlin.models.tf.TopKEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MultiOptimizer.html">merlin.models.tf.MultiOptimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.LazyAdam.html">merlin.models.tf.LazyAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.OptimizerBlocks.html">merlin.models.tf.OptimizerBlocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.split_embeddings_on_size.html">merlin.models.tf.split_embeddings_on_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CategoryEncoding.html">merlin.models.tf.CategoryEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MapValues.html">merlin.models.tf.MapValues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PrepareListFeatures.html">merlin.models.tf.PrepareListFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PrepareFeatures.html">merlin.models.tf.PrepareFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToSparse.html">merlin.models.tf.ToSparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToDense.html">merlin.models.tf.ToDense</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToTarget.html">merlin.models.tf.ToTarget</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToOneHot.html">merlin.models.tf.ToOneHot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.HashedCross.html">merlin.models.tf.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.HashedCrossAll.html">merlin.models.tf.HashedCrossAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.BroadcastToSequence.html">merlin.models.tf.BroadcastToSequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequencePredictNext.html">merlin.models.tf.SequencePredictNext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequencePredictLast.html">merlin.models.tf.SequencePredictLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequencePredictRandom.html">merlin.models.tf.SequencePredictRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceTargetAsInput.html">merlin.models.tf.SequenceTargetAsInput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceMaskLast.html">merlin.models.tf.SequenceMaskLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceMaskRandom.html">merlin.models.tf.SequenceMaskRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ExpandDims.html">merlin.models.tf.ExpandDims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.StochasticSwapNoise.html">merlin.models.tf.StochasticSwapNoise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.AsTabular.html">merlin.models.tf.AsTabular</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MMOEBlock.html">merlin.models.tf.MMOEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CGCBlock.html">merlin.models.tf.CGCBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PLEBlock.html">merlin.models.tf.PLEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Loader.html">merlin.models.tf.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.AvgPrecisionAt.html">merlin.models.tf.AvgPrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MRRAt.html">merlin.models.tf.MRRAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.NDCGAt.html">merlin.models.tf.NDCGAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PrecisionAt.html">merlin.models.tf.PrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RecallAt.html">merlin.models.tf.RecallAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TopKMetricsAggregator.html">merlin.models.tf.TopKMetricsAggregator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ItemSampler.html">merlin.models.tf.ItemSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.InBatchSampler.html">merlin.models.tf.InBatchSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PopularityBasedSampler.html">merlin.models.tf.PopularityBasedSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.CategoricalCrossEntropy.html">merlin.models.tf.losses.CategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.SparseCategoricalCrossEntropy.html">merlin.models.tf.losses.SparseCategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.BPRLoss.html">merlin.models.tf.losses.BPRLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.BPRmaxLoss.html">merlin.models.tf.losses.BPRmaxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.HingeLoss.html">merlin.models.tf.losses.HingeLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.LogisticLoss.html">merlin.models.tf.losses.LogisticLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.TOP1Loss.html">merlin.models.tf.losses.TOP1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.TOP1maxLoss.html">merlin.models.tf.losses.TOP1maxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.TOP1v2Loss.html">merlin.models.tf.losses.TOP1v2Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.select_targets.html">merlin.models.utils.schema_utils.select_targets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json.html">merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema.html">merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.create_categorical_column.html">merlin.models.utils.schema_utils.create_categorical_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.create_continuous_column.html">merlin.models.utils.schema_utils.create_continuous_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.filter_dict_by_schema.html">merlin.models.utils.schema_utils.filter_dict_by_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.categorical_cardinalities.html">merlin.models.utils.schema_utils.categorical_cardinalities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.categorical_domains.html">merlin.models.utils.schema_utils.categorical_domains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.get_embedding_sizes_from_schema.html">merlin.models.utils.schema_utils.get_embedding_sizes_from_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.get_embedding_size_from_cardinality.html">merlin.models.utils.schema_utils.get_embedding_size_from_cardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TensorInitializer.html">merlin.models.tf.TensorInitializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.filter_kwargs.html">merlin.models.utils.misc_utils.filter_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.safe_json.html">merlin.models.utils.misc_utils.safe_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_filenames.html">merlin.models.utils.misc_utils.get_filenames</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_label_feature_name.html">merlin.models.utils.misc_utils.get_label_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_timestamp_feature_name.html">merlin.models.utils.misc_utils.get_timestamp_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_parquet_files_names.html">merlin.models.utils.misc_utils.get_parquet_files_names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.Timing.html">merlin.models.utils.misc_utils.Timing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_object_size.html">merlin.models.utils.misc_utils.get_object_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.validate_dataset.html">merlin.models.utils.misc_utils.validate_dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.camelcase_to_snakecase.html">merlin.models.utils.registry.camelcase_to_snakecase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.snakecase_to_camelcase.html">merlin.models.utils.registry.snakecase_to_camelcase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.default_name.html">merlin.models.utils.registry.default_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.default_object_name.html">merlin.models.utils.registry.default_object_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.Registry.html">merlin.models.utils.registry.Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.RegistryMixin.html">merlin.models.utils.registry.RegistryMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.display_list_by_prefix.html">merlin.models.utils.registry.display_list_by_prefix</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_core/merlin.schema.html">merlin.schema</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.schema.Schema.html">merlin.schema.Schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.schema.ColumnSchema.html">merlin.schema.ColumnSchema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html">merlin.schema.Tags</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_systems.html">merlin.systems</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.Ensemble.html">merlin.systems.dag.Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.workflow.TransformWorkflow.html">merlin.systems.dag.ops.workflow.TransformWorkflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.tensorflow.PredictTensorflow.html">merlin.systems.dag.ops.tensorflow.PredictTensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.fil.PredictForest.html">merlin.systems.dag.ops.fil.PredictForest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.implicit.PredictImplicit.html">merlin.systems.dag.ops.implicit.PredictImplicit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling.html">merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.session_filter.FilterCandidates.html">merlin.systems.dag.ops.session_filter.FilterCandidates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.unroll_features.UnrollFeatures.html">merlin.systems.dag.ops.unroll_features.UnrollFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.triton.convert_df_to_triton_input.html">merlin.systems.triton.convert_df_to_triton_input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.triton.convert_triton_output_to_df.html">merlin.systems.triton.convert_triton_output_to_df</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_nvtabular.html">nvtabular</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.workflow.workflow.Workflow.html">nvtabular.workflow.workflow.Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.workflow.workflow.WorkflowNode.html">nvtabular.workflow.workflow.WorkflowNode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Bucketize.html">nvtabular.ops.Bucketize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Categorify.html">nvtabular.ops.Categorify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.DropLowCardinality.html">nvtabular.ops.DropLowCardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.HashBucket.html">nvtabular.ops.HashBucket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.HashedCross.html">nvtabular.ops.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TargetEncoding.html">nvtabular.ops.TargetEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Clip.html">nvtabular.ops.Clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.LogOp.html">nvtabular.ops.LogOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Normalize.html">nvtabular.ops.Normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.NormalizeMinMax.html">nvtabular.ops.NormalizeMinMax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Dropna.html">nvtabular.ops.Dropna</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.FillMissing.html">nvtabular.ops.FillMissing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.FillMedian.html">nvtabular.ops.FillMedian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.DifferenceLag.html">nvtabular.ops.DifferenceLag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Filter.html">nvtabular.ops.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Groupby.html">nvtabular.ops.Groupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.JoinExternal.html">nvtabular.ops.JoinExternal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.JoinGroupby.html">nvtabular.ops.JoinGroupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.AddMetadata.html">nvtabular.ops.AddMetadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.AddProperties.html">nvtabular.ops.AddProperties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.AddTags.html">nvtabular.ops.AddTags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Rename.html">nvtabular.ops.Rename</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ReduceDtypeSize.html">nvtabular.ops.ReduceDtypeSize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsItemFeatures.html">nvtabular.ops.TagAsItemFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsItemID.html">nvtabular.ops.TagAsItemID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsUserFeatures.html">nvtabular.ops.TagAsUserFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsUserID.html">nvtabular.ops.TagAsUserID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ListSlice.html">nvtabular.ops.ListSlice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ValueCount.html">nvtabular.ops.ValueCount</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ColumnSimilarity.html">nvtabular.ops.ColumnSimilarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.LambdaOp.html">nvtabular.ops.LambdaOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Operator.html">nvtabular.ops.Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.StatOperator.html">nvtabular.ops.StatOperator</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="modules.html">transformers4rec</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="transformers4rec.html">transformers4rec package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.config.html">transformers4rec.config package</a></li>
<li class="toctree-l3 current active has-children"><a class="current reference internal" href="#">transformers4rec.torch package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html">transformers4rec.torch.block package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html">transformers4rec.torch.features package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html">transformers4rec.torch.model package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html">transformers4rec.torch.tabular package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html">transformers4rec.torch.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.utils.html">transformers4rec.utils package</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="merlin_standard_lib.html">merlin_standard_lib package</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="merlin_standard_lib.proto.html">merlin_standard_lib.proto package</a></li>
<li class="toctree-l3"><a class="reference internal" href="merlin_standard_lib.schema.html">merlin_standard_lib.schema package</a></li>
<li class="toctree-l3"><a class="reference internal" href="merlin_standard_lib.utils.html">merlin_standard_lib.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-merlin-ecosystem-nav" aria-label="Merlin Ecosystem Nav">
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul class="nav bd-sidenav">
      <li class="toctree-l1"><a class="reference external" href="/core/">Core</a></li>
      <li class="toctree-l1"><a class="reference external" href="/models/">Models</a></li>
      <li class="toctree-l1"><a class="reference external" href="/systems/">Systems</a></li>
      <li class="toctree-l1"><a class="reference external" href="/NVTabular/">NVTabular</a></li>
      <li class="toctree-l1"><a class="reference external" href="/Transformers4Rec/">Transformers4Rec</a></li>
      <li class="toctree-l1"><a class="reference external" href="/dataloader/">Dataloader</a></li>
      <li class="toctree-l1"><a class="reference external" href="/HugetCTR/">HugeCTR</a></li>
    </ul>
  </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>transformers4rec.torch package</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#subpackages">Subpackages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.masking">transformers4rec.torch.masking module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskingInfo"><code class="docutils literal notranslate"><span class="pre">MaskingInfo</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskingInfo.schema"><code class="docutils literal notranslate"><span class="pre">MaskingInfo.schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskingInfo.targets"><code class="docutils literal notranslate"><span class="pre">MaskingInfo.targets</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence"><code class="docutils literal notranslate"><span class="pre">MaskSequence</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.compute_masked_targets"><code class="docutils literal notranslate"><span class="pre">MaskSequence.compute_masked_targets()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MaskSequence.apply_mask_to_inputs()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.predict_all"><code class="docutils literal notranslate"><span class="pre">MaskSequence.predict_all()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.forward"><code class="docutils literal notranslate"><span class="pre">MaskSequence.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.forward_output_size"><code class="docutils literal notranslate"><span class="pre">MaskSequence.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.transformer_required_arguments"><code class="docutils literal notranslate"><span class="pre">MaskSequence.transformer_required_arguments()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.transformer_optional_arguments"><code class="docutils literal notranslate"><span class="pre">MaskSequence.transformer_optional_arguments()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.transformer_arguments"><code class="docutils literal notranslate"><span class="pre">MaskSequence.transformer_arguments</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.CausalLanguageModeling"><code class="docutils literal notranslate"><span class="pre">CausalLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.CausalLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">CausalLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskedLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MaskedLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskedLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MaskedLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.PermutationLanguageModeling"><code class="docutils literal notranslate"><span class="pre">PermutationLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.PermutationLanguageModeling.compute_masked_targets"><code class="docutils literal notranslate"><span class="pre">PermutationLanguageModeling.compute_masked_targets()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.PermutationLanguageModeling.transformer_required_arguments"><code class="docutils literal notranslate"><span class="pre">PermutationLanguageModeling.transformer_required_arguments()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.ReplacementLanguageModeling"><code class="docutils literal notranslate"><span class="pre">ReplacementLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.ReplacementLanguageModeling.get_fake_tokens"><code class="docutils literal notranslate"><span class="pre">ReplacementLanguageModeling.get_fake_tokens()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.ReplacementLanguageModeling.sample_from_softmax"><code class="docutils literal notranslate"><span class="pre">ReplacementLanguageModeling.sample_from_softmax()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.ranking_metric">transformers4rec.torch.ranking_metric module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RankingMetric"><code class="docutils literal notranslate"><span class="pre">RankingMetric</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RankingMetric.update"><code class="docutils literal notranslate"><span class="pre">RankingMetric.update()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RankingMetric.compute"><code class="docutils literal notranslate"><span class="pre">RankingMetric.compute()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.PrecisionAt"><code class="docutils literal notranslate"><span class="pre">PrecisionAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RecallAt"><code class="docutils literal notranslate"><span class="pre">RecallAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.AvgPrecisionAt"><code class="docutils literal notranslate"><span class="pre">AvgPrecisionAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.DCGAt"><code class="docutils literal notranslate"><span class="pre">DCGAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.NDCGAt"><code class="docutils literal notranslate"><span class="pre">NDCGAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.MeanReciprocalRankAt"><code class="docutils literal notranslate"><span class="pre">MeanReciprocalRankAt</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.trainer">transformers4rec.torch.trainer module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_train_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_train_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_eval_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_eval_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_test_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_test_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.num_examples"><code class="docutils literal notranslate"><span class="pre">Trainer.num_examples()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.reset_lr_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.reset_lr_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.create_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.create_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.get_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.compute_loss"><code class="docutils literal notranslate"><span class="pre">Trainer.compute_loss()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.prediction_step"><code class="docutils literal notranslate"><span class="pre">Trainer.prediction_step()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.evaluation_loop"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluation_loop()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.load_model_trainer_states_from_checkpoint"><code class="docutils literal notranslate"><span class="pre">Trainer.load_model_trainer_states_from_checkpoint()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.log_predictions_callback"><code class="docutils literal notranslate"><span class="pre">Trainer.log_predictions_callback</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.log"><code class="docutils literal notranslate"><span class="pre">Trainer.log()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.process_metrics"><code class="docutils literal notranslate"><span class="pre">process_metrics()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_begin"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback.on_train_begin()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_end"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback.on_train_end()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_epoch_end"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback.on_epoch_end()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.DatasetMock"><code class="docutils literal notranslate"><span class="pre">DatasetMock</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.typing">transformers4rec.torch.typing module</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema"><code class="docutils literal notranslate"><span class="pre">Schema</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.feature"><code class="docutils literal notranslate"><span class="pre">Schema.feature</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.create"><code class="docutils literal notranslate"><span class="pre">Schema.create()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.with_tags_based_on_properties"><code class="docutils literal notranslate"><span class="pre">Schema.with_tags_based_on_properties()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.apply"><code class="docutils literal notranslate"><span class="pre">Schema.apply()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.apply_inverse"><code class="docutils literal notranslate"><span class="pre">Schema.apply_inverse()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.filter_columns_from_dict"><code class="docutils literal notranslate"><span class="pre">Schema.filter_columns_from_dict()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.select_by_type"><code class="docutils literal notranslate"><span class="pre">Schema.select_by_type()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.remove_by_type"><code class="docutils literal notranslate"><span class="pre">Schema.remove_by_type()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.select_by_tag"><code class="docutils literal notranslate"><span class="pre">Schema.select_by_tag()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.remove_by_tag"><code class="docutils literal notranslate"><span class="pre">Schema.remove_by_tag()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.select_by_name"><code class="docutils literal notranslate"><span class="pre">Schema.select_by_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.remove_by_name"><code class="docutils literal notranslate"><span class="pre">Schema.remove_by_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.map_column_schemas"><code class="docutils literal notranslate"><span class="pre">Schema.map_column_schemas()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.filter_column_schemas"><code class="docutils literal notranslate"><span class="pre">Schema.filter_column_schemas()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.column_names"><code class="docutils literal notranslate"><span class="pre">Schema.column_names</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.column_schemas"><code class="docutils literal notranslate"><span class="pre">Schema.column_schemas</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.item_id_column_name"><code class="docutils literal notranslate"><span class="pre">Schema.item_id_column_name</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.from_json"><code class="docutils literal notranslate"><span class="pre">Schema.from_json()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.to_proto_text"><code class="docutils literal notranslate"><span class="pre">Schema.to_proto_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.from_proto_text"><code class="docutils literal notranslate"><span class="pre">Schema.from_proto_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.copy"><code class="docutils literal notranslate"><span class="pre">Schema.copy()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.add"><code class="docutils literal notranslate"><span class="pre">Schema.add()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.requires_schema"><code class="docutils literal notranslate"><span class="pre">requires_schema()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig"><code class="docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.to_huggingface_torch_model"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.to_huggingface_torch_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.to_torch_model"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.to_torch_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.transformers_config_cls"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.transformers_config_cls</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.build"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.GPT2Config"><code class="docutils literal notranslate"><span class="pre">GPT2Config</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.GPT2Config.build"><code class="docutils literal notranslate"><span class="pre">GPT2Config.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.XLNetConfig"><code class="docutils literal notranslate"><span class="pre">XLNetConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.XLNetConfig.build"><code class="docutils literal notranslate"><span class="pre">XLNetConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransfoXLConfig"><code class="docutils literal notranslate"><span class="pre">TransfoXLConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransfoXLConfig.build"><code class="docutils literal notranslate"><span class="pre">TransfoXLConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.LongformerConfig"><code class="docutils literal notranslate"><span class="pre">LongformerConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.LongformerConfig.build"><code class="docutils literal notranslate"><span class="pre">LongformerConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AlbertConfig"><code class="docutils literal notranslate"><span class="pre">AlbertConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AlbertConfig.build"><code class="docutils literal notranslate"><span class="pre">AlbertConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ReformerConfig"><code class="docutils literal notranslate"><span class="pre">ReformerConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ReformerConfig.build"><code class="docutils literal notranslate"><span class="pre">ReformerConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElectraConfig"><code class="docutils literal notranslate"><span class="pre">ElectraConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElectraConfig.build"><code class="docutils literal notranslate"><span class="pre">ElectraConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.max_sequence_length"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.max_sequence_length</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.shuffle_buffer_size"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.shuffle_buffer_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.data_loader_engine"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.data_loader_engine</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.eval_on_test_set"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.eval_on_test_set</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.eval_steps_on_train_set"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.eval_steps_on_train_set</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.predict_top_k"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.predict_top_k</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.learning_rate_num_cosine_cycles_by_epoch"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.learning_rate_num_cosine_cycles_by_epoch</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.log_predictions"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.log_predictions</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.compute_metrics_each_n_steps"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.compute_metrics_each_n_steps</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.experiments_group"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.experiments_group</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.place_model_on_device"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.place_model_on_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.output_dir"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.output_dir</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock"><code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.inputs"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.inputs</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.add_module"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.add_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.add_module_and_maybe_build"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.add_module_and_maybe_build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.forward"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.build"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.as_tabular"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.as_tabular()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.forward_output_size"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.get_children_by_class_name"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.get_children_by_class_name()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.right_shift_block"><code class="docutils literal notranslate"><span class="pre">right_shift_block()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.build_blocks"><code class="docutils literal notranslate"><span class="pre">build_blocks()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BlockBase"><code class="docutils literal notranslate"><span class="pre">BlockBase</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BlockBase.to_model"><code class="docutils literal notranslate"><span class="pre">BlockBase.to_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BlockBase.as_tabular"><code class="docutils literal notranslate"><span class="pre">BlockBase.as_tabular()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock"><code class="docutils literal notranslate"><span class="pre">TabularBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock.to_module"><code class="docutils literal notranslate"><span class="pre">TabularBlock.to_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock.output_size"><code class="docutils literal notranslate"><span class="pre">TabularBlock.output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock.build"><code class="docutils literal notranslate"><span class="pre">TabularBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Block"><code class="docutils literal notranslate"><span class="pre">Block</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Block.forward"><code class="docutils literal notranslate"><span class="pre">Block.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Block.forward_output_size"><code class="docutils literal notranslate"><span class="pre">Block.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MLPBlock"><code class="docutils literal notranslate"><span class="pre">MLPBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MLPBlock.build"><code class="docutils literal notranslate"><span class="pre">MLPBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularTransformation"><code class="docutils literal notranslate"><span class="pre">TabularTransformation</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularTransformation.forward"><code class="docutils literal notranslate"><span class="pre">TabularTransformation.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularTransformation.parse"><code class="docutils literal notranslate"><span class="pre">TabularTransformation.parse()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialTabularTransformations"><code class="docutils literal notranslate"><span class="pre">SequentialTabularTransformations</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialTabularTransformations.append"><code class="docutils literal notranslate"><span class="pre">SequentialTabularTransformations.append()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularAggregation"><code class="docutils literal notranslate"><span class="pre">TabularAggregation</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularAggregation.forward"><code class="docutils literal notranslate"><span class="pre">TabularAggregation.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularAggregation.parse"><code class="docutils literal notranslate"><span class="pre">TabularAggregation.parse()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise.forward"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise.forward_output_size"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise.augment"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.augment()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.from_feature_config"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.from_feature_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.forward"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.build"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularDropout"><code class="docutils literal notranslate"><span class="pre">TabularDropout</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularDropout.forward"><code class="docutils literal notranslate"><span class="pre">TabularDropout.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularDropout.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularDropout.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock"><code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.TRANSFORMER_TO_PREPARE"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.TRANSFORMER_TO_PREPARE</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.from_registry"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.from_registry()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.forward"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures.from_features"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.from_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures.forward"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.item_embedding_table"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.item_embedding_table</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.item_ids"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.item_ids()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.forward"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer.forward"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer.training"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.build"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.forward"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.parse_combiner"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.parse_combiner()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.masking"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.masking</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.set_masking"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.set_masking()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.item_id"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.item_id</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.item_embedding_table"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.item_embedding_table</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.forward"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.project_continuous_features"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.project_continuous_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequenceEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequenceEmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequenceEmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig"><code class="docutils literal notranslate"><span class="pre">FeatureConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig.table"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.table</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig.max_sequence_length"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.max_sequence_length</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig.name"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.name</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig"><code class="docutils literal notranslate"><span class="pre">TableConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.vocabulary_size"><code class="docutils literal notranslate"><span class="pre">TableConfig.vocabulary_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.dim"><code class="docutils literal notranslate"><span class="pre">TableConfig.dim</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.initializer"><code class="docutils literal notranslate"><span class="pre">TableConfig.initializer</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.combiner"><code class="docutils literal notranslate"><span class="pre">TableConfig.combiner</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.name"><code class="docutils literal notranslate"><span class="pre">TableConfig.name</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures"><code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.CONTINUOUS_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.CONTINUOUS_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.project_continuous_features"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.project_continuous_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.continuous_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.continuous_module</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.categorical_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.categorical_module</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.pretrained_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.pretrained_module</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head"><code class="docutils literal notranslate"><span class="pre">Head</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.build"><code class="docutils literal notranslate"><span class="pre">Head.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.from_schema"><code class="docutils literal notranslate"><span class="pre">Head.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.pop_labels"><code class="docutils literal notranslate"><span class="pre">Head.pop_labels()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.forward"><code class="docutils literal notranslate"><span class="pre">Head.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">Head.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.compute_metrics"><code class="docutils literal notranslate"><span class="pre">Head.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.reset_metrics"><code class="docutils literal notranslate"><span class="pre">Head.reset_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.task_blocks"><code class="docutils literal notranslate"><span class="pre">Head.task_blocks</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.to_model"><code class="docutils literal notranslate"><span class="pre">Head.to_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.training"><code class="docutils literal notranslate"><span class="pre">Head.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.forward"><code class="docutils literal notranslate"><span class="pre">Model.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">Model.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.compute_metrics"><code class="docutils literal notranslate"><span class="pre">Model.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.reset_metrics"><code class="docutils literal notranslate"><span class="pre">Model.reset_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.to_lightning"><code class="docutils literal notranslate"><span class="pre">Model.to_lightning()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.fit"><code class="docutils literal notranslate"><span class="pre">Model.fit()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.evaluate"><code class="docutils literal notranslate"><span class="pre">Model.evaluate()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.input_schema"><code class="docutils literal notranslate"><span class="pre">Model.input_schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.output_schema"><code class="docutils literal notranslate"><span class="pre">Model.output_schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.prediction_tasks"><code class="docutils literal notranslate"><span class="pre">Model.prediction_tasks</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.save"><code class="docutils literal notranslate"><span class="pre">Model.save()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.load"><code class="docutils literal notranslate"><span class="pre">Model.load()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.training"><code class="docutils literal notranslate"><span class="pre">Model.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask"><code class="docutils literal notranslate"><span class="pre">PredictionTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.build"><code class="docutils literal notranslate"><span class="pre">PredictionTask.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.forward"><code class="docutils literal notranslate"><span class="pre">PredictionTask.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.task_name"><code class="docutils literal notranslate"><span class="pre">PredictionTask.task_name</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.child_name"><code class="docutils literal notranslate"><span class="pre">PredictionTask.child_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.set_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.set_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.compute_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.metric_name"><code class="docutils literal notranslate"><span class="pre">PredictionTask.metric_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.reset_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.reset_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.to_head"><code class="docutils literal notranslate"><span class="pre">PredictionTask.to_head()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.to_model"><code class="docutils literal notranslate"><span class="pre">PredictionTask.to_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.training"><code class="docutils literal notranslate"><span class="pre">PredictionTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AsTabular"><code class="docutils literal notranslate"><span class="pre">AsTabular</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AsTabular.forward"><code class="docutils literal notranslate"><span class="pre">AsTabular.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AsTabular.forward_output_size"><code class="docutils literal notranslate"><span class="pre">AsTabular.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ConcatFeatures"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ConcatFeatures.forward"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ConcatFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FilterFeatures"><code class="docutils literal notranslate"><span class="pre">FilterFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FilterFeatures.forward"><code class="docutils literal notranslate"><span class="pre">FilterFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FilterFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">FilterFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSum"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSum.forward"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSum.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti.forward"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti.REQUIRES_SCHEMA"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.REQUIRES_SCHEMA</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular"><code class="docutils literal notranslate"><span class="pre">MergeTabular</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.merge_values"><code class="docutils literal notranslate"><span class="pre">MergeTabular.merge_values</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.forward"><code class="docutils literal notranslate"><span class="pre">MergeTabular.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.forward_output_size"><code class="docutils literal notranslate"><span class="pre">MergeTabular.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.build"><code class="docutils literal notranslate"><span class="pre">MergeTabular.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StackFeatures"><code class="docutils literal notranslate"><span class="pre">StackFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StackFeatures.forward"><code class="docutils literal notranslate"><span class="pre">StackFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StackFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">StackFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask.DEFAULT_LOSS"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.DEFAULT_LOSS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.DEFAULT_METRICS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask.training"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask"><code class="docutils literal notranslate"><span class="pre">RegressionTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask.DEFAULT_LOSS"><code class="docutils literal notranslate"><span class="pre">RegressionTask.DEFAULT_LOSS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">RegressionTask.DEFAULT_METRICS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask.training"><code class="docutils literal notranslate"><span class="pre">RegressionTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.DEFAULT_METRICS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.build"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.forward"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.remove_pad_3d"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.remove_pad_3d()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.compute_metrics"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.training"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule"><code class="docutils literal notranslate"><span class="pre">TabularModule</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularModule.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.from_features"><code class="docutils literal notranslate"><span class="pre">TabularModule.from_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.pre"><code class="docutils literal notranslate"><span class="pre">TabularModule.pre</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.post"><code class="docutils literal notranslate"><span class="pre">TabularModule.post</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.aggregation"><code class="docutils literal notranslate"><span class="pre">TabularModule.aggregation</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.pre_forward"><code class="docutils literal notranslate"><span class="pre">TabularModule.pre_forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.forward"><code class="docutils literal notranslate"><span class="pre">TabularModule.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.post_forward"><code class="docutils literal notranslate"><span class="pre">TabularModule.post_forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.merge"><code class="docutils literal notranslate"><span class="pre">TabularModule.merge()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.training"><code class="docutils literal notranslate"><span class="pre">TabularModule.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbedding"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbedding.training"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_train_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_train_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_eval_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_eval_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_test_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_test_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.num_examples"><code class="docutils literal notranslate"><span class="pre">Trainer.num_examples()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.reset_lr_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.reset_lr_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.create_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.create_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.get_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.compute_loss"><code class="docutils literal notranslate"><span class="pre">Trainer.compute_loss()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.prediction_step"><code class="docutils literal notranslate"><span class="pre">Trainer.prediction_step()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.evaluation_loop"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluation_loop()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.load_model_trainer_states_from_checkpoint"><code class="docutils literal notranslate"><span class="pre">Trainer.load_model_trainer_states_from_checkpoint()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.log_predictions_callback"><code class="docutils literal notranslate"><span class="pre">Trainer.log_predictions_callback</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.log"><code class="docutils literal notranslate"><span class="pre">Trainer.log()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.LabelSmoothCrossEntropyLoss"><code class="docutils literal notranslate"><span class="pre">LabelSmoothCrossEntropyLoss()</span></code></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="transformers4rec-torch-package">
<h1>transformers4rec.torch package<a class="headerlink" href="#transformers4rec-torch-package" title="Permalink to this heading">#</a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this heading">#</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="transformers4rec.torch.block.html">transformers4rec.torch.block package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.block.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.block.html#module-transformers4rec.torch.block.base">transformers4rec.torch.block.base module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase"><code class="docutils literal notranslate"><span class="pre">BlockBase</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase.to_model"><code class="docutils literal notranslate"><span class="pre">BlockBase.to_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase.as_tabular"><code class="docutils literal notranslate"><span class="pre">BlockBase.as_tabular()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.Block"><code class="docutils literal notranslate"><span class="pre">Block</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.Block.forward"><code class="docutils literal notranslate"><span class="pre">Block.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.Block.forward_output_size"><code class="docutils literal notranslate"><span class="pre">Block.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock"><code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.inputs"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.inputs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.add_module"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.add_module()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.add_module_and_maybe_build"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.add_module_and_maybe_build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.forward"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.build"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.as_tabular"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.as_tabular()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.forward_output_size"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.forward_output_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock.get_children_by_class_name"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.get_children_by_class_name()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.build_blocks"><code class="docutils literal notranslate"><span class="pre">build_blocks()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock"><code class="docutils literal notranslate"><span class="pre">BuildableBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock.build"><code class="docutils literal notranslate"><span class="pre">BuildableBlock.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock.to_module"><code class="docutils literal notranslate"><span class="pre">BuildableBlock.to_module()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.right_shift_block"><code class="docutils literal notranslate"><span class="pre">right_shift_block()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.block.html#module-transformers4rec.torch.block.mlp">transformers4rec.torch.block.mlp module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.mlp.MLPBlock"><code class="docutils literal notranslate"><span class="pre">MLPBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.mlp.MLPBlock.build"><code class="docutils literal notranslate"><span class="pre">MLPBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.mlp.DenseBlock"><code class="docutils literal notranslate"><span class="pre">DenseBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.mlp.DenseBlock.forward_output_size"><code class="docutils literal notranslate"><span class="pre">DenseBlock.forward_output_size()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.block.html#module-transformers4rec.torch.block.transformer">transformers4rec.torch.block.transformer module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerPrepare"><code class="docutils literal notranslate"><span class="pre">TransformerPrepare</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerPrepare.forward"><code class="docutils literal notranslate"><span class="pre">TransformerPrepare.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerPrepare.training"><code class="docutils literal notranslate"><span class="pre">TransformerPrepare.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.GPT2Prepare"><code class="docutils literal notranslate"><span class="pre">GPT2Prepare</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.GPT2Prepare.forward"><code class="docutils literal notranslate"><span class="pre">GPT2Prepare.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.GPT2Prepare.training"><code class="docutils literal notranslate"><span class="pre">GPT2Prepare.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock"><code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock.TRANSFORMER_TO_PREPARE"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.TRANSFORMER_TO_PREPARE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock.transformer"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.transformer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock.prepare_module"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.prepare_module</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock.from_registry"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.from_registry()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock.training"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.training</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock.forward"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerBlock.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.forward_output_size()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.block.html#module-transformers4rec.torch.block">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="transformers4rec.torch.features.html">transformers4rec.torch.features package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#module-transformers4rec.torch.features.base">transformers4rec.torch.features.base module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.base.InputBlock"><code class="docutils literal notranslate"><span class="pre">InputBlock</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#module-transformers4rec.torch.features.continuous">transformers4rec.torch.features.continuous module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.continuous.ContinuousFeatures"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.continuous.ContinuousFeatures.from_features"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.from_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.continuous.ContinuousFeatures.forward"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.continuous.ContinuousFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#module-transformers4rec.torch.features.embedding">transformers4rec.torch.features.embedding module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures.item_embedding_table"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.item_embedding_table</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures.item_ids"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.item_ids()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures.forward"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.forward"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.num_embeddings"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.num_embeddings</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.embedding_dim"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.embedding_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.max_norm"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.max_norm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.norm_type"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.norm_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.scale_grad_by_freq"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.scale_grad_by_freq</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.weight"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.weight</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.mode"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.mode</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.sparse"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.sparse</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.include_last_offset"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.include_last_offset</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.padding_idx"><code class="docutils literal notranslate"><span class="pre">EmbeddingBagWrapper.padding_idx</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig"><code class="docutils literal notranslate"><span class="pre">TableConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig.vocabulary_size"><code class="docutils literal notranslate"><span class="pre">TableConfig.vocabulary_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig.dim"><code class="docutils literal notranslate"><span class="pre">TableConfig.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig.initializer"><code class="docutils literal notranslate"><span class="pre">TableConfig.initializer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig.combiner"><code class="docutils literal notranslate"><span class="pre">TableConfig.combiner</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig.name"><code class="docutils literal notranslate"><span class="pre">TableConfig.name</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig"><code class="docutils literal notranslate"><span class="pre">FeatureConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig.table"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.table</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig.max_sequence_length"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.max_sequence_length</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig.name"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.name</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbedding"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbedding.training"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer.forward"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer.training"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures.build"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures.forward"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.forward_output_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures.parse_combiner"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.parse_combiner()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#module-transformers4rec.torch.features.sequence">transformers4rec.torch.features.sequence module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.masking"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.masking</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.set_masking"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.set_masking()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.item_id"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.item_id</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.item_embedding_table"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.item_embedding_table</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.forward"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.project_continuous_features"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.project_continuous_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#module-transformers4rec.torch.features.tabular">transformers4rec.torch.features.tabular module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures"><code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.CONTINUOUS_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.CONTINUOUS_MODULE_CLASS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.project_continuous_features"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.project_continuous_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.forward_output_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.continuous_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.continuous_module</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.categorical_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.categorical_module</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures.pretrained_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.pretrained_module</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#module-transformers4rec.torch.features.text">transformers4rec.torch.features.text module</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.features.html#module-transformers4rec.torch.features">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="transformers4rec.torch.model.html">transformers4rec.torch.model package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.model.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec-torch-model-head-module">transformers4rec.torch.model.head module</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec-torch-model-model-module">transformers4rec.torch.model.model module</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.model.html#module-transformers4rec.torch.model.prediction_task">transformers4rec.torch.model.prediction_task module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.BinaryClassificationPrepareBlock"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationPrepareBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.BinaryClassificationPrepareBlock.build"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationPrepareBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.BinaryClassificationTask"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.BinaryClassificationTask.DEFAULT_LOSS"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.DEFAULT_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.BinaryClassificationTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.DEFAULT_METRICS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.BinaryClassificationTask.training"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.RegressionPrepareBlock"><code class="docutils literal notranslate"><span class="pre">RegressionPrepareBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.RegressionPrepareBlock.build"><code class="docutils literal notranslate"><span class="pre">RegressionPrepareBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.RegressionTask"><code class="docutils literal notranslate"><span class="pre">RegressionTask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.RegressionTask.DEFAULT_LOSS"><code class="docutils literal notranslate"><span class="pre">RegressionTask.DEFAULT_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.RegressionTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">RegressionTask.DEFAULT_METRICS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.RegressionTask.training"><code class="docutils literal notranslate"><span class="pre">RegressionTask.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.DEFAULT_METRICS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask.build"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask.forward"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask.remove_pad_3d"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.remove_pad_3d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.calculate_metrics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask.compute_metrics"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.compute_metrics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionTask.training"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionPrepareBlock"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionPrepareBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.NextItemPredictionPrepareBlock.build"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionPrepareBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.LogUniformSampler"><code class="docutils literal notranslate"><span class="pre">LogUniformSampler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.LogUniformSampler.get_log_uniform_distr"><code class="docutils literal notranslate"><span class="pre">LogUniformSampler.get_log_uniform_distr()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.LogUniformSampler.get_unique_sampling_distr"><code class="docutils literal notranslate"><span class="pre">LogUniformSampler.get_unique_sampling_distr()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.LogUniformSampler.sample"><code class="docutils literal notranslate"><span class="pre">LogUniformSampler.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.LogUniformSampler.forward"><code class="docutils literal notranslate"><span class="pre">LogUniformSampler.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html#transformers4rec.torch.model.prediction_task.LogUniformSampler.training"><code class="docutils literal notranslate"><span class="pre">LogUniformSampler.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.model.html#module-transformers4rec.torch.model">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="transformers4rec.torch.tabular.html">transformers4rec.torch.tabular package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.tabular.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.tabular.html#module-transformers4rec.torch.tabular.aggregation">transformers4rec.torch.tabular.aggregation module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ConcatFeatures"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ConcatFeatures.forward"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ConcatFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.StackFeatures"><code class="docutils literal notranslate"><span class="pre">StackFeatures</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.StackFeatures.forward"><code class="docutils literal notranslate"><span class="pre">StackFeatures.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.StackFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">StackFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseFeatureAggregation"><code class="docutils literal notranslate"><span class="pre">ElementwiseFeatureAggregation</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSum"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSum.forward"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSum.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSumItemMulti"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSumItemMulti.forward"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSumItemMulti.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.forward_output_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSumItemMulti.REQUIRES_SCHEMA"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.REQUIRES_SCHEMA</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseSumItemMulti.training"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.training</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec-torch-tabular-tabular-module">transformers4rec.torch.tabular.tabular module</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.tabular.html#module-transformers4rec.torch.tabular.transformations">transformers4rec.torch.tabular.transformations module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.StochasticSwapNoise"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.StochasticSwapNoise.forward"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.StochasticSwapNoise.forward_output_size"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.forward_output_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.StochasticSwapNoise.augment"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.augment()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularLayerNorm"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularLayerNorm.from_feature_config"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.from_feature_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularLayerNorm.forward"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularLayerNorm.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.forward_output_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularLayerNorm.build"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.build()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularDropout"><code class="docutils literal notranslate"><span class="pre">TabularDropout</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularDropout.forward"><code class="docutils literal notranslate"><span class="pre">TabularDropout.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.transformations.TabularDropout.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularDropout.forward_output_size()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.tabular.html#module-transformers4rec.torch.tabular">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="transformers4rec.torch.utils.html">transformers4rec.torch.utils package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.utils.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.utils.html#module-transformers4rec.torch.utils.data_utils">transformers4rec.torch.utils.data_utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.T4RecDataLoader"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.T4RecDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.T4RecDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.set_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.T4RecDataLoader.parse"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.parse()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.batch_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.num_workers</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.pin_memory</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.drop_last</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.set_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.dataset</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.timeout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.sampler</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.pin_memory_device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader"><code class="docutils literal notranslate"><span class="pre">DLDataLoader</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.device"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.dataset</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.batch_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.num_workers</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.pin_memory</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.drop_last</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.timeout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.sampler</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.pin_memory_device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.DLDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.batch_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.drop_last</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.dataset</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.set_dataset()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.from_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.output_schema"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.output_schema</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.num_workers</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.pin_memory</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.timeout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.sampler</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.pin_memory_device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.MerlinDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.ParquetDataset"><code class="docutils literal notranslate"><span class="pre">ParquetDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.ParquetDataset.pad_seq_column_if_needed"><code class="docutils literal notranslate"><span class="pre">ParquetDataset.pad_seq_column_if_needed()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.ShuffleDataset"><code class="docutils literal notranslate"><span class="pre">ShuffleDataset</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.data_utils.to_core_schema"><code class="docutils literal notranslate"><span class="pre">to_core_schema()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.utils.html#module-transformers4rec.torch.utils.examples_utils">transformers4rec.torch.utils.examples_utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.examples_utils.list_files"><code class="docutils literal notranslate"><span class="pre">list_files()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.examples_utils.visualize_response"><code class="docutils literal notranslate"><span class="pre">visualize_response()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.examples_utils.fit_and_evaluate"><code class="docutils literal notranslate"><span class="pre">fit_and_evaluate()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.examples_utils.wipe_memory"><code class="docutils literal notranslate"><span class="pre">wipe_memory()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.utils.html#module-transformers4rec.torch.utils.schema_utils">transformers4rec.torch.utils.schema_utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.schema_utils.random_data_from_schema"><code class="docutils literal notranslate"><span class="pre">random_data_from_schema()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.utils.html#module-transformers4rec.torch.utils.torch_utils">transformers4rec.torch.utils.torch_utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.build"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.output_size"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.output_size()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.forward_output_size"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LossMixin"><code class="docutils literal notranslate"><span class="pre">LossMixin</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LossMixin.compute_loss"><code class="docutils literal notranslate"><span class="pre">LossMixin.compute_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MetricsMixin"><code class="docutils literal notranslate"><span class="pre">MetricsMixin</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MetricsMixin.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.calculate_metrics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MetricsMixin.compute_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.compute_metrics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MetricsMixin.reset_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.reset_metrics()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.requires_schema"><code class="docutils literal notranslate"><span class="pre">requires_schema()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.check_gpu"><code class="docutils literal notranslate"><span class="pre">check_gpu()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.get_output_sizes_from_schema"><code class="docutils literal notranslate"><span class="pre">get_output_sizes_from_schema()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.calculate_batch_size_from_input_size"><code class="docutils literal notranslate"><span class="pre">calculate_batch_size_from_input_size()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.check_inputs"><code class="docutils literal notranslate"><span class="pre">check_inputs()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.extract_topk"><code class="docutils literal notranslate"><span class="pre">extract_topk()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.create_output_placeholder"><code class="docutils literal notranslate"><span class="pre">create_output_placeholder()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.tranform_label_to_onehot"><code class="docutils literal notranslate"><span class="pre">tranform_label_to_onehot()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.nested_detach"><code class="docutils literal notranslate"><span class="pre">nested_detach()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.nested_concat"><code class="docutils literal notranslate"><span class="pre">nested_concat()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.torch_pad_and_concatenate"><code class="docutils literal notranslate"><span class="pre">torch_pad_and_concatenate()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.atleast_1d"><code class="docutils literal notranslate"><span class="pre">atleast_1d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.nested_numpify"><code class="docutils literal notranslate"><span class="pre">nested_numpify()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.nested_truncate"><code class="docutils literal notranslate"><span class="pre">nested_truncate()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.numpy_pad_and_concatenate"><code class="docutils literal notranslate"><span class="pre">numpy_pad_and_concatenate()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.one_hot_1d"><code class="docutils literal notranslate"><span class="pre">one_hot_1d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LambdaModule"><code class="docutils literal notranslate"><span class="pre">LambdaModule</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LambdaModule.forward"><code class="docutils literal notranslate"><span class="pre">LambdaModule.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LambdaModule.training"><code class="docutils literal notranslate"><span class="pre">LambdaModule.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.CausalLanguageModeling</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MaskedLanguageModeling</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.PermutationLanguageModeling</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ReplacementLanguageModeling</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DEFAULT_MASKING"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DEFAULT_MASKING</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.BertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.BertConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ConvBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ConvBertConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DebertaConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DebertaConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DistilBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DistilBertConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.GPT2Config"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.GPT2Config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.LongformerConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.LongformerConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MegatronBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MegatronBertConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MPNetConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MPNetConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RobertaConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.RobertaConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RoFormerConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.RoFormerConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.TransfoXLConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.TransfoXLConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.XLNetConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.XLNetConfig</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transformers4rec.torch.utils.html#module-transformers4rec.torch.utils">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading">#</a></h2>
</section>
<section id="module-transformers4rec.torch.masking">
<span id="transformers4rec-torch-masking-module"></span><h2>transformers4rec.torch.masking module<a class="headerlink" href="#module-transformers4rec.torch.masking" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskingInfo">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.masking.</span></span><span class="sig-name descname"><span class="pre">MaskingInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskingInfo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskingInfo" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskingInfo.schema">
<span class="sig-name descname"><span class="pre">schema</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#transformers4rec.torch.masking.MaskingInfo.schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskingInfo.targets">
<span class="sig-name descname"><span class="pre">targets</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#transformers4rec.torch.masking.MaskingInfo.targets" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.masking.</span></span><span class="sig-name descname"><span class="pre">MaskSequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin" title="transformers4rec.torch.utils.torch_utils.OutputSizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutputSizeMixin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Base class to prepare masked items inputs/labels for language modeling tasks.</p>
<p>Transformer architectures can be trained in different ways. Depending of the training method,
there is a specific masking schema. The masking schema sets the items to be predicted (labels)
and mask (hide) their positions in the sequence so that they are not used by the Transformer
layers for prediction.</p>
<dl class="simple">
<dt>We currently provide 4 different masking schemes out of the box:</dt><dd><ul class="simple">
<li><p>Causal LM (clm)</p></li>
<li><p>Masked LM (mlm)</p></li>
<li><p>Permutation LM (plm)</p></li>
<li><p>Replacement Token Detection (rtd)</p></li>
</ul>
</dd>
</dl>
<p>This class can be extended to add different a masking scheme.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong>  The hidden dimension of input tensors, needed to initialize trainable vector of
masked positions.</p></li>
<li><p><strong>pad_token</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of the padding token used for getting batch of sequences with the same length</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.compute_masked_targets">
<span class="sig-name descname"><span class="pre">compute_masked_targets</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.masking.MaskingInfo" title="transformers4rec.torch.masking.MaskingInfo"><span class="pre">MaskingInfo</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence.compute_masked_targets"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.compute_masked_targets" title="Permalink to this definition">#</a></dt>
<dd><blockquote>
<div><p>Method to prepare masked labels based on the sequence of item ids.
It returns The true labels of masked positions and the related boolean mask.
And the attributes of the class <cite>mask_schema</cite> and <cite>masked_targets</cite>
are updated to be re-used in other modules.</p>
<dl class="simple">
<dt>item_ids: torch.Tensor</dt><dd><p>The sequence of input item ids used for deriving labels of
next item prediction task.</p>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>training: bool</dt><dd><p>Flag to indicate whether we are in <cite>Training</cite> mode or not.
During training, the labels can be any items within the sequence
based on the selected masking task.</p>
</dd>
<dt>testing: bool</dt><dd><p>Flag to indicate whether we are in <cite>Evaluation</cite> (=True)
or <cite>Inference</cite> (=False) mode.
During evaluation, we are predicting all next items or last item only
in the sequence based on the param <cite>eval_on_last_item_seq_only</cite>.
During inference, we dont mask the input sequence and use all available
information to predict the next item.</p>
<p>Tuple[MaskingSchema, MaskedTargets]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.apply_mask_to_inputs">
<span class="sig-name descname"><span class="pre">apply_mask_to_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence.apply_mask_to_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.apply_mask_to_inputs" title="Permalink to this definition">#</a></dt>
<dd><p>Control the masked positions in the inputs by replacing the true interaction
by a learnable masked embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.Tensor</em>)  The 3-D tensor of interaction embeddings resulting from the ops:
TabularFeatures + aggregation + projection(optional)</p></li>
<li><p><strong>schema</strong> (<em>MaskingSchema</em>)  The boolean mask indicating masked positions.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.predict_all">
<span class="sig-name descname"><span class="pre">predict_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.masking.MaskingInfo" title="transformers4rec.torch.masking.MaskingInfo"><span class="pre">MaskingInfo</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence.predict_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.predict_all" title="Permalink to this definition">#</a></dt>
<dd><p>Prepare labels for all next item predictions instead of
last-item predictions in a users sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>item_ids</strong> (<em>torch.Tensor</em>)  The sequence of input item ids used for deriving labels of
next item prediction task.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[MaskingSchema, MaskedTargets]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.transformer_required_arguments">
<span class="sig-name descname"><span class="pre">transformer_required_arguments</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence.transformer_required_arguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.transformer_required_arguments" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.transformer_optional_arguments">
<span class="sig-name descname"><span class="pre">transformer_optional_arguments</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskSequence.transformer_optional_arguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.transformer_optional_arguments" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskSequence.transformer_arguments">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transformer_arguments</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.masking.MaskSequence.transformer_arguments" title="Permalink to this definition">#</a></dt>
<dd><p>Prepare additional arguments to pass to the Transformer forward methods.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.CausalLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.masking.</span></span><span class="sig-name descname"><span class="pre">CausalLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#CausalLanguageModeling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.CausalLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskSequence</span></code></a></p>
<p>In Causal Language Modeling (clm) you predict the next item based on past positions of the
sequence. Future positions are masked.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>train_on_last_item_seq_only</strong> (<em>predict only last item during training</em>)  </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.CausalLanguageModeling.apply_mask_to_inputs">
<span class="sig-name descname"><span class="pre">apply_mask_to_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#CausalLanguageModeling.apply_mask_to_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.CausalLanguageModeling.apply_mask_to_inputs" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskedLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.masking.</span></span><span class="sig-name descname"><span class="pre">MaskedLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlm_probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.15</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskedLanguageModeling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskedLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskSequence</span></code></a></p>
<p>In Masked Language Modeling (mlm) you randomly select some positions of the sequence to be
predicted, which are masked.
During training, the Transformer layer is allowed to use positions on the right (future info).
During inference, all past items are visible for the Transformer layer, which tries to predict
the next item.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>mlm_probability</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>default = 0.15</em>)  Probability of an item to be selected (masked) as a label of the given sequence.
p.s. We enforce that at least one item is masked for each sequence, so that the network can
learn something with it.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.MaskedLanguageModeling.apply_mask_to_inputs">
<span class="sig-name descname"><span class="pre">apply_mask_to_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#MaskedLanguageModeling.apply_mask_to_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.MaskedLanguageModeling.apply_mask_to_inputs" title="Permalink to this definition">#</a></dt>
<dd><blockquote>
<div><p>Control the masked positions in the inputs by replacing the true interaction
by a learnable masked embedding.</p>
<dl class="simple">
<dt>inputs: torch.Tensor</dt><dd><p>The 3-D tensor of interaction embeddings resulting from the ops:
TabularFeatures + aggregation + projection(optional)</p>
</dd>
<dt>schema: MaskingSchema</dt><dd><p>The boolean mask indicating masked positions.</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>training: bool</dt><dd><p>Flag to indicate whether we are in <cite>Training</cite> mode or not.
During training, the labels can be any items within the sequence
based on the selected masking task.</p>
</dd>
<dt>testing: bool</dt><dd><p>Flag to indicate whether we are in <cite>Evaluation</cite> (=True)
or <cite>Inference</cite> (=False) mode.
During evaluation, we are predicting all next items or last item only
in the sequence based on the param <cite>eval_on_last_item_seq_only</cite>.
During inference, we dont mask the input sequence and use all available
information to predict the next item.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.PermutationLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.masking.</span></span><span class="sig-name descname"><span class="pre">PermutationLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plm_probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.16666666666666666</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_span_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">permute_all</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#PermutationLanguageModeling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.PermutationLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskSequence</span></code></a></p>
<p>In Permutation Language Modeling (plm) you use a permutation factorization at the level of the
self-attention layer to define the accessible bidirectional context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>max_span_length</strong> (<em>int</em>)  maximum length of a span of masked items</p></li>
<li><p><strong>plm_probability</strong> (<em>float</em>)  The ratio of surrounding items to unmask to define the context of the span-based
prediction segment of items</p></li>
<li><p><strong>permute_all</strong> (<em>bool</em>)  Compute partial span-based prediction (=False) or not.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.PermutationLanguageModeling.compute_masked_targets">
<span class="sig-name descname"><span class="pre">compute_masked_targets</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.masking.MaskingInfo" title="transformers4rec.torch.masking.MaskingInfo"><span class="pre">MaskingInfo</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#PermutationLanguageModeling.compute_masked_targets"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.PermutationLanguageModeling.compute_masked_targets" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.PermutationLanguageModeling.transformer_required_arguments">
<span class="sig-name descname"><span class="pre">transformer_required_arguments</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#PermutationLanguageModeling.transformer_required_arguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.PermutationLanguageModeling.transformer_required_arguments" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.ReplacementLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.masking.</span></span><span class="sig-name descname"><span class="pre">ReplacementLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_from_batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#ReplacementLanguageModeling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.ReplacementLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.masking.MaskedLanguageModeling" title="transformers4rec.torch.masking.MaskedLanguageModeling"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskedLanguageModeling</span></code></a></p>
<p>Replacement Language Modeling (rtd) you use MLM to randomly select some items, but replace
them by random tokens.
Then, a discriminator model (that can share the weights with the generator or not), is asked
to classify whether the item at each position belongs or not to the original sequence.
The generator-discriminator architecture was jointly trained using Masked LM and RTD tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>sample_from_batch</strong> (<em>bool</em>)  Whether to sample replacement item ids from the same batch or not</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.ReplacementLanguageModeling.get_fake_tokens">
<span class="sig-name descname"><span class="pre">get_fake_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">itemid_seq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_flat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#ReplacementLanguageModeling.get_fake_tokens"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.ReplacementLanguageModeling.get_fake_tokens" title="Permalink to this definition">#</a></dt>
<dd><p>Second task of RTD is binary classification to train the discriminator.
The task consists of generating fake data by replacing [MASK] positions with random items,
ELECTRA discriminator learns to detect fake replacements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>itemid_seq</strong> (<em>torch.Tensor</em><em> of </em><em>shape</em><em> (</em><em>bs</em><em>, </em><em>max_seq_len</em><em>)</em>)  input sequence of item ids</p></li>
<li><p><strong>target_flat</strong> (<em>torch.Tensor</em><em> of </em><em>shape</em><em> (</em><em>bs*max_seq_len</em><em>)</em>)  flattened masked label sequences</p></li>
<li><p><strong>logits</strong> (<em>torch.Tensor</em><em> of </em><em>shape</em><em> (</em><em>#pos_item</em><em>, </em><em>vocab_size</em><em> or </em><em>#pos_item</em><em>)</em><em>,</em>)  mlm probabilities of positive items computed by the generator model.
The logits are over the whole corpus if sample_from_batch = False,
over the positive items (masked) of the current batch otherwise</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>corrupted_inputs</strong> (<em>torch.Tensor of shape (bs, max_seq_len)</em>)  input sequence of item ids with fake replacement</p></li>
<li><p><strong>discriminator_labels</strong> (<em>torch.Tensor of shape (bs, max_seq_len)</em>)  binary labels to distinguish between original and replaced items</p></li>
<li><p><strong>batch_updates</strong> (<em>torch.Tensor of shape (#pos_item)</em>)  the indices of replacement item within the current batch if sample_from_batch is enabled</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.masking.ReplacementLanguageModeling.sample_from_softmax">
<span class="sig-name descname"><span class="pre">sample_from_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/masking.html#ReplacementLanguageModeling.sample_from_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.masking.ReplacementLanguageModeling.sample_from_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>Sampling method for replacement token modeling (ELECTRA)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logits</strong> (<em>torch.Tensor</em><em>(</em><em>pos_item</em><em>, </em><em>vocab_size</em><em>)</em>)  scores of probability of masked positions returned  by the generator model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>samples</strong>  ids of replacements items.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor(#pos_item)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-transformers4rec.torch.ranking_metric">
<span id="transformers4rec-torch-ranking-metric-module"></span><h2>transformers4rec.torch.ranking_metric module<a class="headerlink" href="#module-transformers4rec.torch.ranking_metric" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.RankingMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.ranking_metric.</span></span><span class="sig-name descname"><span class="pre">RankingMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#RankingMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.RankingMetric" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></p>
<p>Metric wrapper for computing ranking metrics&#64;K for session-based task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>top_ks</strong> (<em>list</em><em>, </em><em>default</em><em> [</em><em>2</em><em>, </em><em>5</em><em>]</em><em>)</em>)  list of cutoffs</p></li>
<li><p><strong>labels_onehot</strong> (<em>bool</em>)  Enable transform the labels to one-hot representation</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.RankingMetric.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#RankingMetric.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.RankingMetric.update" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.RankingMetric.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#RankingMetric.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.RankingMetric.compute" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.PrecisionAt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.ranking_metric.</span></span><span class="sig-name descname"><span class="pre">PrecisionAt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#PrecisionAt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.PrecisionAt" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.ranking_metric.RankingMetric" title="transformers4rec.torch.ranking_metric.RankingMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">RankingMetric</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.RecallAt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.ranking_metric.</span></span><span class="sig-name descname"><span class="pre">RecallAt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#RecallAt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.RecallAt" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.ranking_metric.RankingMetric" title="transformers4rec.torch.ranking_metric.RankingMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">RankingMetric</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.AvgPrecisionAt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.ranking_metric.</span></span><span class="sig-name descname"><span class="pre">AvgPrecisionAt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#AvgPrecisionAt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.AvgPrecisionAt" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.ranking_metric.RankingMetric" title="transformers4rec.torch.ranking_metric.RankingMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">RankingMetric</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.DCGAt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.ranking_metric.</span></span><span class="sig-name descname"><span class="pre">DCGAt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#DCGAt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.DCGAt" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.ranking_metric.RankingMetric" title="transformers4rec.torch.ranking_metric.RankingMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">RankingMetric</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.NDCGAt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.ranking_metric.</span></span><span class="sig-name descname"><span class="pre">NDCGAt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#NDCGAt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.NDCGAt" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.ranking_metric.RankingMetric" title="transformers4rec.torch.ranking_metric.RankingMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">RankingMetric</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ranking_metric.MeanReciprocalRankAt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.ranking_metric.</span></span><span class="sig-name descname"><span class="pre">MeanReciprocalRankAt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">top_ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/ranking_metric.html#MeanReciprocalRankAt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ranking_metric.MeanReciprocalRankAt" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.ranking_metric.RankingMetric" title="transformers4rec.torch.ranking_metric.RankingMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">RankingMetric</span></code></a></p>
</dd></dl>

</section>
<section id="module-transformers4rec.torch.trainer">
<span id="transformers4rec-torch-trainer-module"></span><h2>transformers4rec.torch.trainer module<a class="headerlink" href="#module-transformers4rec.torch.trainer" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.trainer.</span></span><span class="sig-name descname"><span class="pre">Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.model.base.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.trainer.T4RecTrainingArguments" title="transformers4rec.config.trainer.T4RecTrainingArguments"><span class="pre">T4RecTrainingArguments</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset_or_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataset_or_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset_or_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">TrainerCallback</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental_logging</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
<p>An <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> specialized for sequential recommendation
including (session-based and sequtial recommendation)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.Model"><em>Model</em></a>)  The Model defined using Transformers4Rec api.</p></li>
<li><p><strong>args</strong> (<a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.trainer.T4RecTrainingArguments" title="transformers4rec.config.trainer.T4RecTrainingArguments"><em>T4RecTrainingArguments</em></a>)  The training arguments needed to setup training and evaluation
experiments.</p></li>
<li><p><strong>schema</strong> (<em>Optional</em><em>[</em><em>Dataset.schema</em><em>]</em><em>, </em><em>optional</em>)  The schema object including features to use and their properties.
by default None</p></li>
<li><p><strong>train_dataset_or_path</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset" title="merlin.io.Dataset"><em>Dataset</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Path of parquet files or DataSet to use for training.
by default None</p></li>
<li><p><strong>eval_dataset_or_path</strong> (<em>Optional</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset" title="merlin.io.Dataset"><em>Dataset</em></a><em>]</em><em>, </em><em>optional</em>)  Path of parquet files or DataSet to use for evaluation.
by default None</p></li>
<li><p><strong>train_dataloader</strong> (<em>Optional</em><em>[</em><em>DataLoader</em><em>]</em><em>, </em><em>optional</em>)  The data generator to use for training.
by default None</p></li>
<li><p><strong>eval_dataloader</strong> (<em>Optional</em><em>[</em><em>DataLoader</em><em>]</em><em>, </em><em>optional</em>)  The data generator to use for evaluation.
by default None</p></li>
<li><p><strong>compute_metrics</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em><em>, </em><em>optional</em>)  Whether to compute metrics defined by Model class or not.
by default None</p></li>
<li><p><strong>incremental_logging</strong> (<em>bool</em>)  Whether to enable incremental logging or not. If True, it ensures that
global steps are incremented over many <cite>trainer.train()</cite> calls, so that
train and eval metrics steps do not overlap and can be seen properly
in reports like W&amp;B and Tensorboard</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.get_train_dataloader">
<span class="sig-name descname"><span class="pre">get_train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_train_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.get_train_dataloader" title="Permalink to this definition">#</a></dt>
<dd><p>Set the train dataloader to use by Trainer.
It supports user defined data-loader set as an attribute in the constructor.
When the attribute is None, The data-loader is defined using train_dataset
and the <cite>data_loader_engine</cite> specified in Training Arguments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.get_eval_dataloader">
<span class="sig-name descname"><span class="pre">get_eval_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_eval_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.get_eval_dataloader" title="Permalink to this definition">#</a></dt>
<dd><p>Set the eval dataloader to use by Trainer.
It supports user defined data-loader set as an attribute in the constructor.
When the attribute is None, The data-loader is defined using eval_dataset
and the <cite>data_loader_engine</cite> specified in Training Arguments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.get_test_dataloader">
<span class="sig-name descname"><span class="pre">get_test_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_test_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.get_test_dataloader" title="Permalink to this definition">#</a></dt>
<dd><p>Set the test dataloader to use by Trainer.
It supports user defined data-loader set as an attribute in the constructor.
When the attribute is None, The data-loader is defined using test_dataset
and the <cite>data_loader_engine</cite> specified in Training Arguments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.num_examples">
<span class="sig-name descname"><span class="pre">num_examples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.num_examples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.num_examples" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <a class="reference internal" href="#transformers4rec.torch.trainer.Trainer.num_examples" title="transformers4rec.torch.trainer.Trainer.num_examples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.num_examples()</span></code></a> method because
the data loaders for this project do not return the dataset size,
but the number of steps. So we estimate the dataset size here
by multiplying the number of steps * batch size</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.reset_lr_scheduler">
<span class="sig-name descname"><span class="pre">reset_lr_scheduler</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.reset_lr_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.reset_lr_scheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Resets the LR scheduler of the previous <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.train()</span></code> call,
so that a new LR scheduler one is created by the next <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.train()</span></code> call.
This is important for LR schedules like <cite>get_linear_schedule_with_warmup()</cite>
which decays LR to 0 in the end of the train</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.create_scheduler">
<span class="sig-name descname"><span class="pre">create_scheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_training_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Optimizer</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.create_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.create_scheduler" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.get_scheduler">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_scheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">SchedulerType</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_warmup_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_training_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_cycles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.get_scheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Unified API to get any scheduler from its name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code> or <cite>:obj:`SchedulerType</cite>))  The name of the scheduler to use.</p></li>
<li><p><strong>optimizer</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code>))  The optimizer that will be used during training.</p></li>
<li><p><strong>num_warmup_steps</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>))  The number of warm-up steps to perform. This is not required by all schedulers
(hence the argument being optional),
the function will raise an error if its unset and the scheduler type requires it.</p></li>
<li><p><strong>num_training_steps</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>))  The number of training steps to do. This is not required by all schedulers
(hence the argument being optional),
the function will raise an error if its unset and the scheduler type requires it.</p></li>
<li><p><strong>num_cycles</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>))  The number of waves in the cosine schedule /
hard restarts to use for cosine scheduler</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.compute_loss">
<span class="sig-name descname"><span class="pre">compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.compute_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.compute_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <a class="reference internal" href="#transformers4rec.torch.trainer.Trainer.compute_loss" title="transformers4rec.torch.trainer.Trainer.compute_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.compute_loss()</span></code></a>
To allow for passing the targets to the models forward method
How the loss is computed by Trainer. By default, all Transformers4Rec models return
a dictionary of three elements {loss, predictions, and labels}</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.prediction_step">
<span class="sig-name descname"><span class="pre">prediction_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_loss_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.prediction_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.prediction_step" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <a class="reference internal" href="#transformers4rec.torch.trainer.Trainer.prediction_step" title="transformers4rec.torch.trainer.Trainer.prediction_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.prediction_step()</span></code></a>
to provide more flexibility to unpack results from the model,
like returning labels that are not exactly one input feature
model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.evaluation_loop">
<span class="sig-name descname"><span class="pre">evaluation_loop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_loss_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_key_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eval'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">EvalLoopOutput</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.evaluation_loop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.evaluation_loop" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.prediction_loop()</span></code>
(shared by <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.evaluate()</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.predict()</span></code>)
to provide more flexibility to work with streaming metrics
(computed at each eval batch) and
to log with the outputs of the model
(e.g. prediction scores, prediction metadata, attention weights)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataloader</strong> (<em>DataLoader</em>)  DataLoader object to use to iterate over evaluation data</p></li>
<li><p><strong>description</strong> (<em>str</em>)  Parameter to describe the evaluation experiment.
e.g: <cite>Prediction</cite>, <cite>test</cite></p></li>
<li><p><strong>prediction_loss_only</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>)  Whether or not to return the loss only.
by default None</p></li>
<li><p><strong>ignore_keys</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>)  Columns not accepted by the <code class="docutils literal notranslate"><span class="pre">model.forward()</span></code> method
are automatically removed.
by default None</p></li>
<li><p><strong>metric_key_prefix</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>)  Prefix to use when logging evaluation metrics.
by default <cite>eval</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.load_model_trainer_states_from_checkpoint">
<span class="sig-name descname"><span class="pre">load_model_trainer_states_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.load_model_trainer_states_from_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.load_model_trainer_states_from_checkpoint" title="Permalink to this definition">#</a></dt>
<dd><p>This method loads the checkpoints states of the model, trainer and random states.
If model is None the serialized model class is loaded from checkpoint.
It does not loads the optimizer and LR scheduler states (for that call trainer.train()
with resume_from_checkpoint argument for a complete load)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<em>str</em>)  Path to the checkpoint directory.</p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.Model"><em>Model</em></a><em>]</em>)  Model class used by Trainer. by default None</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.log_predictions_callback">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">log_predictions_callback</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.log_predictions_callback" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.Trainer.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.log"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.Trainer.log" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.process_metrics">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.trainer.</span></span><span class="sig-name descname"><span class="pre">process_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metrics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_cpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#process_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.process_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.IncrementalLoggingCallback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.trainer.</span></span><span class="sig-name descname"><span class="pre">IncrementalLoggingCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#transformers4rec.torch.trainer.Trainer" title="transformers4rec.torch.trainer.Trainer"><span class="pre">Trainer</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#IncrementalLoggingCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainerCallback</span></code></p>
<p>An <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainerCallback</span></code> that changes the state of the Trainer
on specific hooks for the purpose of the incremental logging
:param trainer:
:type trainer: Trainer</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_begin">
<span class="sig-name descname"><span class="pre">on_train_begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">control</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#IncrementalLoggingCallback.on_train_begin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_begin" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">control</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#IncrementalLoggingCallback.on_train_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_end" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.IncrementalLoggingCallback.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">control</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#IncrementalLoggingCallback.on_epoch_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_epoch_end" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.trainer.DatasetMock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.trainer.</span></span><span class="sig-name descname"><span class="pre">DatasetMock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nsteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#DatasetMock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.trainer.DatasetMock" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sized</span></code></p>
<p>Mock to inform HF Trainer that the dataset is sized,
and can be obtained via the generated/provided data loader</p>
</dd></dl>

</section>
<section id="module-transformers4rec.torch.typing">
<span id="transformers4rec-torch-typing-module"></span><h2>transformers4rec.torch.typing module<a class="headerlink" href="#module-transformers4rec.torch.typing" title="Permalink to this heading">#</a></h2>
</section>
<section id="module-transformers4rec.torch">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-transformers4rec.torch" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">Schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature:</span> <span class="pre">~typing.Sequence[~merlin_standard_lib.proto.schema_bp.Feature]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_feature:</span> <span class="pre">~typing.List[~merlin_standard_lib.proto.schema_bp.SparseFeature]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighted_feature:</span> <span class="pre">~typing.List[~merlin_standard_lib.proto.schema_bp.WeightedFeature]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">string_domain:</span> <span class="pre">~typing.List[~merlin_standard_lib.proto.schema_bp.StringDomain]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">float_domain:</span> <span class="pre">~typing.List[~merlin_standard_lib.proto.schema_bp.FloatDomain]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">int_domain:</span> <span class="pre">~typing.List[~merlin_standard_lib.proto.schema_bp.IntDomain]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_environment:</span> <span class="pre">~typing.List[str]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">annotation:</span> <span class="pre">~merlin_standard_lib.proto.schema_bp.Annotation</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_constraints:</span> <span class="pre">~merlin_standard_lib.proto.schema_bp.DatasetConstraints</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_representation_group:</span> <span class="pre">~typing.Dict[str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">~merlin_standard_lib.proto.schema_bp.TensorRepresentationGroup]</span> <span class="pre">=</span> <span class="pre">&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Schema</span></code></p>
<p>A collection of column schemas for a dataset.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.feature">
<span class="sig-name descname"><span class="pre">feature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.ColumnSchema" title="merlin_standard_lib.schema.schema.ColumnSchema"><span class="pre">ColumnSchema</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">Field(name=None,type=None,default=&lt;betterproto._PLACEHOLDER</span> <span class="pre">object&gt;,default_factory=&lt;dataclasses._MISSING_TYPE</span> <span class="pre">object&gt;,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'betterproto':</span> <span class="pre">FieldMetadata(number=1,</span> <span class="pre">proto_type='message',</span> <span class="pre">map_types=None,</span> <span class="pre">group=None,</span> <span class="pre">wraps=None)}),_field_type=None)</span></em><a class="headerlink" href="#transformers4rec.torch.Schema.feature" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.create">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">column_schemas</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.ColumnSchema" title="merlin_standard_lib.schema.schema.ColumnSchema"><span class="pre">ColumnSchema</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.ColumnSchema" title="merlin_standard_lib.schema.schema.ColumnSchema"><span class="pre">ColumnSchema</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.create"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.create" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.with_tags_based_on_properties">
<span class="sig-name descname"><span class="pre">with_tags_based_on_properties</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">using_value_count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">using_domain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.with_tags_based_on_properties"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.with_tags_based_on_properties" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">selector</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.apply"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.apply" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.apply_inverse">
<span class="sig-name descname"><span class="pre">apply_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">selector</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.apply_inverse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.apply_inverse" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.filter_columns_from_dict">
<span class="sig-name descname"><span class="pre">filter_columns_from_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.filter_columns_from_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.filter_columns_from_dict" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.select_by_type">
<span class="sig-name descname"><span class="pre">select_by_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_select</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.select_by_type"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.select_by_type" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.remove_by_type">
<span class="sig-name descname"><span class="pre">remove_by_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_remove</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.remove_by_type"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.remove_by_type" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.select_by_tag">
<span class="sig-name descname"><span class="pre">select_by_tag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_select</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.select_by_tag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.select_by_tag" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.remove_by_tag">
<span class="sig-name descname"><span class="pre">remove_by_tag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_remove</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.remove_by_tag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.remove_by_tag" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.select_by_name">
<span class="sig-name descname"><span class="pre">select_by_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_select</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.select_by_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.select_by_name" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.remove_by_name">
<span class="sig-name descname"><span class="pre">remove_by_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_remove</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.remove_by_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.remove_by_name" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.map_column_schemas">
<span class="sig-name descname"><span class="pre">map_column_schemas</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.ColumnSchema" title="merlin_standard_lib.schema.schema.ColumnSchema"><span class="pre">ColumnSchema</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.ColumnSchema" title="merlin_standard_lib.schema.schema.ColumnSchema"><span class="pre">ColumnSchema</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.map_column_schemas"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.map_column_schemas" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.filter_column_schemas">
<span class="sig-name descname"><span class="pre">filter_column_schemas</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filter_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.ColumnSchema" title="merlin_standard_lib.schema.schema.ColumnSchema"><span class="pre">ColumnSchema</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.filter_column_schemas"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.filter_column_schemas" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.column_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">column_names</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.Schema.column_names" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.column_schemas">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">column_schemas</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.ColumnSchema" title="merlin_standard_lib.schema.schema.ColumnSchema"><span class="pre">ColumnSchema</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.Schema.column_schemas" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.item_id_column_name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">item_id_column_name</span></span><a class="headerlink" href="#transformers4rec.torch.Schema.item_id_column_name" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.from_json">
<span class="sig-name descname"><span class="pre">from_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bytes</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.from_json"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.from_json" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.to_proto_text">
<span class="sig-name descname"><span class="pre">to_proto_text</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.to_proto_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.to_proto_text" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.from_proto_text">
<span class="sig-name descname"><span class="pre">from_proto_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_or_proto_text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.from_proto_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.from_proto_text" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.copy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.copy" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Schema.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_overlap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></span><a class="reference internal" href="../_modules/merlin_standard_lib/schema/schema.html#Schema.add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Schema.add" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.requires_schema">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">requires_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/schema.html#requires_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.requires_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">T4RecConfig</span></span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#T4RecConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.T4RecConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class responsible for setting the configuration of the transformers class
from Hugging Face and returning the corresponding T4Rec model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecConfig.to_huggingface_torch_model">
<span class="sig-name descname"><span class="pre">to_huggingface_torch_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#T4RecConfig.to_huggingface_torch_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.T4RecConfig.to_huggingface_torch_model" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiate a Hugging Face transformer model based on
the configuration parameters of the class.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The Hugging Face transformer model.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>transformers.PreTrainedModel</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecConfig.to_torch_model">
<span class="sig-name descname"><span class="pre">to_torch_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">prediction_task</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#T4RecConfig.to_torch_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.T4RecConfig.to_torch_model" title="Permalink to this definition">#</a></dt>
<dd><p>Links the Hugging Face transformer model to the given input block and prediction tasks,
and returns a T4Rec model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_features</strong> (<em>torch4rec.TabularSequenceFeatures</em>)  The sequential block that represents the input features and
defines the masking strategy for training and evaluation.</p></li>
<li><p><strong>prediction_task</strong> (<em>torch4rec.PredictionTask</em>)  One or multiple prediction tasks.</p></li>
<li><p><strong>task_blocks</strong> (<em>list</em><em>, </em><em>optional</em>)  List of task-specific blocks that we apply on top of the HF transformers output.</p></li>
<li><p><strong>task_weights</strong> (<em>list</em><em>, </em><em>optional</em>)  List of the weights to use for combining the tasks losses.</p></li>
<li><p><strong>loss_reduction</strong> (<em>str</em><em>, </em><em>optional</em>)  <dl class="simple">
<dt>The reduction to apply to the prediction losses, possible values are:</dt><dd><p>none: no reduction will be applied,
mean: the weighted mean of the output is taken,
sum: the output will be summed.</p>
</dd>
</dl>
<p>By default: mean.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The T4Rec torch model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch4rec.Model</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong>  If input block or prediction task is of the wrong type.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecConfig.transformers_config_cls">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transformers_config_cls</span></span><a class="headerlink" href="#transformers4rec.torch.T4RecConfig.transformers_config_cls" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecConfig.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#T4RecConfig.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.T4RecConfig.build" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.GPT2Config">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">GPT2Config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50257</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_positions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_embd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">768</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu_new'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resid_pdrop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embd_pdrop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_pdrop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cls_index'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_use_proj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_proj_to_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_first_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_attn_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_attn_by_inverse_layer_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reorder_and_upcast_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#GPT2Config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.GPT2Config" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig" title="transformers4rec.config.transformer.T4RecConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">GPT2Config</span></code></p>
<p>Subclass of T4RecConfig and transformers.GPT2Config from Hugging Face.
It handles configuration for GPT2 layers in the context of T4Rec models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.GPT2Config.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_attention_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#GPT2Config.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.GPT2Config.build" title="Permalink to this definition">#</a></dt>
<dd><p>Creates an instance of GPT2Config with the given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>{transformer_cfg_parameters}</strong>  </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of GPT2Config.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.GPT2Config" title="transformers4rec.torch.GPT2Config">GPT2Config</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.XLNetConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">XLNetConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">24</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ff_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">untie_r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bi'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mem_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reuse_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mems_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mems_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bi_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clamp_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'last'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_use_proj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_last_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_n_top</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_n_top</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#XLNetConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.XLNetConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig" title="transformers4rec.config.transformer.T4RecConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">XLNetConfig</span></code></p>
<p>Subclass of T4RecConfig and transformers.XLNetConfig from Hugging Face.
It handles configuration for XLNetConfig layers in the context of T4Rec models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.XLNetConfig.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bi'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_attention_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mem_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#XLNetConfig.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.XLNetConfig.build" title="Permalink to this definition">#</a></dt>
<dd><p>Creates an instance of XLNetConfig with the given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>{transformer_cfg_parameters}</strong>  </p></li>
<li><p><strong>mem_len</strong> (<em>int</em><em>,</em>)  The number of tokens to be cached. Pre-computed key/value pairs
from a previous forward pass are stored and wont be re-computed.
This parameter is especially useful for long sequence modeling where
different batches may truncate the entire sequence.
Tasks like user-aware recommendation could benefit from this feature.
By default, this parameter is set to 1, which means no caching is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of XLNetConfig.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.XLNetConfig" title="transformers4rec.torch.XLNetConfig">XLNetConfig</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TransfoXLConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TransfoXLConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">267735</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoffs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[20000,</span> <span class="pre">40000,</span> <span class="pre">200000]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_embed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_head</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">div_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_lnorm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">18</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mem_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1600</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clamp_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">same_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_share_all_but_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_softmax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adaptive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropatt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">untie_r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'normal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_init_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#TransfoXLConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TransfoXLConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig" title="transformers4rec.config.transformer.T4RecConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TransfoXLConfig</span></code></p>
<p>Subclass of T4RecConfig and transformers. TransfoXLConfig from Hugging Face.
It handles configuration for TransfoXLConfig layers in the context of T4Rec models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TransfoXLConfig.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_attention_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#TransfoXLConfig.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TransfoXLConfig.build" title="Permalink to this definition">#</a></dt>
<dd><p>Creates an instance of TransfoXLConfig with the given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>{transformer_cfg_parameters}</strong>  </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of TransfoXLConfig.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.TransfoXLConfig" title="transformers4rec.torch.TransfoXLConfig">TransfoXLConfig</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.LongformerConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">LongformerConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attention_window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30522</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">768</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hidden_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_attention_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3072</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dropout_prob</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_probs_dropout_prob</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_position_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_vocab_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onnx_export</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#LongformerConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.LongformerConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig" title="transformers4rec.config.transformer.T4RecConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LongformerConfig</span></code></p>
<p>Subclass of T4RecConfig and transformers.LongformerConfig from Hugging Face.
It handles configuration for LongformerConfig layers in the context of T4Rec models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.LongformerConfig.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_attention_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#LongformerConfig.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.LongformerConfig.build" title="Permalink to this definition">#</a></dt>
<dd><p>Creates an instance of LongformerConfig with the given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>{transformer_cfg_parameters}</strong>  </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of LongformerConfig.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.LongformerConfig" title="transformers4rec.torch.LongformerConfig">LongformerConfig</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.AlbertConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">AlbertConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hidden_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hidden_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_attention_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16384</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_group_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu_new'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_probs_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_position_embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">position_embedding_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'absolute'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#AlbertConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.AlbertConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig" title="transformers4rec.config.transformer.T4RecConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">AlbertConfig</span></code></p>
<p>Subclass of T4RecConfig and transformers.AlbertConfig from Hugging Face.
It handles configuration for AlbertConfig layers in the context of T4Rec models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.AlbertConfig.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_attention_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#AlbertConfig.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.AlbertConfig.build" title="Permalink to this definition">#</a></dt>
<dd><p>Creates an instance of AlbertConfig with the given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>{transformer_cfg_parameters}</strong>  </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of AlbertConfig.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.AlbertConfig" title="transformers4rec.torch.AlbertConfig">AlbertConfig</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ReformerConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">ReformerConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attention_head_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['local',</span> <span class="pre">'lsh',</span> <span class="pre">'local',</span> <span class="pre">'lsh',</span> <span class="pre">'local',</span> <span class="pre">'lsh']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axial_norm_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axial_pos_embds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axial_pos_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[64,</span> <span class="pre">64]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axial_pos_embds_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[64,</span> <span class="pre">192]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size_lm_head</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feed_forward_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hash_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_decoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_num_chunks_before</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_num_chunks_after</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_attention_probs_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_attn_chunk_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lsh_attn_chunk_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lsh_attention_probs_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lsh_num_chunks_before</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lsh_num_chunks_after</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_position_embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_attention_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_buckets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hashes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">320</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tie_word_embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#ReformerConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ReformerConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig" title="transformers4rec.config.transformer.T4RecConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReformerConfig</span></code></p>
<p>Subclass of T4RecConfig and transformers.ReformerConfig from Hugging Face.
It handles configuration for Reformer layers in the context of T4Rec models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ReformerConfig.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_attention_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axial_pos_shape_first_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#ReformerConfig.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ReformerConfig.build" title="Permalink to this definition">#</a></dt>
<dd><p>Creates an instance of ReformerConfig with the given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>{transformer_cfg_parameters}</strong>  </p></li>
<li><p><strong>axial_pos_shape_first_dim</strong> (<em>int</em><em>, </em><em>optional</em>)  The first dimension of the axial position encodings.
During training, the product of the position dims has to be equal to the sequence length.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of ReformerConfig.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.ReformerConfig" title="transformers4rec.torch.ReformerConfig">ReformerConfig</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ElectraConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">ElectraConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30522</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hidden_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_attention_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_probs_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_position_embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type_vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'first'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_use_proj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_last_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">position_embedding_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'absolute'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#ElectraConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElectraConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig" title="transformers4rec.config.transformer.T4RecConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ElectraConfig</span></code></p>
<p>Subclass of T4RecConfig and transformers.ElectraConfig from Hugging Face.
It handles configuration for ElectraConfig layers in the context of T4Rec models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ElectraConfig.build">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gelu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_attention_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/transformer.html#ElectraConfig.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElectraConfig.build" title="Permalink to this definition">#</a></dt>
<dd><p>Creates an instance of ElectraConfig with the given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>{transformer_cfg_parameters}</strong>  </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of ElectraConfig.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.ElectraConfig" title="transformers4rec.torch.ElectraConfig">ElectraConfig</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">T4RecTrainingArguments</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_output_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_predict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">IntervalStrategy</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'no'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_loss_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_device_train_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_device_eval_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_gpu_train_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_gpu_eval_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_accumulation_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_accumulation_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_delay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adam_beta1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adam_beta2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adam_epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_grad_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_train_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">SchedulerType</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_level</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'passive'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_level_replica</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'warning'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_on_each_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">IntervalStrategy</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'steps'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_first_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_nan_inf_filter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">IntervalStrategy</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'steps'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_total_limit</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_safetensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_on_each_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_cuda</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mps_device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jit_mode_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_ipex</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bf16</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp16</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp16_opt_level</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'O1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">half_precision_backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bf16_full_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp16_full_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tf32</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_rank</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddp_backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tpu_num_cores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tpu_metrics_debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_drop_last</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_num_workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">past_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_tqdm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_unused_columns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_best_model_at_end</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_for_best_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">greater_is_better</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_data_skip</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sharded_ddp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fsdp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fsdp_min_num_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fsdp_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fsdp_transformer_layer_cls_to_wrap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deepspeed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">OptimizerNames</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'adamw_hf'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adafactor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_by_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length_column_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'length'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_to</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddp_find_unused_parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddp_bucket_cap_mb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_pin_memory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_memory_metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_legacy_prediction_loop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume_from_checkpoint</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hub_model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hub_strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">HubStrategy</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'every_save'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hub_token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hub_private_repo</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_checkpointing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_inputs_for_metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp16_backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub_model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub_organization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">push_to_hub_token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mp_parameters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_find_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_determinism</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torchdynamo</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ray_scope</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'last'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddp_timeout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1800</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_compile</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_compile_backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_compile_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xpu_backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle_buffer_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader_engine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'merlin'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_test_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_steps_on_train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate_num_cosine_cycles_by_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_metrics_each_n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experiments_group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'default'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/config/trainer.html#T4RecTrainingArguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingArguments</span></code></p>
<p>Class that inherits HF TrainingArguments and add on top of it arguments needed for
session-based and sequential-based recommendation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shuffle_buffer_size</strong> (<em>int</em>)  </p></li>
<li><p><strong>validate_every</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>int</em>)  Run validation set every this epoch.
-1 means no validation is used
by default -1</p></li>
<li><p><strong>eval_on_test_set</strong> (<em>bool</em>)  </p></li>
<li><p><strong>eval_steps_on_train_set</strong> (<em>int</em>)  </p></li>
<li><p><strong>predict_top_k</strong> (<em>Option</em><em>[</em><em>int</em><em>]</em><em>, </em><em>int</em>)  Truncate recommendation list to the highest top-K predicted items,
(do not affect evaluation metrics computation),
This parameter is specific to NextItemPredictionTask and only affects
model.predict() and model.evaluate(), which both call <cite>Trainer.evaluation_loop</cite>.
By default 100.</p></li>
<li><p><strong>log_predictions</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em><em>, </em><em>bool</em>)  log predictions, labels and metadata features each compute_metrics_each_n_steps
(for test set).
by default False</p></li>
<li><p><strong>log_attention_weights</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em><em>, </em><em>bool</em>)  Logs the inputs and attention weights
each eval_steps (only test set)
by default False</p></li>
<li><p><strong>learning_rate_num_cosine_cycles_by_epoch</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>int</em>)  Number of cycles for by epoch when lr_scheduler_type = cosine_with_warmup.
The number of waves in the cosine schedule
(e.g. 0.5 is to just decrease from the max value to 0, following a half-cosine).
by default 1.25</p></li>
<li><p><strong>experiments_group</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>str</em>)  Name of the Experiments Group, for organizing job runs logged on W&amp;B
by default default</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.max_sequence_length">
<span class="sig-name descname"><span class="pre">max_sequence_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.max_sequence_length" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.shuffle_buffer_size">
<span class="sig-name descname"><span class="pre">shuffle_buffer_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.shuffle_buffer_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.data_loader_engine">
<span class="sig-name descname"><span class="pre">data_loader_engine</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'merlin'</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.data_loader_engine" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.eval_on_test_set">
<span class="sig-name descname"><span class="pre">eval_on_test_set</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.eval_on_test_set" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.eval_steps_on_train_set">
<span class="sig-name descname"><span class="pre">eval_steps_on_train_set</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">20</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.eval_steps_on_train_set" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.predict_top_k">
<span class="sig-name descname"><span class="pre">predict_top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">100</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.predict_top_k" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.learning_rate_num_cosine_cycles_by_epoch">
<span class="sig-name descname"><span class="pre">learning_rate_num_cosine_cycles_by_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.25</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.learning_rate_num_cosine_cycles_by_epoch" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.log_predictions">
<span class="sig-name descname"><span class="pre">log_predictions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.log_predictions" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.compute_metrics_each_n_steps">
<span class="sig-name descname"><span class="pre">compute_metrics_each_n_steps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.compute_metrics_each_n_steps" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.experiments_group">
<span class="sig-name descname"><span class="pre">experiments_group</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'default'</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.experiments_group" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.place_model_on_device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">place_model_on_device</span></span><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.place_model_on_device" title="Permalink to this definition">#</a></dt>
<dd><p>Override the method to allow running training on cpu</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.T4RecTrainingArguments.output_dir">
<span class="sig-name descname"><span class="pre">output_dir</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#transformers4rec.torch.T4RecTrainingArguments.output_dir" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">SequentialBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Size</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">BlockBase</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequential</span></code></p>
<p>Extends the module torch.nn.Sequential. Its used for creating
a sequence of layers or blocks in a T4Rec model. The modules
will be applied to inputs in the order they are passed in the constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong>  The list of PyTorch modules.</p></li>
<li><p><strong>output_size</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>torch.Size</em><em>]</em><em>, </em><em>optional</em>)  The expected output size from the last layer in the sequential block
By default None</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.inputs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inputs</span></span><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.inputs" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock.add_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.add_module" title="Permalink to this definition">#</a></dt>
<dd><p>Adds a PyTorch module to the sequential block. If a list of strings is provided,
a <cite>FilterFeatures</cite> block gets added to the sequential block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>)  The name of the child module. The child module can be accessed
from this module using the given name.</p></li>
<li><p><strong>module</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>Module</em><em>]</em><em>]</em>)  The child module to be added to the module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.add_module_and_maybe_build">
<span class="sig-name descname"><span class="pre">add_module_and_maybe_build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parent</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock.add_module_and_maybe_build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.add_module_and_maybe_build" title="Permalink to this definition">#</a></dt>
<dd><p>Checks if a module needs to be built and adds it to the sequential block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>)  The name of the child module.</p></li>
<li><p><strong>module</strong> (<em>torch.nn.Module</em>)  The child module to be added to the sequential block.</p></li>
<li><p><strong>parent</strong> (<em>torch.nn.Module</em>)  The parent module.</p></li>
<li><p><strong>idx</strong> (<em>int</em>)  The index of the current module in the sequential block.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Applies the modules layers sequentially to the input block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>tensor</em>)  The input to the block.</p></li>
<li><p><strong>training</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether the block is in training mode. The default is False.</p></li>
<li><p><strong>testing</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether the block is in testing mode. The default is False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.build" title="Permalink to this definition">#</a></dt>
<dd><p>Builds the layers of the sequential block given the input size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>torch.Size</em><em>]</em>)  The size of the input tensor(s).</p></li>
<li><p><strong>schema</strong> (<a class="reference internal" href="#transformers4rec.torch.Schema" title="transformers4rec.torch.Schema"><em>Schema</em></a><em>, </em><em>optional</em>)  The schema of the inputs features, by default None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The built sequential block.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.SequentialBlock" title="transformers4rec.torch.SequentialBlock">SequentialBlock</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.as_tabular">
<span class="sig-name descname"><span class="pre">as_tabular</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock.as_tabular"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.as_tabular" title="Permalink to this definition">#</a></dt>
<dd><p>Converts the output of the block into a dictionary, keyed by the
provided name</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>)  The output name, if not provided, uses the name of the block class.
by default None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd><p>Calculates the output size of the tensor(s) returned by the forward pass,
given the input size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_size</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>torch.Size</em><em>]</em>)  The size of the input tensor(s) to the module.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The size of the output from the module.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[List[int], torch.Size]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialBlock.get_children_by_class_name">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_children_by_class_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parent</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">class_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#SequentialBlock.get_children_by_class_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialBlock.get_children_by_class_name" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.right_shift_block">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">right_shift_block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#right_shift_block"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.right_shift_block" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.build_blocks">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">build_blocks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">modules</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#build_blocks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.build_blocks" title="Permalink to this definition">#</a></dt>
<dd><p>Builds a SequentialBlock from a list of PyTorch modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*modules</strong> (<em>List</em><em>[</em><em>torch.nn.Module</em><em>]</em>)  List containing PyTorch modules.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A SequentialBlock instance created from the provided modules.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.BlockBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">BlockBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#BlockBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.BlockBase" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin" title="transformers4rec.torch.utils.torch_utils.OutputSizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutputSizeMixin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A subclass of PyTorchs torch.nn.Module, providing additional functionality
for dealing with automatic setting of input/output dimensions of neural networks layers.
Specifically, It implements the OutputSizeMixin for managing output sizes.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.BlockBase.to_model">
<span class="sig-name descname"><span class="pre">to_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction_task_or_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#BlockBase.to_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.BlockBase.to_model" title="Permalink to this definition">#</a></dt>
<dd><p>Converts the BlockBase instance into a T4Rec model by attaching it to
attaching a Head or PredictionTask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction_task_or_head</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.PredictionTask" title="transformers4rec.torch.PredictionTask"><em>PredictionTask</em></a><em>, </em><a class="reference internal" href="#transformers4rec.torch.Head" title="transformers4rec.torch.Head"><em>Head</em></a><em>]</em>)  A PredictionTask or Head instance to attach to this block.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.base.InputBlock" title="transformers4rec.torch.features.base.InputBlock"><em>InputBlock</em></a><em>, </em><em>optional</em>)  The input block representing input features.
By default None</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong>  If prediction_task_or_head is neither a Head nor a PredictionTask.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.BlockBase.as_tabular">
<span class="sig-name descname"><span class="pre">as_tabular</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#BlockBase.as_tabular"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.BlockBase.as_tabular" title="Permalink to this definition">#</a></dt>
<dd><p>Converts the output of the block into a dictionary, keyed by the
provided name</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>)  The output name, if not provided, uses the name of the block class.
by default None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularBlock" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">BlockBase</span></code></a>, <a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>TabularBlock extends TabularModule to turn it into a block with output size info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularBlock.to_module">
<span class="sig-name descname"><span class="pre">to_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape_or_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularBlock.to_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularBlock.to_module" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularBlock.output_size">
<span class="sig-name descname"><span class="pre">output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularBlock.output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularBlock.output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularBlock.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularBlock.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularBlock.build" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.Block">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">Block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Size</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#Block"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Block" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">BlockBase</span></code></a></p>
<p>Wraps a PyTorch module, allowing it to be used as a block in a T4Rec model.
It carries the module and its expected output size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>torch.nn.Module</em>)  The PyTorch module to be wrapped in this block.</p></li>
<li><p><strong>output_size</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>torch.Size</em><em>]</em>)  The expected output size of the module.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Block.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#Block.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Block.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Block.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/base.html#Block.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Block.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd><p>Calculates the output size of the tensor(s) returned by the forward pass,
given the input size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_size</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>torch.Size</em><em>]</em>)  The size of the input tensor(s) to the module.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The size of the output from the module.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[List[int], torch.Size]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.MLPBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">MLPBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dimensions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout:</span> <span class="pre">~typing.Optional[float]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization:</span> <span class="pre">~typing.Optional[str]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_features=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/mlp.html#MLPBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.MLPBlock" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">BuildableBlock</span></code></a></p>
<p>Defines Multi-Layer Perceptron (MLP) Block by stacking
multiple DenseBlock instances.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dimensions</strong> (<em>int</em><em> or </em><em>list</em><em> of </em><em>int</em>)  The dimensions of the layers in the MLP.
If an integer is provided, a single layer MLP is created.
If a list is provided, it must contain the size of each layer in order.</p></li>
<li><p><strong>activation</strong> (<em>optional</em>)  The activation function to apply after each layer.
By default <cite>torch.nn.ReLU</cite>.</p></li>
<li><p><strong>use_bias</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether to add a bias term to the dense layers.
by default True</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>optional</em>)  The dropout rate to apply after each layer, by default None</p></li>
<li><p><strong>normalization</strong> (<em>str</em><em>, </em><em>optional</em>)  The normalization to apply after each layer, by default None</p></li>
<li><p><strong>filter_features</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  List of features to select from the input., by default None</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.MLPBlock.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock" title="transformers4rec.torch.block.base.SequentialBlock"><span class="pre">SequentialBlock</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/block/mlp.html#MLPBlock.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.MLPBlock.build" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularTransformation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularTransformation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularTransformation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularTransformation" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin" title="transformers4rec.torch.utils.torch_utils.OutputSizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutputSizeMixin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Transformation that takes in <cite>TabularData</cite> and outputs <cite>TabularData</cite>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularTransformation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularTransformation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularTransformation.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularTransformation.parse">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">class_or_str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularTransformation.parse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularTransformation.parse" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialTabularTransformations">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">SequentialTabularTransformations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">transformation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#SequentialTabularTransformations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialTabularTransformations" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.SequentialBlock" title="transformers4rec.torch.block.base.SequentialBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequentialBlock</span></code></a></p>
<p>A sequential container, modules will be added to it in the order they are passed in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>transformation</strong> (<em>TabularTransformationType</em>)  transformations that are passed in here will be called in order.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequentialTabularTransformations.append">
<span class="sig-name descname"><span class="pre">append</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transformation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#SequentialTabularTransformations.append"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequentialTabularTransformations.append" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularAggregation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularAggregation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularAggregation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularAggregation" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.OutputSizeMixin" title="transformers4rec.torch.utils.torch_utils.OutputSizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutputSizeMixin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Aggregation of <cite>TabularData</cite> that outputs a single <cite>Tensor</cite></p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularAggregation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularAggregation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularAggregation.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularAggregation.parse">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">class_or_str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularAggregation.parse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularAggregation.parse" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.StochasticSwapNoise">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">StochasticSwapNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replacement_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#StochasticSwapNoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.StochasticSwapNoise" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularTransformation</span></code></a></p>
<p>Applies Stochastic replacement of sequence features.
It can be applied as a <cite>pre</cite> transform like <cite>TransformerBlock(pre=stochastic-swap-noise)</cite></p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.StochasticSwapNoise.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#StochasticSwapNoise.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.StochasticSwapNoise.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.StochasticSwapNoise.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#StochasticSwapNoise.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.StochasticSwapNoise.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.StochasticSwapNoise.augment">
<span class="sig-name descname"><span class="pre">augment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#StochasticSwapNoise.augment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.StochasticSwapNoise.augment" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularLayerNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularLayerNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularLayerNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularLayerNorm" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularTransformation</span></code></a></p>
<p>Applies Layer norm to each input feature individually, before the aggregation</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularLayerNorm.from_feature_config">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_feature_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><span class="pre">FeatureConfig</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularLayerNorm.from_feature_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularLayerNorm.from_feature_config" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularLayerNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularLayerNorm.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularLayerNorm.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularLayerNorm.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularLayerNorm.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularLayerNorm.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularLayerNorm.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularLayerNorm.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularLayerNorm.build" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularDropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularDropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularDropout" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularTransformation</span></code></a></p>
<p>Applies dropout transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularDropout.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularDropout.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularDropout.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularDropout.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/transformations.html#TabularDropout.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularDropout.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TransformerBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TransformerBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">transformer:</span> <span class="pre">~typing.Union[~transformers.modeling_utils.PreTrainedModel,</span> <span class="pre">~transformers.configuration_utils.PretrainedConfig],</span> <span class="pre">masking:</span> <span class="pre">~typing.Optional[~transformers4rec.torch.masking.MaskSequence]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">prepare_module:</span> <span class="pre">~typing.Optional[~typing.Type[~transformers4rec.torch.block.transformer.TransformerPrepare]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">output_fn=&lt;function</span> <span class="pre">TransformerBlock.&lt;lambda&gt;&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/transformer.html#TransformerBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TransformerBlock" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">BlockBase</span></code></a></p>
<p>Class to support HF Transformers for session-based and sequential-based recommendation models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transformer</strong> (<em>TransformerBody</em>)  The T4RecConfig or a pre-trained HF object related to specific transformer architecture.</p></li>
<li><p><strong>masking</strong>  Needed when masking is applied on the inputs.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TransformerBlock.TRANSFORMER_TO_PREPARE">
<span class="sig-name descname"><span class="pre">TRANSFORMER_TO_PREPARE</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">PreTrainedModel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.transformer.TransformerPrepare" title="transformers4rec.torch.block.transformer.TransformerPrepare"><span class="pre">TransformerPrepare</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{&lt;class</span> <span class="pre">'transformers.models.gpt2.modeling_gpt2.GPT2Model'&gt;:</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.block.transformer.GPT2Prepare'&gt;}</span></em><a class="headerlink" href="#transformers4rec.torch.TransformerBlock.TRANSFORMER_TO_PREPARE" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TransformerBlock.from_registry">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_registry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transformer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_seq_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><span class="pre">MaskSequence</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/transformer.html#TransformerBlock.from_registry"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TransformerBlock.from_registry" title="Permalink to this definition">#</a></dt>
<dd><p>Load the HF transformer architecture based on its name</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transformer</strong> (<em>str</em>)  Name of the Transformer to use. Possible values are :
[reformer, gtp2, longformer, electra, albert, xlnet]</p></li>
<li><p><strong>d_model</strong> (<em>int</em>)  size of hidden states for Transformers</p></li>
<li><p><strong>n_head</strong>  Number of attention heads for Transformers</p></li>
<li><p><strong>n_layer</strong> (<em>int</em>)  Number of layers for RNNs and Transformers</p></li>
<li><p><strong>total_seq_length</strong> (<em>int</em>)  The maximum sequence length</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TransformerBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs_embeds</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/transformer.html#TransformerBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TransformerBlock.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Transformer Models</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TransformerBlock.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/block/transformer.html#TransformerBlock.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TransformerBlock.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ContinuousFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">ContinuousFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ContinuousFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.base.InputBlock" title="transformers4rec.torch.features.base.InputBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputBlock</span></code></a></p>
<p>Input block for continuous features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>)  List of continuous features to include in this module.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ContinuousFeatures.from_features">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures.from_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ContinuousFeatures.from_features" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ContinuousFeatures.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ContinuousFeatures.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ContinuousFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ContinuousFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.EmbeddingFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">EmbeddingFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><span class="pre">FeatureConfig</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.EmbeddingFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.base.InputBlock" title="transformers4rec.torch.features.base.InputBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputBlock</span></code></a></p>
<p>Input block for embedding-lookups for categorical features.</p>
<p>For multi-hot features, the embeddings will be aggregated into a single tensor using the mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_config</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.FeatureConfig" title="transformers4rec.torch.FeatureConfig"><em>FeatureConfig</em></a><em>]</em>)  This specifies what TableConfig to use for each feature. For shared embeddings, the same
TableConfig can be used for multiple features.</p></li>
<li><p><strong>item_id</strong> (<em>str</em><em>, </em><em>optional</em>)  The name of the feature thats used for the item_id.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>pre: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p>
</dd>
<dt>post: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p>
</dd>
<dt>aggregation: Union[str, TabularAggregation], optional</dt><dd><p>Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.EmbeddingFeatures.item_embedding_table">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">item_embedding_table</span></span><a class="headerlink" href="#transformers4rec.torch.EmbeddingFeatures.item_embedding_table" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.EmbeddingFeatures.table_to_embedding_module">
<span class="sig-name descname"><span class="pre">table_to_embedding_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">TableConfig</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.table_to_embedding_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.EmbeddingFeatures.table_to_embedding_module" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.EmbeddingFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim_default</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infer_embedding_sizes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infer_embedding_sizes_multiplier</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings_initializers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">TagSet</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.tags.Tags"><span class="pre">Tags</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.tags.Tags"><span class="pre">Tags</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">automatic_build</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><span class="pre">EmbeddingFeatures</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.EmbeddingFeatures.from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Instantitates <code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>)  Dataset schema</p></li>
<li><p><strong>embedding_dims</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  The dimension of the embedding table for each feature (key),
by default None by default None</p></li>
<li><p><strong>default_embedding_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  Default dimension of the embedding table, when the feature is not found
in <code class="docutils literal notranslate"><span class="pre">default_soft_embedding_dim</span></code>, by default 64</p></li>
<li><p><strong>infer_embedding_sizes</strong> (<em>bool</em><em>, </em><em>optional</em>)  Automatically defines the embedding dimension from the
feature cardinality in the schema,
by default False</p></li>
<li><p><strong>infer_embedding_sizes_multiplier</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>by default 2.0</em>)  multiplier used by the heuristic to infer the embedding dimension from
its cardinality. Generally reasonable values range between 2.0 and 10.0</p></li>
<li><p><strong>embeddings_initializers</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em><em>]</em>)  Dict where keys are feature names and values are callable to initialize embedding tables</p></li>
<li><p><strong>combiner</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  Feature aggregation option, by default mean</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><em>list</em><em>, </em><em>str</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  Tags to filter columns, by default None</p></li>
<li><p><strong>item_id</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  Name of the item id column (feature), by default None</p></li>
<li><p><strong>automatic_build</strong> (<em>bool</em><em>, </em><em>optional</em>)  Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  Maximum sequence length for list features,, by default None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns the <code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code> for the dataset schema</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#transformers4rec.torch.EmbeddingFeatures" title="transformers4rec.torch.EmbeddingFeatures">EmbeddingFeatures</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.EmbeddingFeatures.item_ids">
<span class="sig-name descname"><span class="pre">item_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.item_ids"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.EmbeddingFeatures.item_ids" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.EmbeddingFeatures.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.EmbeddingFeatures.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.EmbeddingFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.EmbeddingFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.SoftEmbeddingFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">SoftEmbeddingFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><span class="pre">FeatureConfig</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwarg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbeddingFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SoftEmbeddingFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code></a></p>
<p>Encapsulate continuous features encoded using the Soft-one hot encoding
embedding technique (SoftEmbedding),    from <a class="reference external" href="https://arxiv.org/pdf/1708.00065.pdf">https://arxiv.org/pdf/1708.00065.pdf</a>
In a nutshell, it keeps an embedding table for each continuous feature,
which is represented as a weighted average of embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_config</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.FeatureConfig" title="transformers4rec.torch.FeatureConfig"><em>FeatureConfig</em></a><em>]</em>)  This specifies what TableConfig to use for each feature. For shared embeddings, the same
TableConfig can be used for multiple features.</p></li>
<li><p><strong>layer_norm</strong> (<em>boolean</em>)  When layer_norm is true, TabularLayerNorm will be used in post.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SoftEmbeddingFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_cardinalities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_cardinality_default</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_dim_default</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings_initializers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">TagSet</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.tags.Tags"><span class="pre">Tags</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.tags.Tags"><span class="pre">Tags</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">automatic_build</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures" title="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures"><span class="pre">SoftEmbeddingFeatures</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbeddingFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SoftEmbeddingFeatures.from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Instantitates <code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>)  Dataset schema</p></li>
<li><p><strong>soft_embedding_cardinalities</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  The cardinality of the embedding table for each feature (key),
by default None</p></li>
<li><p><strong>soft_embedding_cardinality_default</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  Default cardinality of the embedding table, when the feature
is not found in <code class="docutils literal notranslate"><span class="pre">soft_embedding_cardinalities</span></code>, by default 10</p></li>
<li><p><strong>soft_embedding_dims</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  The dimension of the embedding table for each feature (key), by default None</p></li>
<li><p><strong>soft_embedding_dim_default</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  Default dimension of the embedding table, when the feature
is not found in <code class="docutils literal notranslate"><span class="pre">soft_embedding_dim_default</span></code>, by default 8</p></li>
<li><p><strong>embeddings_initializers</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em><em>]</em>)  Dict where keys are feature names and values are callable to initialize embedding tables</p></li>
<li><p><strong>combiner</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  Feature aggregation option, by default mean</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><em>list</em><em>, </em><em>str</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  Tags to filter columns, by default None</p></li>
<li><p><strong>automatic_build</strong> (<em>bool</em><em>, </em><em>optional</em>)  Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  Maximum sequence length for list features, by default None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns a <code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code> instance from the dataset schema</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#transformers4rec.torch.SoftEmbeddingFeatures" title="transformers4rec.torch.SoftEmbeddingFeatures">SoftEmbeddingFeatures</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SoftEmbeddingFeatures.table_to_embedding_module">
<span class="sig-name descname"><span class="pre">table_to_embedding_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">TableConfig</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbedding" title="transformers4rec.torch.features.embedding.SoftEmbedding"><span class="pre">SoftEmbedding</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbeddingFeatures.table_to_embedding_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SoftEmbeddingFeatures.table_to_embedding_module" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingsInitializer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">PretrainedEmbeddingsInitializer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight_matrix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingsInitializer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Initializer of embedding tables with pre-trained weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight_matrix</strong> (<em>Union</em><em>[</em><em>torch.Tensor</em><em>, </em><em>List</em><em>[</em><em>List</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em>)  A 2D torch or numpy tensor or lists of lists with the pre-trained
weights for embeddings. The expect dims are
(embedding_cardinality, embedding_dim). The embedding_cardinality
can be inferred from the column schema, for example,
<cite>schema.select_by_name(item_id).feature[0].int_domain.max + 1</cite>.
The first position of the embedding table is reserved for padded
items (id=0).</p></li>
<li><p><strong>trainable</strong> (<em>bool</em>)  Whether the embedding table should be trainable or not</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingsInitializer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingsInitializer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingsInitializer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">PretrainedEmbeddingFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained_output_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_combiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.base.InputBlock" title="transformers4rec.torch.features.base.InputBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputBlock</span></code></a></p>
<p>Input block for pre-trained embeddings features.</p>
<p>For 3-D features, if sequence_combiner is set, the features are aggregated
using the second dimension (sequence length)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>)  A list of the pre-trained embeddings feature names.
You typically will pass schema.select_by_tag(Tags.EMBEDDING).column_names,
as that is the tag added to pre-trained embedding features when using the
merlin.dataloader.ops.embeddings.EmbeddingOperator</p></li>
<li><p><strong>pretrained_output_dims</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>int</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em><em>]</em><em>]</em>)  If provided, it projects features to specified dim(s).
If an int, all features are projected to that dim.
If a dict, only features provided in the dict will be mapped to the specified dim,</p></li>
<li><p><strong>sequence_combiner</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.nn.Module</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  A string (mean, sum, max, min) or torch.nn.Module specifying
how to combine the second dimension of the pre-trained embeddings if it is 3D.
Default is None (no sequence combiner used)</p></li>
<li><p><strong>normalizer</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>TabularTransformationType</em><em>]</em><em>]</em>)  A tabular layer (e.g.tr.TabularLayerNorm()) or string (layer-norm) to be applied
to pre-trained embeddings after projected and sequence combined
Default is None (no normalization)</p></li>
<li><p><strong>(</strong><strong>Optional</strong><strong>[</strong><strong>Schema</strong><strong>]</strong><strong>)</strong> (<em>schema</em>)  </p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingFeatures.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingFeatures.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.build" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">TagSet</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.tags.Tags"><span class="pre">Tags</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.tags.Tags"><span class="pre">Tags</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained_output_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.from_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingFeatures.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PretrainedEmbeddingFeatures.parse_combiner">
<span class="sig-name descname"><span class="pre">parse_combiner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">combiner</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingFeatures.parse_combiner"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.parse_combiner" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularSequenceFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">continuous_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained_embedding_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projection_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><span class="pre">MaskSequence</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularFeatures</span></code></a></p>
<p>Input module that combines different types of features to a sequence: continuous,
categorical &amp; text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>continuous_module</strong> (<a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>)  Module used to process continuous features.</p></li>
<li><p><strong>categorical_module</strong> (<a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>)  Module used to process categorical features.</p></li>
<li><p><strong>text_embedding_module</strong> (<a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>)  Module used to process text features.</p></li>
<li><p><strong>projection_module</strong> (<em>BlockOrModule</em><em>, </em><em>optional</em>)  Module thats used to project the output of this module, typically done by an MLPBlock.</p></li>
<li><p><strong>masking</strong> (<a class="reference internal" href="#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><em>MaskSequence</em></a><em>, </em><em>optional</em>)  Masking to apply to the inputs.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.EMBEDDING_MODULE_CLASS">
<span class="sig-name descname"><span class="pre">EMBEDDING_MODULE_CLASS</span></span><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.EMBEDDING_MODULE_CLASS" title="Permalink to this definition">#</a></dt>
<dd><p>alias of <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures" title="transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">schema:</span> <span class="pre">~merlin_standard_lib.schema.schema.Schema,</span> <span class="pre">continuous_tags:</span> <span class="pre">~typing.Optional[~typing.Union[~merlin.schema.tags.TagSet,</span> <span class="pre">~typing.List[str],</span> <span class="pre">~typing.List[~merlin.schema.tags.Tags],</span> <span class="pre">~typing.List[~typing.Union[str,</span> <span class="pre">~merlin.schema.tags.Tags]],</span> <span class="pre">~typing.Tuple[~merlin.schema.tags.Tags]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tags.CONTINUOUS:</span> <span class="pre">'continuous'&gt;,),</span> <span class="pre">categorical_tags:</span> <span class="pre">~typing.Optional[~typing.Union[~merlin.schema.tags.TagSet,</span> <span class="pre">~typing.List[str],</span> <span class="pre">~typing.List[~merlin.schema.tags.Tags],</span> <span class="pre">~typing.List[~typing.Union[str,</span> <span class="pre">~merlin.schema.tags.Tags]],</span> <span class="pre">~typing.Tuple[~merlin.schema.tags.Tags]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tags.CATEGORICAL:</span> <span class="pre">'categorical'&gt;,),</span> <span class="pre">pretrained_embeddings_tags:</span> <span class="pre">~typing.Optional[~typing.Union[~merlin.schema.tags.TagSet,</span> <span class="pre">~typing.List[str],</span> <span class="pre">~typing.List[~merlin.schema.tags.Tags],</span> <span class="pre">~typing.List[~typing.Union[str,</span> <span class="pre">~merlin.schema.tags.Tags]],</span> <span class="pre">~typing.Tuple[~merlin.schema.tags.Tags]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tags.EMBEDDING:</span> <span class="pre">'embedding'&gt;,),</span> <span class="pre">aggregation:</span> <span class="pre">~typing.Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">automatic_build:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">max_sequence_length:</span> <span class="pre">~typing.Optional[int]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_projection:</span> <span class="pre">~typing.Optional[~typing.Union[~typing.List[int],</span> <span class="pre">int]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_soft_embeddings:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">projection:</span> <span class="pre">~typing.Optional[~typing.Union[~torch.nn.modules.module.Module,</span> <span class="pre">~transformers4rec.torch.block.base.BuildableBlock]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">d_output:</span> <span class="pre">~typing.Optional[int]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">masking:</span> <span class="pre">~typing.Optional[~typing.Union[str,</span> <span class="pre">~transformers4rec.torch.masking.MaskSequence]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">**kwargs</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures" title="transformers4rec.torch.features.sequence.TabularSequenceFeatures"><span class="pre">TabularSequenceFeatures</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiates <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>)  Dataset schema</p></li>
<li><p><strong>continuous_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>TagsType</em><em>, </em><em>Tuple</em><em>[</em><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.Tags"><em>Tags</em></a><em>]</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  Tags to filter the continuous features, by default Tags.CONTINUOUS</p></li>
<li><p><strong>categorical_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>TagsType</em><em>, </em><em>Tuple</em><em>[</em><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.Tags"><em>Tags</em></a><em>]</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  Tags to filter the categorical features, by default Tags.CATEGORICAL</p></li>
<li><p><strong>aggregation</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  Feature aggregation option, by default None</p></li>
<li><p><strong>automatic_build</strong> (<em>bool</em><em>, </em><em>optional</em>)  Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  Maximum sequence length for list features by default None</p></li>
<li><p><strong>continuous_projection</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>int</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  If set, concatenate all numerical features and project them by a number of MLP layers.
The argument accepts a list with the dimensions of the MLP layers, by default None</p></li>
<li><p><strong>continuous_soft_embeddings</strong> (<em>bool</em>)  Indicates if the  soft one-hot encoding technique must be used to represent
continuous features, by default False</p></li>
<li><p><strong>projection</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>torch.nn.Module</em><em>, </em><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><em>BuildableBlock</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  If set, project the aggregated embeddings vectors into hidden dimension vector space,
by default None</p></li>
<li><p><strong>d_output</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  If set, init a MLPBlock as projection module to project embeddings vectors,
by default None</p></li>
<li><p><strong>masking</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><em>MaskSequence</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  If set, Apply masking to the input embeddings and compute masked labels, It requires
a categorical_module including an item_id column, by default None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a dataset schema</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.TabularFeatures" title="transformers4rec.torch.TabularFeatures">TabularFeatures</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.masking">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">masking</span></span><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.masking" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.set_masking">
<span class="sig-name descname"><span class="pre">set_masking</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.set_masking"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.set_masking" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.item_id">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">item_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.item_id" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.item_embedding_table">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">item_embedding_table</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.item_embedding_table" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.project_continuous_features">
<span class="sig-name descname"><span class="pre">project_continuous_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dimensions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.project_continuous_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.project_continuous_features" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularSequenceFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularSequenceFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.SequenceEmbeddingFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">SequenceEmbeddingFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><span class="pre">FeatureConfig</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#SequenceEmbeddingFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequenceEmbeddingFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code></a></p>
<p>Input block for embedding-lookups for categorical features. This module produces 3-D tensors,
this is useful for sequential models like transformers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_config</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.FeatureConfig" title="transformers4rec.torch.FeatureConfig"><em>FeatureConfig</em></a><em>]</em>)  This specifies what TableConfig to use for each feature. For shared embeddings, the same
TableConfig can be used for multiple features.</p></li>
<li><p><strong>item_id</strong> (<em>str</em><em>, </em><em>optional</em>)  The name of the feature thats used for the item_id.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>)  The symbol to use for padding.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequenceEmbeddingFeatures.table_to_embedding_module">
<span class="sig-name descname"><span class="pre">table_to_embedding_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">TableConfig</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Embedding</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#SequenceEmbeddingFeatures.table_to_embedding_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequenceEmbeddingFeatures.table_to_embedding_module" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SequenceEmbeddingFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#SequenceEmbeddingFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SequenceEmbeddingFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.FeatureConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">FeatureConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">TableConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#FeatureConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.FeatureConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to set the embeddings table of a categorical feature
with a maximum sequence length.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.FeatureConfig.table">
<span class="sig-name descname"><span class="pre">table</span></span><a class="headerlink" href="#transformers4rec.torch.FeatureConfig.table" title="Permalink to this definition">#</a></dt>
<dd><p>Configuration for the lookup table,
which is used for embedding lookup and aggregation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.TableConfig" title="transformers4rec.torch.TableConfig">TableConfig</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.FeatureConfig.max_sequence_length">
<span class="sig-name descname"><span class="pre">max_sequence_length</span></span><a class="headerlink" href="#transformers4rec.torch.FeatureConfig.max_sequence_length" title="Permalink to this definition">#</a></dt>
<dd><p>Maximum sequence length for sequence features.
By default 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.FeatureConfig.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#transformers4rec.torch.FeatureConfig.name" title="Permalink to this definition">#</a></dt>
<dd><p>The feature name.
By default None</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str, optional</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TableConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TableConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocabulary_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#TableConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TableConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to configure the embeddings lookup table for a categorical feature.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TableConfig.vocabulary_size">
<span class="sig-name descname"><span class="pre">vocabulary_size</span></span><a class="headerlink" href="#transformers4rec.torch.TableConfig.vocabulary_size" title="Permalink to this definition">#</a></dt>
<dd><p>The size of the vocabulary,
i.e., the cardinality of the categorical feature.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TableConfig.dim">
<span class="sig-name descname"><span class="pre">dim</span></span><a class="headerlink" href="#transformers4rec.torch.TableConfig.dim" title="Permalink to this definition">#</a></dt>
<dd><p>The dimensionality of the embedding vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TableConfig.initializer">
<span class="sig-name descname"><span class="pre">initializer</span></span><a class="headerlink" href="#transformers4rec.torch.TableConfig.initializer" title="Permalink to this definition">#</a></dt>
<dd><p>The initializer function for the embedding weights.
If None, the weights are initialized using a normal
distribution with mean 0.0 and standard deviation 0.05.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[Callable[[torch.Tensor], None]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TableConfig.combiner">
<span class="sig-name descname"><span class="pre">combiner</span></span><a class="headerlink" href="#transformers4rec.torch.TableConfig.combiner" title="Permalink to this definition">#</a></dt>
<dd><p>The combiner operation used to aggregate bag of embeddings.
Possible options are mean, sum, and sqrtn.
By default mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TableConfig.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#transformers4rec.torch.TableConfig.name" title="Permalink to this definition">#</a></dt>
<dd><p>The name of the lookup table.
By default None.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[str]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">continuous_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained_embedding_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.MergeTabular" title="transformers4rec.torch.tabular.base.MergeTabular"><code class="xref py py-class docutils literal notranslate"><span class="pre">MergeTabular</span></code></a></p>
<p>Input module that combines different types of features: continuous, categorical &amp; text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>continuous_module</strong> (<a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>)  Module used to process continuous features.</p></li>
<li><p><strong>categorical_module</strong> (<a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>)  Module used to process categorical features.</p></li>
<li><p><strong>text_embedding_module</strong> (<a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>)  Module used to process text features.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>pre: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p>
</dd>
<dt>post: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p>
</dd>
<dt>aggregation: Union[str, TabularAggregation], optional</dt><dd><p>Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.CONTINUOUS_MODULE_CLASS">
<span class="sig-name descname"><span class="pre">CONTINUOUS_MODULE_CLASS</span></span><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.CONTINUOUS_MODULE_CLASS" title="Permalink to this definition">#</a></dt>
<dd><p>alias of <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.continuous.ContinuousFeatures" title="transformers4rec.torch.features.continuous.ContinuousFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">ContinuousFeatures</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.EMBEDDING_MODULE_CLASS">
<span class="sig-name descname"><span class="pre">EMBEDDING_MODULE_CLASS</span></span><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.EMBEDDING_MODULE_CLASS" title="Permalink to this definition">#</a></dt>
<dd><p>alias of <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS">
<span class="sig-name descname"><span class="pre">SOFT_EMBEDDING_MODULE_CLASS</span></span><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS" title="Permalink to this definition">#</a></dt>
<dd><p>alias of <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures" title="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS">
<span class="sig-name descname"><span class="pre">PRETRAINED_EMBEDDING_MODULE_CLASS</span></span><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS" title="Permalink to this definition">#</a></dt>
<dd><p>alias of <a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures" title="transformers4rec.torch.features.embedding.PretrainedEmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.project_continuous_features">
<span class="sig-name descname"><span class="pre">project_continuous_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mlp_layers_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><span class="pre">TabularFeatures</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures.project_continuous_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.project_continuous_features" title="Permalink to this definition">#</a></dt>
<dd><p>Combine all concatenated continuous features with stacked MLP layers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mlp_layers_dims</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>int</em><em>]</em>)  The MLP layer dimensions</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns the same <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> object with the continuous features projected</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.TabularFeatures" title="transformers4rec.torch.TabularFeatures">TabularFeatures</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">schema:</span> <span class="pre">~merlin_standard_lib.schema.schema.Schema,</span> <span class="pre">continuous_tags:</span> <span class="pre">~typing.Optional[~typing.Union[~merlin.schema.tags.TagSet,</span> <span class="pre">~typing.List[str],</span> <span class="pre">~typing.List[~merlin.schema.tags.Tags],</span> <span class="pre">~typing.List[~typing.Union[str,</span> <span class="pre">~merlin.schema.tags.Tags]],</span> <span class="pre">~typing.Tuple[~merlin.schema.tags.Tags]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tags.CONTINUOUS:</span> <span class="pre">'continuous'&gt;,),</span> <span class="pre">categorical_tags:</span> <span class="pre">~typing.Optional[~typing.Union[~merlin.schema.tags.TagSet,</span> <span class="pre">~typing.List[str],</span> <span class="pre">~typing.List[~merlin.schema.tags.Tags],</span> <span class="pre">~typing.List[~typing.Union[str,</span> <span class="pre">~merlin.schema.tags.Tags]],</span> <span class="pre">~typing.Tuple[~merlin.schema.tags.Tags]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tags.CATEGORICAL:</span> <span class="pre">'categorical'&gt;,),</span> <span class="pre">pretrained_embeddings_tags:</span> <span class="pre">~typing.Optional[~typing.Union[~merlin.schema.tags.TagSet,</span> <span class="pre">~typing.List[str],</span> <span class="pre">~typing.List[~merlin.schema.tags.Tags],</span> <span class="pre">~typing.List[~typing.Union[str,</span> <span class="pre">~merlin.schema.tags.Tags]],</span> <span class="pre">~typing.Tuple[~merlin.schema.tags.Tags]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tags.EMBEDDING:</span> <span class="pre">'embedding'&gt;,),</span> <span class="pre">aggregation:</span> <span class="pre">~typing.Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">automatic_build:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">max_sequence_length:</span> <span class="pre">~typing.Optional[int]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_projection:</span> <span class="pre">~typing.Optional[~typing.Union[~typing.List[int],</span> <span class="pre">int]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_soft_embeddings:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">**kwargs</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><span class="pre">TabularFeatures</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiates <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>)  Dataset schema</p></li>
<li><p><strong>continuous_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>TagsType</em><em>, </em><em>Tuple</em><em>[</em><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.Tags"><em>Tags</em></a><em>]</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  Tags to filter the continuous features, by default Tags.CONTINUOUS</p></li>
<li><p><strong>categorical_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>TagsType</em><em>, </em><em>Tuple</em><em>[</em><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html#merlin.schema.Tags" title="merlin.schema.Tags"><em>Tags</em></a><em>]</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  Tags to filter the categorical features, by default Tags.CATEGORICAL</p></li>
<li><p><strong>aggregation</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  Feature aggregation option, by default None</p></li>
<li><p><strong>automatic_build</strong> (<em>bool</em><em>, </em><em>optional</em>)  Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>)  Maximum sequence length for list features by default None</p></li>
<li><p><strong>continuous_projection</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>int</em><em>]</em><em>]</em><em>, </em><em>optional</em>)  If set, concatenate all numerical features and project them by a number of MLP layers.
The argument accepts a list with the dimensions of the MLP layers, by default None</p></li>
<li><p><strong>continuous_soft_embeddings</strong> (<em>bool</em>)  Indicates if the  soft one-hot encoding technique must be used to
represent continuous features, by default False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a dataset schema</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.TabularFeatures" title="transformers4rec.torch.TabularFeatures">TabularFeatures</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.continuous_module">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">continuous_module</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.continuous_module" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.categorical_module">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">categorical_module</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.categorical_module" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularFeatures.pretrained_module">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pretrained_module</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularFeatures.pretrained_module" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.Head">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">Head</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_tasks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.PredictionTask" title="transformers4rec.torch.model.base.PredictionTask"><span class="pre">PredictionTask</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.PredictionTask" title="transformers4rec.torch.model.base.PredictionTask"><span class="pre">PredictionTask</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_blocks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures" title="transformers4rec.torch.features.sequence.TabularSequenceFeatures"><span class="pre">TabularSequenceFeatures</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><span class="pre">TabularFeatures</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LossMixin" title="transformers4rec.torch.utils.torch_utils.LossMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">LossMixin</span></code></a>, <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MetricsMixin" title="transformers4rec.torch.utils.torch_utils.MetricsMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricsMixin</span></code></a></p>
<p>Head of a Model, a head has a single body but could have multiple prediction-tasks.
:param body: TODO
:type body: Block
:param prediction_tasks: TODO
:type prediction_tasks: Union[List[PredictionTask], PredictionTask], optional
:param task_blocks: TODO
:param task_weights: TODO
:type task_weights: List[float], optional
:param loss_reduction: TODO
:type loss_reduction: str, default=mean
:param inputs: TODO
:type inputs: TabularFeaturesType, optional</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.build" title="Permalink to this definition">#</a></dt>
<dd><p>Build each prediction task thats part of the head.
:param body:
:param inputs:
:param device:
:param task_blocks:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">body</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_blocks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_weight_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.sequence.TabularSequenceFeatures" title="transformers4rec.torch.features.sequence.TabularSequenceFeatures"><span class="pre">TabularSequenceFeatures</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><span class="pre">TabularFeatures</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.Head" title="transformers4rec.torch.model.base.Head"><span class="pre">Head</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiate a Head from a Schema through tagged targets.
:param schema: Schema to use for inferring all targets based on the tags.
:type schema: DatasetSchema
:param body:
:param task_blocks:
:param task_weight_dict:
:param loss_reduction:
:param inputs:</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.Head" title="transformers4rec.torch.Head">Head</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.pop_labels">
<span class="sig-name descname"><span class="pre">pop_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.pop_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.pop_labels" title="Permalink to this definition">#</a></dt>
<dd><p>Pop the labels from the different prediction_tasks from the inputs.
:param inputs: Input dictionary containing all targets.
:type inputs: TabularData</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>TabularData</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">call_body</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.calculate_metrics">
<span class="sig-name descname"><span class="pre">calculate_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.calculate_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.calculate_metrics" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate metrics of the task(s) set in the Head instance.
:param predictions: The predictions tensors to use for calculate metrics.</p>
<blockquote>
<div><p>They can be either a torch.Tensor if a single task is used or
a dictionary of torch.Tensor if multiple tasks are used. In the
second case, the dictionary is indexed by the tasks names.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>targets</strong>  The tensor or dictionary of targets to use for computing the metrics of
one or multiple tasks.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.compute_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.compute_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.reset_metrics">
<span class="sig-name descname"><span class="pre">reset_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.reset_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.reset_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.task_blocks">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">task_blocks</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.Head.task_blocks" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.to_model">
<span class="sig-name descname"><span class="pre">to_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.model.base.Model"><span class="pre">Model</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Head.to_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Head.to_model" title="Permalink to this definition">#</a></dt>
<dd><p>Convert the head to a Model.
:rtype: Model</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.Head.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.Head.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">*head:</span> <span class="pre">~transformers4rec.torch.model.base.Head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_weights:</span> <span class="pre">~typing.Optional[~typing.List[float]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_reduction:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer:</span> <span class="pre">~typing.Type[~torch.optim.optimizer.Optimizer]</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name:</span> <span class="pre">~typing.Optional[str]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length:</span> <span class="pre">~typing.Optional[int]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k:</span> <span class="pre">~typing.Optional[int]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LossMixin" title="transformers4rec.torch.utils.torch_utils.LossMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">LossMixin</span></code></a>, <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MetricsMixin" title="transformers4rec.torch.utils.torch_utils.MetricsMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricsMixin</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.calculate_metrics">
<span class="sig-name descname"><span class="pre">calculate_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.calculate_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.calculate_metrics" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate metrics of the task(s) set in the Head instance.
:param predictions: The predictions tensors returned by the model.</p>
<blockquote>
<div><p>They can be either a torch.Tensor if a single task is used or
a dictionary of torch.Tensor if multiple heads/tasks are used. In the
second case, the dictionary is indexed by the tasks names.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>targets</strong>  The tensor or dictionary of targets returned by the model.
They are used for computing the metrics of one or multiple tasks.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.compute_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.compute_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.reset_metrics">
<span class="sig-name descname"><span class="pre">reset_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.reset_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.reset_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.to_lightning">
<span class="sig-name descname"><span class="pre">to_lightning</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.to_lightning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.to_lightning" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataloader=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_epochs=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_metric=True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.fit" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'eval'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.evaluate" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.input_schema">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_schema</span></span><a class="headerlink" href="#transformers4rec.torch.Model.input_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.output_schema">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_schema</span></span><a class="headerlink" href="#transformers4rec.torch.Model.output_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.prediction_tasks">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prediction_tasks</span></span><a class="headerlink" href="#transformers4rec.torch.Model.prediction_tasks" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">PathLike</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'t4rec_model_class'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.save" title="Permalink to this definition">#</a></dt>
<dd><p>Saves the model to f{export_path}/{model_name}.pkl using <cite>cloudpickle</cite>
:param path: Path to the directory where the T4Rec model should be saved.
:type path: Union[str, os.PathLike]
:param model_name:</p>
<blockquote>
<div><dl class="simple">
<dt>the name given to the pickle file storing the T4Rec model,</dt><dd><p>by default t4rec_model_class</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">PathLike</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'t4rec_model_class'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.model.base.Model"><span class="pre">Model</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#Model.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Model.load" title="Permalink to this definition">#</a></dt>
<dd><p>Loads a T4Rec model that was saved with <cite>model.save()</cite>.
:param path: Path to the directory where the T4Rec model is saved.
:type path: Union[str, os.PathLike]
:param model_name:</p>
<blockquote>
<div><dl class="simple">
<dt>the name given to the pickle file storing the T4Rec model,</dt><dd><p>by default t4rec_model_class.</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.Model.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.Model.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">PredictionTask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">loss:</span> <span class="pre">~torch.nn.modules.module.Module,</span> <span class="pre">metrics:</span> <span class="pre">~typing.Optional[~typing.Iterable[~torchmetrics.metric.Metric]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">target_name:</span> <span class="pre">~typing.Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">task_name:</span> <span class="pre">~typing.Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">forward_to_prediction_fn:</span> <span class="pre">~typing.Callable[[~torch.Tensor],</span> <span class="pre">~torch.Tensor]</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">PredictionTask.&lt;lambda&gt;&gt;,</span> <span class="pre">task_block:</span> <span class="pre">~typing.Optional[~typing.Union[~transformers4rec.torch.block.base.BlockBase,</span> <span class="pre">~transformers4rec.torch.block.base.BuildableBlock]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">pre:</span> <span class="pre">~typing.Optional[~typing.Union[~transformers4rec.torch.block.base.BlockBase,</span> <span class="pre">~transformers4rec.torch.block.base.BuildableBlock]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">summary_type:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'last'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.LossMixin" title="transformers4rec.torch.utils.torch_utils.LossMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">LossMixin</span></code></a>, <a class="reference internal" href="transformers4rec.torch.utils.html#transformers4rec.torch.utils.torch_utils.MetricsMixin" title="transformers4rec.torch.utils.torch_utils.MetricsMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MetricsMixin</span></code></a></p>
<p>Individual prediction-task of a model.
:param loss: The loss to use during training of this task.
:type loss: torch.nn.Module
:param metrics: The metrics to calculate during training &amp; evaluation.
:type metrics: torch.nn.Module
:param target_name: Name of the target, this is needed when there are multiple targets.
:type target_name: str, optional
:param task_name: Name of the prediction task, if not provided a name will be automatically constructed based</p>
<blockquote>
<div><p>on the target-name &amp; class-name.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>forward_to_prediction_fn</strong> (<em>Callable</em><em>[</em><em>[</em><em>torch.Tensor</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em>)  Function to apply before the prediction</p></li>
<li><p><strong>task_block</strong> (<em>BlockType</em>)  Module to transform input tensor before computing predictions.</p></li>
<li><p><strong>pre</strong> (<em>BlockType</em>)  Module to compute the predictions probabilities.</p></li>
<li><p><strong>summary_type</strong> (<em>str</em>)  <dl class="simple">
<dt>This is used to summarize a sequence into a single tensor. Accepted values are:</dt><dd><ul>
<li><p><cite>last</cite>  Take the last token hidden state (like XLNet)</p></li>
<li><p><cite>first</cite>  Take the first token hidden state (like Bert)</p></li>
<li><p><cite>mean</cite>  Take the mean of all tokens hidden states</p></li>
<li><p><cite>cls_index</cite>  Supply a Tensor of classification token position (GPT/GPT-2)</p></li>
<li><p><cite>attn</cite>  Not implemented now, use multi-head attention</p></li>
</ul>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.features.html#transformers4rec.torch.features.base.InputBlock" title="transformers4rec.torch.features.base.InputBlock"><span class="pre">InputBlock</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_block</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.build" title="Permalink to this definition">#</a></dt>
<dd><p>The method will be called when block is converted to a model,
i.e when linked to prediction head.
:param block: the model block to link with head
:param device: set the device for the metrics and layers of the task</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.task_name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">task_name</span></span><a class="headerlink" href="#transformers4rec.torch.PredictionTask.task_name" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.child_name">
<span class="sig-name descname"><span class="pre">child_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.child_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.child_name" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.set_metrics">
<span class="sig-name descname"><span class="pre">set_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metrics</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.set_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.set_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.calculate_metrics">
<span class="sig-name descname"><span class="pre">calculate_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.calculate_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.calculate_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.compute_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.compute_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Metric</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.metric_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.metric_name" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.reset_metrics">
<span class="sig-name descname"><span class="pre">reset_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.reset_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.reset_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.to_head">
<span class="sig-name descname"><span class="pre">to_head</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.Head" title="transformers4rec.torch.model.base.Head"><span class="pre">Head</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.to_head"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.to_head" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.to_model">
<span class="sig-name descname"><span class="pre">to_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.model.base.Model"><span class="pre">Model</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/base.html#PredictionTask.to_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.PredictionTask.to_model" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.PredictionTask.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.PredictionTask.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.AsTabular">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">AsTabular</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#AsTabular"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.AsTabular" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularBlock" title="transformers4rec.torch.tabular.base.TabularBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularBlock</span></code></a></p>
<p>Converts a Tensor to TabularData by converting it to a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>output_name</strong> (<em>str</em>)  Name that should be used as the key in the output dictionary.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.AsTabular.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#AsTabular.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.AsTabular.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.AsTabular.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#AsTabular.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.AsTabular.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ConcatFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">ConcatFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ConcatFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ConcatFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularAggregation</span></code></a></p>
<p>Aggregation by stacking all values in TabularData, all non-sequential values will be
converted to a sequence.</p>
<p>The output of this concatenation will have 3 dimensions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ConcatFeatures.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ConcatFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ConcatFeatures.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ConcatFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ConcatFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ConcatFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.FilterFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">FilterFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">to_include</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#FilterFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.FilterFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularTransformation</span></code></a></p>
<p>Module that filters out certain features from <cite>TabularData</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>to_include</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>)  List of features to include in the result of calling the module</p></li>
<li><p><strong>pop</strong> (<em>bool</em>)  Boolean indicating whether to pop the features to exclude from the inputs dictionary.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.FilterFeatures.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#FilterFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.FilterFeatures.forward" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>TabularData</em>)  Input dictionary containing features to filter.</p></li>
<li><p><strong>self.to_include.</strong> (<em>Returns Filtered TabularData that only contains the feature-names in</em>)  </p></li>
<li><p><strong>-------</strong>  </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.FilterFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#FilterFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.FilterFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong>  </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ElementwiseSum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">ElementwiseSum</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ElementwiseSum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElementwiseSum" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseFeatureAggregation" title="transformers4rec.torch.tabular.aggregation.ElementwiseFeatureAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElementwiseFeatureAggregation</span></code></a></p>
<p>Aggregation by first stacking all values in TabularData in the first dimension, and then
summing the result.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ElementwiseSum.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ElementwiseSum.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElementwiseSum.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ElementwiseSum.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ElementwiseSum.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElementwiseSum.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.ElementwiseSumItemMulti">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">ElementwiseSumItemMulti</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ElementwiseSumItemMulti"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElementwiseSumItemMulti" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.tabular.html#transformers4rec.torch.tabular.aggregation.ElementwiseFeatureAggregation" title="transformers4rec.torch.tabular.aggregation.ElementwiseFeatureAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElementwiseFeatureAggregation</span></code></a></p>
<p>Aggregation by applying the <cite>ElementwiseSum</cite> aggregation to all features except the item-id,
and then multiplying this with the item-ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>schema</strong> (<em>DatasetSchema</em>)  </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ElementwiseSumItemMulti.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ElementwiseSumItemMulti.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElementwiseSumItemMulti.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.ElementwiseSumItemMulti.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#ElementwiseSumItemMulti.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.ElementwiseSumItemMulti.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.ElementwiseSumItemMulti.REQUIRES_SCHEMA">
<span class="sig-name descname"><span class="pre">REQUIRES_SCHEMA</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#transformers4rec.torch.ElementwiseSumItemMulti.REQUIRES_SCHEMA" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.MergeTabular">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">MergeTabular</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">modules_to_merge</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#MergeTabular"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.MergeTabular" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularBlock" title="transformers4rec.torch.tabular.base.TabularBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularBlock</span></code></a></p>
<p>Merge multiple TabularModules into a single output of TabularData.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>modules_to_merge</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>]</em><em>]</em>)  TabularModules to merge into, this can also be one or multiple dictionaries keyed by the
name the module should have.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.MergeTabular.merge_values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">merge_values</span></span><a class="headerlink" href="#transformers4rec.torch.MergeTabular.merge_values" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.MergeTabular.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#MergeTabular.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.MergeTabular.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.MergeTabular.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#MergeTabular.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.MergeTabular.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.MergeTabular.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#MergeTabular.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.MergeTabular.build" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.StackFeatures">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">StackFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#StackFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.StackFeatures" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><code class="xref py py-class docutils literal notranslate"><span class="pre">TabularAggregation</span></code></a></p>
<p>Aggregation by stacking all values in input dictionary in the given dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>default=-1</em>)  Axis to use for the stacking operation.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.StackFeatures.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#StackFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.StackFeatures.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.StackFeatures.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/aggregation.html#StackFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.StackFeatures.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.BinaryClassificationTask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">BinaryClassificationTask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_block</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">BCELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(BinaryPrecision(),</span> <span class="pre">BinaryRecall(),</span> <span class="pre">BinaryAccuracy())</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'first'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#BinaryClassificationTask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.BinaryClassificationTask" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.PredictionTask" title="transformers4rec.torch.model.base.PredictionTask"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionTask</span></code></a></p>
<p>Returns a <code class="docutils literal notranslate"><span class="pre">PredictionTask</span></code> for binary classification.</p>
<p>Example usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the input module to process the tabular input features.</span>
<span class="n">input_module</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">,</span>
    <span class="n">max_sequence_length</span><span class="o">=</span><span class="n">max_sequence_length</span><span class="p">,</span>
    <span class="n">continuous_projection</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
    <span class="n">masking</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Define XLNetConfig class and set default parameters for HF XLNet config.</span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="n">max_sequence_length</span>
<span class="p">)</span>

<span class="c1"># Define the model block including: inputs, masking, projection and transformer block.</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">SequentialBlock</span><span class="p">(</span>
    <span class="n">input_module</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]),</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span>
        <span class="n">transformer_config</span><span class="p">,</span>
        <span class="n">masking</span><span class="o">=</span><span class="n">input_module</span><span class="o">.</span><span class="n">masking</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Define a head with BinaryClassificationTask.</span>
<span class="n">head</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Head</span><span class="p">(</span>
    <span class="n">body</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">BinaryClassificationTask</span><span class="p">(</span>
        <span class="s2">&quot;click&quot;</span><span class="p">,</span>
        <span class="n">summary_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span>
            <span class="n">tm</span><span class="o">.</span><span class="n">Precision</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">),</span>
            <span class="n">tm</span><span class="o">.</span><span class="n">Recall</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">),</span>
            <span class="n">tm</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">),</span>
            <span class="n">tm</span><span class="o">.</span><span class="n">F1Score</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">),</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">input_module</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Get the end-to-end Model class.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>] </em><em>= None</em>)  Specifies the variable name that represents the positive and negative values.</p></li>
<li><p><strong>task_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>] </em><em>= None</em>)  Specifies the name of the prediction task. If this parameter is not specified,
a name is automatically constructed based on <code class="docutils literal notranslate"><span class="pre">target_name</span></code> and the Python
class name of the model.</p></li>
<li><p><strong>task_block</strong> (<em>Optional</em><em>[</em><em>BlockType</em><em>] </em><em>= None</em>)  Specifies a module to transform the input tensor before computing predictions.</p></li>
<li><p><strong>loss</strong> (<em>torch.nn.Module</em>)  Specifies the loss function for the task.
The default class is <code class="docutils literal notranslate"><span class="pre">torch.nn.BCELoss</span></code>.</p></li>
<li><p><strong>metrics</strong> (<em>Tuple</em><em>[</em><em>torch.nn.Module</em><em>, </em><em>...</em><em>]</em>)  Specifies the metrics to calculate during training and evaluation.
The default metrics are <code class="docutils literal notranslate"><span class="pre">Precision</span></code>, <code class="docutils literal notranslate"><span class="pre">Recall</span></code>, and <code class="docutils literal notranslate"><span class="pre">Accuracy</span></code>.</p></li>
<li><p><strong>summary_type</strong> (<em>str</em>)  <p>Summarizes a sequence into a single tensor. Accepted values are:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">last</span></code>  Take the last token hidden state (like XLNet)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">first</span></code>  Take the first token hidden state (like Bert)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>  Take the mean of all tokens hidden states</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cls_index</span></code>  Supply a Tensor of classification token position (GPT/GPT-2)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attn</span></code>  Not implemented now, use multi-head attention</p></li>
</ul>
</div></blockquote>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.BinaryClassificationTask.DEFAULT_LOSS">
<span class="sig-name descname"><span class="pre">DEFAULT_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">BCELoss()</span></em><a class="headerlink" href="#transformers4rec.torch.BinaryClassificationTask.DEFAULT_LOSS" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.BinaryClassificationTask.DEFAULT_METRICS">
<span class="sig-name descname"><span class="pre">DEFAULT_METRICS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(BinaryPrecision(),</span> <span class="pre">BinaryRecall(),</span> <span class="pre">BinaryAccuracy())</span></em><a class="headerlink" href="#transformers4rec.torch.BinaryClassificationTask.DEFAULT_METRICS" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.BinaryClassificationTask.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.BinaryClassificationTask.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.RegressionTask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">RegressionTask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_block</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">MSELoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(MeanSquaredError(),)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'first'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#RegressionTask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.RegressionTask" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.PredictionTask" title="transformers4rec.torch.model.base.PredictionTask"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionTask</span></code></a></p>
<p>Returns a <code class="docutils literal notranslate"><span class="pre">PredictionTask</span></code> for regression.</p>
<p>Example usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the input module to process the tabular input features.</span>
<span class="n">input_module</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">,</span>
    <span class="n">max_sequence_length</span><span class="o">=</span><span class="n">max_sequence_length</span><span class="p">,</span>
    <span class="n">continuous_projection</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
    <span class="n">masking</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Define XLNetConfig class and set default parameters for HF XLNet config.</span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="n">max_sequence_length</span>
<span class="p">)</span>

<span class="c1"># Define the model block including: inputs, projection and transformer block.</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">SequentialBlock</span><span class="p">(</span>
    <span class="n">input_module</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]),</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span>
        <span class="n">transformer_config</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Define a head with BinaryClassificationTask.</span>
<span class="n">head</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Head</span><span class="p">(</span>
    <span class="n">body</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">RegressionTask</span><span class="p">(</span>
        <span class="s2">&quot;watch_time&quot;</span><span class="p">,</span>
        <span class="n">summary_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tm</span><span class="o">.</span><span class="n">regression</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()]</span>
    <span class="p">),</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">input_module</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Get the end-to-end Model class.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>)  Specifies the variable name that represents the continuous value to predict.
By default None</p></li>
<li><p><strong>task_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>)  Specifies the name of the prediction task. If this parameter is not specified,
a name is automatically constructed based on <code class="docutils literal notranslate"><span class="pre">target_name</span></code> and the Python
class name of the model.
By default None</p></li>
<li><p><strong>task_block</strong> (<em>Optional</em><em>[</em><em>BlockType</em><em>] </em><em>= None</em>)  Specifies a module to transform the input tensor before computing predictions.</p></li>
<li><p><strong>loss</strong> (<em>torch.nn.Module</em>)  Specifies the loss function for the task.
The default class is <code class="docutils literal notranslate"><span class="pre">torch.nn.MSELoss</span></code>.</p></li>
<li><p><strong>metrics</strong> (<em>Tuple</em><em>[</em><em>torch.nn.Module</em><em>, </em><em>...</em><em>]</em>)  Specifies the metrics to calculate during training and evaluation.
The default metric is MeanSquaredError.</p></li>
<li><p><strong>summary_type</strong> (<em>str</em>)  <p>Summarizes a sequence into a single tensor. Accepted values are:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">last</span></code>  Take the last token hidden state (like XLNet)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">first</span></code>  Take the first token hidden state (like Bert)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>  Take the mean of all tokens hidden states</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cls_index</span></code>  Supply a Tensor of classification token position (GPT/GPT-2)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attn</span></code>  Not implemented now, use multi-head attention</p></li>
</ul>
</div></blockquote>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.RegressionTask.DEFAULT_LOSS">
<span class="sig-name descname"><span class="pre">DEFAULT_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">MSELoss()</span></em><a class="headerlink" href="#transformers4rec.torch.RegressionTask.DEFAULT_LOSS" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.RegressionTask.DEFAULT_METRICS">
<span class="sig-name descname"><span class="pre">DEFAULT_METRICS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(MeanSquaredError(),)</span></em><a class="headerlink" href="#transformers4rec.torch.RegressionTask.DEFAULT_METRICS" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.RegressionTask.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.RegressionTask.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">NextItemPredictionTask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">CrossEntropyLoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">Metric</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(NDCGAt(),</span> <span class="pre">AvgPrecisionAt(),</span> <span class="pre">RecallAt())</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_block</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">BlockBase</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">BuildableBlock</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'next-item'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_tying</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">softmax_temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampled_softmax</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#NextItemPredictionTask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.PredictionTask" title="transformers4rec.torch.model.base.PredictionTask"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionTask</span></code></a></p>
<p>This block performs item prediction task for session and sequential-based models.
It requires a body containing a masking schema to use for training and target generation.
For the supported masking schemes, please refers to:
<a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/stable/model_definition.html#sequence-masking">https://nvidia-merlin.github.io/Transformers4Rec/stable/model_definition.html#sequence-masking</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<em>torch.nn.Module</em>)  Loss function to use. Defaults to NLLLos.</p></li>
<li><p><strong>metrics</strong> (<em>Iterable</em><em>[</em><em>torchmetrics.Metric</em><em>]</em>)  List of ranking metrics to use for evaluation.</p></li>
<li><p><strong>task_block</strong>  Module to transform input tensor before computing predictions.</p></li>
<li><p><strong>task_name</strong> (<em>str</em><em>, </em><em>optional</em>)  Name of the prediction task, if not provided a name will be automatically constructed based
on the target-name &amp; class-name.</p></li>
<li><p><strong>weight_tying</strong> (<em>bool</em>)  The item id embedding table weights are shared with the prediction network layer.</p></li>
<li><p><strong>softmax_temperature</strong> (<em>float</em>)  Softmax temperature, used to reduce model overconfidence, so that softmax(logits / T).
Value 1.0 reduces to regular softmax.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>)  pad token id.</p></li>
<li><p><strong>target_dim</strong> (<em>int</em>)  vocabulary size of item ids</p></li>
<li><p><strong>sampled_softmax</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>)  Enables sampled softmax. By default False</p></li>
<li><p><strong>max_n_samples</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>)  Number of samples for sampled softmax. By default 100</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask.DEFAULT_METRICS">
<span class="sig-name descname"><span class="pre">DEFAULT_METRICS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(NDCGAt(),</span> <span class="pre">AvgPrecisionAt(),</span> <span class="pre">RecallAt())</span></em><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask.DEFAULT_METRICS" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#NextItemPredictionTask.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask.build" title="Permalink to this definition">#</a></dt>
<dd><p>Build method, this is called by the <cite>Head</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#NextItemPredictionTask.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask.remove_pad_3d">
<span class="sig-name descname"><span class="pre">remove_pad_3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_pad_mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#NextItemPredictionTask.remove_pad_3d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask.remove_pad_3d" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask.calculate_metrics">
<span class="sig-name descname"><span class="pre">calculate_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#NextItemPredictionTask.calculate_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask.calculate_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/model/prediction_task.html#NextItemPredictionTask.compute_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask.compute_metrics" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.NextItemPredictionTask.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.NextItemPredictionTask.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">TabularModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularModule" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>PyTorch Module thats specialized for tabular-data by integrating many often used operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularModule.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularModule.from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiate a TabularModule instance from a DatasetSchema.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong>  </p></li>
<li><p><strong>tags</strong>  </p></li>
<li><p><strong>kwargs</strong>  </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[<a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule">TabularModule</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.from_features">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularModule.from_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularModule.from_features" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Initializes a TabularModule instance where the contents of features will be filtered</dt><dd><p>out</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>)  A list of feature-names that will be used as the first pre-processing op to filter out
all other features not in this list.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>)  Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule">TabularModule</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.pre">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pre</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.SequentialTabularTransformations" title="transformers4rec.torch.tabular.base.SequentialTabularTransformations"><span class="pre">SequentialTabularTransformations</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularModule.pre" title="Permalink to this definition">#</a></dt>
<dd><p>rtype: SequentialTabularTransformations, optional</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.post">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">post</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.SequentialTabularTransformations" title="transformers4rec.torch.tabular.base.SequentialTabularTransformations"><span class="pre">SequentialTabularTransformations</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularModule.post" title="Permalink to this definition">#</a></dt>
<dd><p>rtype: SequentialTabularTransformations, optional</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.aggregation">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aggregation</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.TabularModule.aggregation" title="Permalink to this definition">#</a></dt>
<dd><p>rtype: TabularAggregation, optional</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.pre_forward">
<span class="sig-name descname"><span class="pre">pre_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularModule.pre_forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularModule.pre_forward" title="Permalink to this definition">#</a></dt>
<dd><p>Method thats typically called before the forward method for pre-processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>TabularData</em>)  input-data, typically the output of the forward method.</p></li>
<li><p><strong>transformations</strong> (<em>TabularAggregationType</em><em>, </em><em>optional</em>)  </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>TabularData</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularModule.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.post_forward">
<span class="sig-name descname"><span class="pre">post_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.tabular.base.TabularTransformation"><span class="pre">TabularTransformation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merge_with</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.tabular.base.TabularModule"><span class="pre">TabularModule</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.tabular.base.TabularAggregation"><span class="pre">TabularAggregation</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/tabular/base.html#TabularModule.post_forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.TabularModule.post_forward" title="Permalink to this definition">#</a></dt>
<dd><p>Method thats typically called after the forward method for post-processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>TabularData</em>)  input-data, typically the output of the forward method.</p></li>
<li><p><strong>transformations</strong> (<em>TabularTransformationType</em><em>, </em><em>optional</em>)  Transformations to apply on the input data.</p></li>
<li><p><strong>merge_with</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>List</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Other TabularModules to call and merge the outputs with.</p></li>
<li><p><strong>aggregation</strong> (<em>TabularAggregationType</em><em>, </em><em>optional</em>)  Aggregation to aggregate the output to a single Tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>TensorOrTabularData (Tensor when aggregation is set, else TabularData)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.merge">
<span class="sig-name descname"><span class="pre">merge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformers4rec.torch.TabularModule.merge" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.TabularModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.TabularModule.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.SoftEmbedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">SoftEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SoftEmbedding" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Soft-one hot encoding embedding technique, from <a class="reference external" href="https://arxiv.org/pdf/1708.00065.pdf">https://arxiv.org/pdf/1708.00065.pdf</a>
In a nutshell, it represents a continuous feature as a weighted average of embeddings</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.SoftEmbedding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_numeric</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbedding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.SoftEmbedding.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.SoftEmbedding.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.SoftEmbedding.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.model.base.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.trainer.T4RecTrainingArguments" title="transformers4rec.config.trainer.T4RecTrainingArguments"><span class="pre">T4RecTrainingArguments</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset_or_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataset_or_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset_or_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">TrainerCallback</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental_logging</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></p>
<p>An <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> specialized for sequential recommendation
including (session-based and sequtial recommendation)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.Model"><em>Model</em></a>)  The Model defined using Transformers4Rec api.</p></li>
<li><p><strong>args</strong> (<a class="reference internal" href="#transformers4rec.torch.T4RecTrainingArguments" title="transformers4rec.torch.T4RecTrainingArguments"><em>T4RecTrainingArguments</em></a>)  The training arguments needed to setup training and evaluation
experiments.</p></li>
<li><p><strong>schema</strong> (<em>Optional</em><em>[</em><em>Dataset.schema</em><em>]</em><em>, </em><em>optional</em>)  The schema object including features to use and their properties.
by default None</p></li>
<li><p><strong>train_dataset_or_path</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset" title="merlin.io.Dataset"><em>Dataset</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>)  Path of parquet files or DataSet to use for training.
by default None</p></li>
<li><p><strong>eval_dataset_or_path</strong> (<em>Optional</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset" title="merlin.io.Dataset"><em>Dataset</em></a><em>]</em><em>, </em><em>optional</em>)  Path of parquet files or DataSet to use for evaluation.
by default None</p></li>
<li><p><strong>train_dataloader</strong> (<em>Optional</em><em>[</em><em>DataLoader</em><em>]</em><em>, </em><em>optional</em>)  The data generator to use for training.
by default None</p></li>
<li><p><strong>eval_dataloader</strong> (<em>Optional</em><em>[</em><em>DataLoader</em><em>]</em><em>, </em><em>optional</em>)  The data generator to use for evaluation.
by default None</p></li>
<li><p><strong>compute_metrics</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em><em>, </em><em>optional</em>)  Whether to compute metrics defined by Model class or not.
by default None</p></li>
<li><p><strong>incremental_logging</strong> (<em>bool</em>)  Whether to enable incremental logging or not. If True, it ensures that
global steps are incremented over many <cite>trainer.train()</cite> calls, so that
train and eval metrics steps do not overlap and can be seen properly
in reports like W&amp;B and Tensorboard</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.get_train_dataloader">
<span class="sig-name descname"><span class="pre">get_train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_train_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.get_train_dataloader" title="Permalink to this definition">#</a></dt>
<dd><p>Set the train dataloader to use by Trainer.
It supports user defined data-loader set as an attribute in the constructor.
When the attribute is None, The data-loader is defined using train_dataset
and the <cite>data_loader_engine</cite> specified in Training Arguments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.get_eval_dataloader">
<span class="sig-name descname"><span class="pre">get_eval_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_eval_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.get_eval_dataloader" title="Permalink to this definition">#</a></dt>
<dd><p>Set the eval dataloader to use by Trainer.
It supports user defined data-loader set as an attribute in the constructor.
When the attribute is None, The data-loader is defined using eval_dataset
and the <cite>data_loader_engine</cite> specified in Training Arguments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.get_test_dataloader">
<span class="sig-name descname"><span class="pre">get_test_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_test_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.get_test_dataloader" title="Permalink to this definition">#</a></dt>
<dd><p>Set the test dataloader to use by Trainer.
It supports user defined data-loader set as an attribute in the constructor.
When the attribute is None, The data-loader is defined using test_dataset
and the <cite>data_loader_engine</cite> specified in Training Arguments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.num_examples">
<span class="sig-name descname"><span class="pre">num_examples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.num_examples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.num_examples" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <a class="reference internal" href="#transformers4rec.torch.Trainer.num_examples" title="transformers4rec.torch.Trainer.num_examples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.num_examples()</span></code></a> method because
the data loaders for this project do not return the dataset size,
but the number of steps. So we estimate the dataset size here
by multiplying the number of steps * batch size</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.reset_lr_scheduler">
<span class="sig-name descname"><span class="pre">reset_lr_scheduler</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.reset_lr_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.reset_lr_scheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Resets the LR scheduler of the previous <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.train()</span></code> call,
so that a new LR scheduler one is created by the next <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.train()</span></code> call.
This is important for LR schedules like <cite>get_linear_schedule_with_warmup()</cite>
which decays LR to 0 in the end of the train</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.create_scheduler">
<span class="sig-name descname"><span class="pre">create_scheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_training_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Optimizer</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.create_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.create_scheduler" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.get_scheduler">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_scheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">SchedulerType</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_warmup_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_training_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_cycles</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.get_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.get_scheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Unified API to get any scheduler from its name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code> or <cite>:obj:`SchedulerType</cite>))  The name of the scheduler to use.</p></li>
<li><p><strong>optimizer</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code>))  The optimizer that will be used during training.</p></li>
<li><p><strong>num_warmup_steps</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>))  The number of warm-up steps to perform. This is not required by all schedulers
(hence the argument being optional),
the function will raise an error if its unset and the scheduler type requires it.</p></li>
<li><p><strong>num_training_steps</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>))  The number of training steps to do. This is not required by all schedulers
(hence the argument being optional),
the function will raise an error if its unset and the scheduler type requires it.</p></li>
<li><p><strong>num_cycles</strong> ((<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <cite>optional</cite>))  The number of waves in the cosine schedule /
hard restarts to use for cosine scheduler</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.compute_loss">
<span class="sig-name descname"><span class="pre">compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.compute_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.compute_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <a class="reference internal" href="#transformers4rec.torch.Trainer.compute_loss" title="transformers4rec.torch.Trainer.compute_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.compute_loss()</span></code></a>
To allow for passing the targets to the models forward method
How the loss is computed by Trainer. By default, all Transformers4Rec models return
a dictionary of three elements {loss, predictions, and labels}</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.prediction_step">
<span class="sig-name descname"><span class="pre">prediction_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_loss_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.prediction_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.prediction_step" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <a class="reference internal" href="#transformers4rec.torch.Trainer.prediction_step" title="transformers4rec.torch.Trainer.prediction_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.prediction_step()</span></code></a>
to provide more flexibility to unpack results from the model,
like returning labels that are not exactly one input feature
model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.evaluation_loop">
<span class="sig-name descname"><span class="pre">evaluation_loop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_loss_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_key_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eval'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">EvalLoopOutput</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.evaluation_loop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.evaluation_loop" title="Permalink to this definition">#</a></dt>
<dd><p>Overriding <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.prediction_loop()</span></code>
(shared by <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.evaluate()</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">Trainer.predict()</span></code>)
to provide more flexibility to work with streaming metrics
(computed at each eval batch) and
to log with the outputs of the model
(e.g. prediction scores, prediction metadata, attention weights)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataloader</strong> (<em>DataLoader</em>)  DataLoader object to use to iterate over evaluation data</p></li>
<li><p><strong>description</strong> (<em>str</em>)  Parameter to describe the evaluation experiment.
e.g: <cite>Prediction</cite>, <cite>test</cite></p></li>
<li><p><strong>prediction_loss_only</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>)  Whether or not to return the loss only.
by default None</p></li>
<li><p><strong>ignore_keys</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>)  Columns not accepted by the <code class="docutils literal notranslate"><span class="pre">model.forward()</span></code> method
are automatically removed.
by default None</p></li>
<li><p><strong>metric_key_prefix</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>)  Prefix to use when logging evaluation metrics.
by default <cite>eval</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.load_model_trainer_states_from_checkpoint">
<span class="sig-name descname"><span class="pre">load_model_trainer_states_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.load_model_trainer_states_from_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.load_model_trainer_states_from_checkpoint" title="Permalink to this definition">#</a></dt>
<dd><p>This method loads the checkpoints states of the model, trainer and random states.
If model is None the serialized model class is loaded from checkpoint.
It does not loads the optimizer and LR scheduler states (for that call trainer.train()
with resume_from_checkpoint argument for a complete load)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<em>str</em>)  Path to the checkpoint directory.</p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#transformers4rec.torch.Model" title="transformers4rec.torch.Model"><em>Model</em></a><em>]</em>)  Model class used by Trainer. by default None</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.log_predictions_callback">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">log_predictions_callback</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><a class="headerlink" href="#transformers4rec.torch.Trainer.log_predictions_callback" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.Trainer.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/trainer.html#Trainer.log"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.Trainer.log" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.LabelSmoothCrossEntropyLoss">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.</span></span><span class="sig-name descname"><span class="pre">LabelSmoothCrossEntropyLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/losses.html#LabelSmoothCrossEntropyLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.LabelSmoothCrossEntropyLoss" title="Permalink to this definition">#</a></dt>
<dd><p>Coss-entropy loss with label smoothing.
This is going to be deprecated. You should use torch.nn.CrossEntropyLoss()
directly that in recent PyTorch versions already supports label_smoothing arg</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing</strong> (<em>float</em>)  The label smoothing factor. Specify a value between 0 and 1.</p></li>
<li><p><strong>reduction</strong> (<em>str</em>)  Specifies the reduction to apply to the output.
Specify one of <cite>none</cite>, <cite>sum</cite>, or <cite>mean</cite>.</p></li>
<li><p><strong>https</strong> (<em>Adapted from</em>)  </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="transformers4rec.config.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">transformers4rec.config package</p>
      </div>
    </a>
    <a class="right-next"
       href="transformers4rec.torch.block.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">transformers4rec.torch.block package</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#subpackages">Subpackages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.masking">transformers4rec.torch.masking module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskingInfo"><code class="docutils literal notranslate"><span class="pre">MaskingInfo</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskingInfo.schema"><code class="docutils literal notranslate"><span class="pre">MaskingInfo.schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskingInfo.targets"><code class="docutils literal notranslate"><span class="pre">MaskingInfo.targets</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence"><code class="docutils literal notranslate"><span class="pre">MaskSequence</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.compute_masked_targets"><code class="docutils literal notranslate"><span class="pre">MaskSequence.compute_masked_targets()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MaskSequence.apply_mask_to_inputs()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.predict_all"><code class="docutils literal notranslate"><span class="pre">MaskSequence.predict_all()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.forward"><code class="docutils literal notranslate"><span class="pre">MaskSequence.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.forward_output_size"><code class="docutils literal notranslate"><span class="pre">MaskSequence.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.transformer_required_arguments"><code class="docutils literal notranslate"><span class="pre">MaskSequence.transformer_required_arguments()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.transformer_optional_arguments"><code class="docutils literal notranslate"><span class="pre">MaskSequence.transformer_optional_arguments()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskSequence.transformer_arguments"><code class="docutils literal notranslate"><span class="pre">MaskSequence.transformer_arguments</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.CausalLanguageModeling"><code class="docutils literal notranslate"><span class="pre">CausalLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.CausalLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">CausalLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskedLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MaskedLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.MaskedLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MaskedLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.PermutationLanguageModeling"><code class="docutils literal notranslate"><span class="pre">PermutationLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.PermutationLanguageModeling.compute_masked_targets"><code class="docutils literal notranslate"><span class="pre">PermutationLanguageModeling.compute_masked_targets()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.PermutationLanguageModeling.transformer_required_arguments"><code class="docutils literal notranslate"><span class="pre">PermutationLanguageModeling.transformer_required_arguments()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.ReplacementLanguageModeling"><code class="docutils literal notranslate"><span class="pre">ReplacementLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.ReplacementLanguageModeling.get_fake_tokens"><code class="docutils literal notranslate"><span class="pre">ReplacementLanguageModeling.get_fake_tokens()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.masking.ReplacementLanguageModeling.sample_from_softmax"><code class="docutils literal notranslate"><span class="pre">ReplacementLanguageModeling.sample_from_softmax()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.ranking_metric">transformers4rec.torch.ranking_metric module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RankingMetric"><code class="docutils literal notranslate"><span class="pre">RankingMetric</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RankingMetric.update"><code class="docutils literal notranslate"><span class="pre">RankingMetric.update()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RankingMetric.compute"><code class="docutils literal notranslate"><span class="pre">RankingMetric.compute()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.PrecisionAt"><code class="docutils literal notranslate"><span class="pre">PrecisionAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.RecallAt"><code class="docutils literal notranslate"><span class="pre">RecallAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.AvgPrecisionAt"><code class="docutils literal notranslate"><span class="pre">AvgPrecisionAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.DCGAt"><code class="docutils literal notranslate"><span class="pre">DCGAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.NDCGAt"><code class="docutils literal notranslate"><span class="pre">NDCGAt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ranking_metric.MeanReciprocalRankAt"><code class="docutils literal notranslate"><span class="pre">MeanReciprocalRankAt</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.trainer">transformers4rec.torch.trainer module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_train_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_train_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_eval_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_eval_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_test_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_test_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.num_examples"><code class="docutils literal notranslate"><span class="pre">Trainer.num_examples()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.reset_lr_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.reset_lr_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.create_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.create_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.get_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.get_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.compute_loss"><code class="docutils literal notranslate"><span class="pre">Trainer.compute_loss()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.prediction_step"><code class="docutils literal notranslate"><span class="pre">Trainer.prediction_step()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.evaluation_loop"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluation_loop()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.load_model_trainer_states_from_checkpoint"><code class="docutils literal notranslate"><span class="pre">Trainer.load_model_trainer_states_from_checkpoint()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.log_predictions_callback"><code class="docutils literal notranslate"><span class="pre">Trainer.log_predictions_callback</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.Trainer.log"><code class="docutils literal notranslate"><span class="pre">Trainer.log()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.process_metrics"><code class="docutils literal notranslate"><span class="pre">process_metrics()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_begin"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback.on_train_begin()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_train_end"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback.on_train_end()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.IncrementalLoggingCallback.on_epoch_end"><code class="docutils literal notranslate"><span class="pre">IncrementalLoggingCallback.on_epoch_end()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.trainer.DatasetMock"><code class="docutils literal notranslate"><span class="pre">DatasetMock</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.typing">transformers4rec.torch.typing module</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema"><code class="docutils literal notranslate"><span class="pre">Schema</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.feature"><code class="docutils literal notranslate"><span class="pre">Schema.feature</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.create"><code class="docutils literal notranslate"><span class="pre">Schema.create()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.with_tags_based_on_properties"><code class="docutils literal notranslate"><span class="pre">Schema.with_tags_based_on_properties()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.apply"><code class="docutils literal notranslate"><span class="pre">Schema.apply()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.apply_inverse"><code class="docutils literal notranslate"><span class="pre">Schema.apply_inverse()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.filter_columns_from_dict"><code class="docutils literal notranslate"><span class="pre">Schema.filter_columns_from_dict()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.select_by_type"><code class="docutils literal notranslate"><span class="pre">Schema.select_by_type()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.remove_by_type"><code class="docutils literal notranslate"><span class="pre">Schema.remove_by_type()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.select_by_tag"><code class="docutils literal notranslate"><span class="pre">Schema.select_by_tag()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.remove_by_tag"><code class="docutils literal notranslate"><span class="pre">Schema.remove_by_tag()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.select_by_name"><code class="docutils literal notranslate"><span class="pre">Schema.select_by_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.remove_by_name"><code class="docutils literal notranslate"><span class="pre">Schema.remove_by_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.map_column_schemas"><code class="docutils literal notranslate"><span class="pre">Schema.map_column_schemas()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.filter_column_schemas"><code class="docutils literal notranslate"><span class="pre">Schema.filter_column_schemas()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.column_names"><code class="docutils literal notranslate"><span class="pre">Schema.column_names</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.column_schemas"><code class="docutils literal notranslate"><span class="pre">Schema.column_schemas</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.item_id_column_name"><code class="docutils literal notranslate"><span class="pre">Schema.item_id_column_name</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.from_json"><code class="docutils literal notranslate"><span class="pre">Schema.from_json()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.to_proto_text"><code class="docutils literal notranslate"><span class="pre">Schema.to_proto_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.from_proto_text"><code class="docutils literal notranslate"><span class="pre">Schema.from_proto_text()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.copy"><code class="docutils literal notranslate"><span class="pre">Schema.copy()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Schema.add"><code class="docutils literal notranslate"><span class="pre">Schema.add()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.requires_schema"><code class="docutils literal notranslate"><span class="pre">requires_schema()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig"><code class="docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.to_huggingface_torch_model"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.to_huggingface_torch_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.to_torch_model"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.to_torch_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.transformers_config_cls"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.transformers_config_cls</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecConfig.build"><code class="docutils literal notranslate"><span class="pre">T4RecConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.GPT2Config"><code class="docutils literal notranslate"><span class="pre">GPT2Config</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.GPT2Config.build"><code class="docutils literal notranslate"><span class="pre">GPT2Config.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.XLNetConfig"><code class="docutils literal notranslate"><span class="pre">XLNetConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.XLNetConfig.build"><code class="docutils literal notranslate"><span class="pre">XLNetConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransfoXLConfig"><code class="docutils literal notranslate"><span class="pre">TransfoXLConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransfoXLConfig.build"><code class="docutils literal notranslate"><span class="pre">TransfoXLConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.LongformerConfig"><code class="docutils literal notranslate"><span class="pre">LongformerConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.LongformerConfig.build"><code class="docutils literal notranslate"><span class="pre">LongformerConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AlbertConfig"><code class="docutils literal notranslate"><span class="pre">AlbertConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AlbertConfig.build"><code class="docutils literal notranslate"><span class="pre">AlbertConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ReformerConfig"><code class="docutils literal notranslate"><span class="pre">ReformerConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ReformerConfig.build"><code class="docutils literal notranslate"><span class="pre">ReformerConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElectraConfig"><code class="docutils literal notranslate"><span class="pre">ElectraConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElectraConfig.build"><code class="docutils literal notranslate"><span class="pre">ElectraConfig.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.max_sequence_length"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.max_sequence_length</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.shuffle_buffer_size"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.shuffle_buffer_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.data_loader_engine"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.data_loader_engine</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.eval_on_test_set"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.eval_on_test_set</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.eval_steps_on_train_set"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.eval_steps_on_train_set</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.predict_top_k"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.predict_top_k</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.learning_rate_num_cosine_cycles_by_epoch"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.learning_rate_num_cosine_cycles_by_epoch</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.log_predictions"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.log_predictions</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.compute_metrics_each_n_steps"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.compute_metrics_each_n_steps</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.experiments_group"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.experiments_group</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.place_model_on_device"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.place_model_on_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.T4RecTrainingArguments.output_dir"><code class="docutils literal notranslate"><span class="pre">T4RecTrainingArguments.output_dir</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock"><code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.inputs"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.inputs</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.add_module"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.add_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.add_module_and_maybe_build"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.add_module_and_maybe_build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.forward"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.build"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.as_tabular"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.as_tabular()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.forward_output_size"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialBlock.get_children_by_class_name"><code class="docutils literal notranslate"><span class="pre">SequentialBlock.get_children_by_class_name()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.right_shift_block"><code class="docutils literal notranslate"><span class="pre">right_shift_block()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.build_blocks"><code class="docutils literal notranslate"><span class="pre">build_blocks()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BlockBase"><code class="docutils literal notranslate"><span class="pre">BlockBase</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BlockBase.to_model"><code class="docutils literal notranslate"><span class="pre">BlockBase.to_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BlockBase.as_tabular"><code class="docutils literal notranslate"><span class="pre">BlockBase.as_tabular()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock"><code class="docutils literal notranslate"><span class="pre">TabularBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock.to_module"><code class="docutils literal notranslate"><span class="pre">TabularBlock.to_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock.output_size"><code class="docutils literal notranslate"><span class="pre">TabularBlock.output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularBlock.build"><code class="docutils literal notranslate"><span class="pre">TabularBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Block"><code class="docutils literal notranslate"><span class="pre">Block</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Block.forward"><code class="docutils literal notranslate"><span class="pre">Block.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Block.forward_output_size"><code class="docutils literal notranslate"><span class="pre">Block.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MLPBlock"><code class="docutils literal notranslate"><span class="pre">MLPBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MLPBlock.build"><code class="docutils literal notranslate"><span class="pre">MLPBlock.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularTransformation"><code class="docutils literal notranslate"><span class="pre">TabularTransformation</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularTransformation.forward"><code class="docutils literal notranslate"><span class="pre">TabularTransformation.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularTransformation.parse"><code class="docutils literal notranslate"><span class="pre">TabularTransformation.parse()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialTabularTransformations"><code class="docutils literal notranslate"><span class="pre">SequentialTabularTransformations</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequentialTabularTransformations.append"><code class="docutils literal notranslate"><span class="pre">SequentialTabularTransformations.append()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularAggregation"><code class="docutils literal notranslate"><span class="pre">TabularAggregation</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularAggregation.forward"><code class="docutils literal notranslate"><span class="pre">TabularAggregation.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularAggregation.parse"><code class="docutils literal notranslate"><span class="pre">TabularAggregation.parse()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise.forward"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise.forward_output_size"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StochasticSwapNoise.augment"><code class="docutils literal notranslate"><span class="pre">StochasticSwapNoise.augment()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.from_feature_config"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.from_feature_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.forward"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularLayerNorm.build"><code class="docutils literal notranslate"><span class="pre">TabularLayerNorm.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularDropout"><code class="docutils literal notranslate"><span class="pre">TabularDropout</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularDropout.forward"><code class="docutils literal notranslate"><span class="pre">TabularDropout.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularDropout.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularDropout.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock"><code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.TRANSFORMER_TO_PREPARE"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.TRANSFORMER_TO_PREPARE</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.from_registry"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.from_registry()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.forward"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TransformerBlock.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures.from_features"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.from_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures.forward"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ContinuousFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ContinuousFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.item_embedding_table"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.item_embedding_table</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.item_ids"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.item_ids()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.forward"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.EmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer.forward"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingsInitializer.training"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingsInitializer.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.build"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.forward"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PretrainedEmbeddingFeatures.parse_combiner"><code class="docutils literal notranslate"><span class="pre">PretrainedEmbeddingFeatures.parse_combiner()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.masking"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.masking</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.set_masking"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.set_masking()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.item_id"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.item_id</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.item_embedding_table"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.item_embedding_table</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.forward"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.project_continuous_features"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.project_continuous_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularSequenceFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequenceEmbeddingFeatures"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequenceEmbeddingFeatures.table_to_embedding_module"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures.table_to_embedding_module()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SequenceEmbeddingFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">SequenceEmbeddingFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig"><code class="docutils literal notranslate"><span class="pre">FeatureConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig.table"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.table</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig.max_sequence_length"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.max_sequence_length</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FeatureConfig.name"><code class="docutils literal notranslate"><span class="pre">FeatureConfig.name</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig"><code class="docutils literal notranslate"><span class="pre">TableConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.vocabulary_size"><code class="docutils literal notranslate"><span class="pre">TableConfig.vocabulary_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.dim"><code class="docutils literal notranslate"><span class="pre">TableConfig.dim</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.initializer"><code class="docutils literal notranslate"><span class="pre">TableConfig.initializer</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.combiner"><code class="docutils literal notranslate"><span class="pre">TableConfig.combiner</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TableConfig.name"><code class="docutils literal notranslate"><span class="pre">TableConfig.name</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures"><code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.CONTINUOUS_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.CONTINUOUS_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.PRETRAINED_EMBEDDING_MODULE_CLASS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.project_continuous_features"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.project_continuous_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.continuous_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.continuous_module</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.categorical_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.categorical_module</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularFeatures.pretrained_module"><code class="docutils literal notranslate"><span class="pre">TabularFeatures.pretrained_module</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head"><code class="docutils literal notranslate"><span class="pre">Head</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.build"><code class="docutils literal notranslate"><span class="pre">Head.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.from_schema"><code class="docutils literal notranslate"><span class="pre">Head.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.pop_labels"><code class="docutils literal notranslate"><span class="pre">Head.pop_labels()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.forward"><code class="docutils literal notranslate"><span class="pre">Head.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">Head.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.compute_metrics"><code class="docutils literal notranslate"><span class="pre">Head.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.reset_metrics"><code class="docutils literal notranslate"><span class="pre">Head.reset_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.task_blocks"><code class="docutils literal notranslate"><span class="pre">Head.task_blocks</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.to_model"><code class="docutils literal notranslate"><span class="pre">Head.to_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Head.training"><code class="docutils literal notranslate"><span class="pre">Head.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.forward"><code class="docutils literal notranslate"><span class="pre">Model.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">Model.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.compute_metrics"><code class="docutils literal notranslate"><span class="pre">Model.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.reset_metrics"><code class="docutils literal notranslate"><span class="pre">Model.reset_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.to_lightning"><code class="docutils literal notranslate"><span class="pre">Model.to_lightning()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.fit"><code class="docutils literal notranslate"><span class="pre">Model.fit()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.evaluate"><code class="docutils literal notranslate"><span class="pre">Model.evaluate()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.input_schema"><code class="docutils literal notranslate"><span class="pre">Model.input_schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.output_schema"><code class="docutils literal notranslate"><span class="pre">Model.output_schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.prediction_tasks"><code class="docutils literal notranslate"><span class="pre">Model.prediction_tasks</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.save"><code class="docutils literal notranslate"><span class="pre">Model.save()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.load"><code class="docutils literal notranslate"><span class="pre">Model.load()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Model.training"><code class="docutils literal notranslate"><span class="pre">Model.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask"><code class="docutils literal notranslate"><span class="pre">PredictionTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.build"><code class="docutils literal notranslate"><span class="pre">PredictionTask.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.forward"><code class="docutils literal notranslate"><span class="pre">PredictionTask.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.task_name"><code class="docutils literal notranslate"><span class="pre">PredictionTask.task_name</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.child_name"><code class="docutils literal notranslate"><span class="pre">PredictionTask.child_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.set_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.set_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.compute_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.metric_name"><code class="docutils literal notranslate"><span class="pre">PredictionTask.metric_name()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.reset_metrics"><code class="docutils literal notranslate"><span class="pre">PredictionTask.reset_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.to_head"><code class="docutils literal notranslate"><span class="pre">PredictionTask.to_head()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.to_model"><code class="docutils literal notranslate"><span class="pre">PredictionTask.to_model()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.PredictionTask.training"><code class="docutils literal notranslate"><span class="pre">PredictionTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AsTabular"><code class="docutils literal notranslate"><span class="pre">AsTabular</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AsTabular.forward"><code class="docutils literal notranslate"><span class="pre">AsTabular.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.AsTabular.forward_output_size"><code class="docutils literal notranslate"><span class="pre">AsTabular.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ConcatFeatures"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ConcatFeatures.forward"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ConcatFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ConcatFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FilterFeatures"><code class="docutils literal notranslate"><span class="pre">FilterFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FilterFeatures.forward"><code class="docutils literal notranslate"><span class="pre">FilterFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.FilterFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">FilterFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSum"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSum.forward"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSum.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ElementwiseSum.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti.forward"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti.forward_output_size"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.ElementwiseSumItemMulti.REQUIRES_SCHEMA"><code class="docutils literal notranslate"><span class="pre">ElementwiseSumItemMulti.REQUIRES_SCHEMA</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular"><code class="docutils literal notranslate"><span class="pre">MergeTabular</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.merge_values"><code class="docutils literal notranslate"><span class="pre">MergeTabular.merge_values</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.forward"><code class="docutils literal notranslate"><span class="pre">MergeTabular.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.forward_output_size"><code class="docutils literal notranslate"><span class="pre">MergeTabular.forward_output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.MergeTabular.build"><code class="docutils literal notranslate"><span class="pre">MergeTabular.build()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StackFeatures"><code class="docutils literal notranslate"><span class="pre">StackFeatures</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StackFeatures.forward"><code class="docutils literal notranslate"><span class="pre">StackFeatures.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.StackFeatures.forward_output_size"><code class="docutils literal notranslate"><span class="pre">StackFeatures.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask.DEFAULT_LOSS"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.DEFAULT_LOSS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.DEFAULT_METRICS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.BinaryClassificationTask.training"><code class="docutils literal notranslate"><span class="pre">BinaryClassificationTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask"><code class="docutils literal notranslate"><span class="pre">RegressionTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask.DEFAULT_LOSS"><code class="docutils literal notranslate"><span class="pre">RegressionTask.DEFAULT_LOSS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">RegressionTask.DEFAULT_METRICS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.RegressionTask.training"><code class="docutils literal notranslate"><span class="pre">RegressionTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.DEFAULT_METRICS"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.DEFAULT_METRICS</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.build"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.forward"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.remove_pad_3d"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.remove_pad_3d()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.compute_metrics"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.NextItemPredictionTask.training"><code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule"><code class="docutils literal notranslate"><span class="pre">TabularModule</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.from_schema"><code class="docutils literal notranslate"><span class="pre">TabularModule.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.from_features"><code class="docutils literal notranslate"><span class="pre">TabularModule.from_features()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.pre"><code class="docutils literal notranslate"><span class="pre">TabularModule.pre</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.post"><code class="docutils literal notranslate"><span class="pre">TabularModule.post</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.aggregation"><code class="docutils literal notranslate"><span class="pre">TabularModule.aggregation</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.pre_forward"><code class="docutils literal notranslate"><span class="pre">TabularModule.pre_forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.forward"><code class="docutils literal notranslate"><span class="pre">TabularModule.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.post_forward"><code class="docutils literal notranslate"><span class="pre">TabularModule.post_forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.merge"><code class="docutils literal notranslate"><span class="pre">TabularModule.merge()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.TabularModule.training"><code class="docutils literal notranslate"><span class="pre">TabularModule.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbedding"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.SoftEmbedding.training"><code class="docutils literal notranslate"><span class="pre">SoftEmbedding.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_train_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_train_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_eval_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_eval_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_test_dataloader"><code class="docutils literal notranslate"><span class="pre">Trainer.get_test_dataloader()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.num_examples"><code class="docutils literal notranslate"><span class="pre">Trainer.num_examples()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.reset_lr_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.reset_lr_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.create_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.create_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.get_scheduler"><code class="docutils literal notranslate"><span class="pre">Trainer.get_scheduler()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.compute_loss"><code class="docutils literal notranslate"><span class="pre">Trainer.compute_loss()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.prediction_step"><code class="docutils literal notranslate"><span class="pre">Trainer.prediction_step()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.evaluation_loop"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluation_loop()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.load_model_trainer_states_from_checkpoint"><code class="docutils literal notranslate"><span class="pre">Trainer.load_model_trainer_states_from_checkpoint()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.log_predictions_callback"><code class="docutils literal notranslate"><span class="pre">Trainer.log_predictions_callback</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.Trainer.log"><code class="docutils literal notranslate"><span class="pre">Trainer.log()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.LabelSmoothCrossEntropyLoss"><code class="docutils literal notranslate"><span class="pre">LabelSmoothCrossEntropyLoss()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 2023, NVIDIA.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>