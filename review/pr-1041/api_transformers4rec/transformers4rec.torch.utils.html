

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>transformers4rec.torch.utils package &#8212; NVIDIA Merlin</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/versions.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../_static/js/rtd-version-switcher.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api_transformers4rec/transformers4rec.torch.utils';</script>
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/api_transformers4rec/transformers4rec.torch.utils.html" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="transformers4rec.utils package" href="transformers4rec.utils.html" />
    <link rel="prev" title="transformers4rec.torch.tabular package" href="transformers4rec.torch.tabular.html" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVJ1Y1YJHK', {
        'anonymize_ip': false,
    });
  </script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,300&display=swap" rel="stylesheet">
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">NVIDIA Merlin</p>
  
</a></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../guide/recommender_system_guide.html">Recommender System Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../guide/recommender_models.html">Recommender Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../examples/index.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/getting-started-movielens/index.html">Getting Started using the MovieLens Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/01-Download-Convert.html">MovieLens Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/03-Training-with-TF.html">Getting Started MovieLens: Training with TensorFlow</a></li>


<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/03-Training-with-PyTorch.html">Training with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/04-Triton-Inference-with-HugeCTR.html">Serving the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/getting-started-movielens/04-Triton-Inference-with-TF.html">Serve Recommendations from the TensorFlow Model</a></li>

</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/Building-and-deploying-multi-stage-RecSys/index.html">Deploying a Multi-Stage Recommender System</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/Building-and-deploying-multi-stage-RecSys/01-Building-Recommender-Systems-with-Merlin.html">Building the Recommender System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/Building-and-deploying-multi-stage-RecSys/02-Deploying-multi-stage-RecSys-with-Merlin-Systems.html">Deploying the Recommender System with Triton</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/sagemaker-tensorflow/index.html">Merlin and AWS SageMaker</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/sagemaker-tensorflow/sagemaker-merlin-tensorflow.html">Training and Serving Merlin on AWS SageMaker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/scaling-criteo/index.html">Scaling Large Datasets with Criteo</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/01-Download-Convert.html">Criteo Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/03-Training-with-Merlin-Models-TensorFlow.html">Training with Merlin Models and TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/04-Triton-Inference-with-HugeCTR.html">Deploy the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/scaling-criteo/04-Triton-Inference-with-Merlin-Models-TensorFlow.html">Deploy the TensorFlow Model with Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../containers.html">Merlin Containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../support_matrix/index.html">Merlin Support Matrix</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../support_matrix/support_matrix_merlin_hugectr.html">Merlin HugeCTR Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../support_matrix/support_matrix_merlin_tensorflow.html">Merlin TensorFlow Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../support_matrix/support_matrix_merlin_pytorch.html">Merlin PyTorch Support Matrix</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API documentation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_core/merlin.dag.html">merlin.dag</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.BaseOperator.html">merlin.dag.BaseOperator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.Graph.html">merlin.dag.Graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.Node.html">merlin.dag.Node</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.dag.ColumnSelector.html">merlin.dag.ColumnSelector</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_dataloader.html">merlin.loader</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tensorflow.Loader.html">merlin.dataloader.tensorflow.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tensorflow.KerasSequenceValidater.html">merlin.dataloader.tensorflow.KerasSequenceValidater</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tf_utils.configure_tensorflow.html">merlin.dataloader.tf_utils.configure_tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns.html">merlin.dataloader.tf_utils.get_dataset_schema_from_feature_columns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.tf_utils.HAS_GPU.html">merlin.dataloader.tf_utils.HAS_GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.torch.Loader.html">merlin.dataloader.torch.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.torch.DLDataLoader.html">merlin.dataloader.torch.DLDataLoader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.jax.Loader.html">merlin.dataloader.jax.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.loader_base.LoaderBase.html">merlin.dataloader.loader_base.LoaderBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.dataloader.loader_base.ChunkQueue.html">merlin.dataloader.loader_base.ChunkQueue</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_core/merlin.io.html">merlin.io</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html">merlin.io.Dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_models.html">merlin.models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DCNModel.html">merlin.models.tf.DCNModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DeepFMModel.html">merlin.models.tf.DeepFMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DLRMModel.html">merlin.models.tf.DLRMModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.WideAndDeepModel.html">merlin.models.tf.WideAndDeepModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Encoder.html">merlin.models.tf.Encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.EmbeddingEncoder.html">merlin.models.tf.EmbeddingEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ItemRetrievalScorer.html">merlin.models.tf.ItemRetrievalScorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RetrievalModelV2.html">merlin.models.tf.RetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MatrixFactorizationModelV2.html">merlin.models.tf.MatrixFactorizationModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MatrixFactorizationModel.html">merlin.models.tf.MatrixFactorizationModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TwoTowerModelV2.html">merlin.models.tf.TwoTowerModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TwoTowerModel.html">merlin.models.tf.TwoTowerModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.YoutubeDNNRetrievalModelV2.html">merlin.models.tf.YoutubeDNNRetrievalModelV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.YoutubeDNNRetrievalModel.html">merlin.models.tf.YoutubeDNNRetrievalModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Embeddings.html">merlin.models.tf.Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.EmbeddingTable.html">merlin.models.tf.EmbeddingTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.AverageEmbeddingsByWeightFeature.html">merlin.models.tf.AverageEmbeddingsByWeightFeature</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ReplaceMaskedEmbeddings.html">merlin.models.tf.ReplaceMaskedEmbeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.L2Norm.html">merlin.models.tf.L2Norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.InputBlockV2.html">merlin.models.tf.InputBlockV2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.InputBlock.html">merlin.models.tf.InputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Continuous.html">merlin.models.tf.Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContinuousFeatures.html">merlin.models.tf.ContinuousFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContinuousEmbedding.html">merlin.models.tf.ContinuousEmbedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContinuousProjection.html">merlin.models.tf.ContinuousProjection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceEmbeddingFeatures.html">merlin.models.tf.SequenceEmbeddingFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DLRMBlock.html">merlin.models.tf.DLRMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MLPBlock.html">merlin.models.tf.MLPBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CrossBlock.html">merlin.models.tf.CrossBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TwoTowerBlock.html">merlin.models.tf.TwoTowerBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MatrixFactorizationBlock.html">merlin.models.tf.MatrixFactorizationBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DotProductInteraction.html">merlin.models.tf.DotProductInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.FMBlock.html">merlin.models.tf.FMBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.FMPairwiseInteraction.html">merlin.models.tf.FMPairwiseInteraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PredictionTasks.html">merlin.models.tf.PredictionTasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PredictionTask.html">merlin.models.tf.PredictionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.BinaryClassificationTask.html">merlin.models.tf.BinaryClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MultiClassClassificationTask.html">merlin.models.tf.MultiClassClassificationTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RegressionTask.html">merlin.models.tf.RegressionTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ItemRetrievalTask.html">merlin.models.tf.ItemRetrievalTask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.OutputBlock.html">merlin.models.tf.OutputBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ModelOutput.html">merlin.models.tf.ModelOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.BinaryOutput.html">merlin.models.tf.BinaryOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CategoricalOutput.html">merlin.models.tf.CategoricalOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ContrastiveOutput.html">merlin.models.tf.ContrastiveOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RegressionOutput.html">merlin.models.tf.RegressionOutput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ColumnBasedSampleWeight.html">merlin.models.tf.ColumnBasedSampleWeight</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequentialBlock.html">merlin.models.tf.SequentialBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ParallelBlock.html">merlin.models.tf.ParallelBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ParallelPredictionBlock.html">merlin.models.tf.ParallelPredictionBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DenseResidualBlock.html">merlin.models.tf.DenseResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.DualEncoderBlock.html">merlin.models.tf.DualEncoderBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ResidualBlock.html">merlin.models.tf.ResidualBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TabularBlock.html">merlin.models.tf.TabularBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Filter.html">merlin.models.tf.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Cond.html">merlin.models.tf.Cond</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TopKEncoder.html">merlin.models.tf.TopKEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MultiOptimizer.html">merlin.models.tf.MultiOptimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.LazyAdam.html">merlin.models.tf.LazyAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.OptimizerBlocks.html">merlin.models.tf.OptimizerBlocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.split_embeddings_on_size.html">merlin.models.tf.split_embeddings_on_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CategoryEncoding.html">merlin.models.tf.CategoryEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MapValues.html">merlin.models.tf.MapValues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PrepareListFeatures.html">merlin.models.tf.PrepareListFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PrepareFeatures.html">merlin.models.tf.PrepareFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToSparse.html">merlin.models.tf.ToSparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToDense.html">merlin.models.tf.ToDense</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToTarget.html">merlin.models.tf.ToTarget</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ToOneHot.html">merlin.models.tf.ToOneHot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.HashedCross.html">merlin.models.tf.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.HashedCrossAll.html">merlin.models.tf.HashedCrossAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.BroadcastToSequence.html">merlin.models.tf.BroadcastToSequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequencePredictNext.html">merlin.models.tf.SequencePredictNext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequencePredictLast.html">merlin.models.tf.SequencePredictLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequencePredictRandom.html">merlin.models.tf.SequencePredictRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceTargetAsInput.html">merlin.models.tf.SequenceTargetAsInput</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceMaskLast.html">merlin.models.tf.SequenceMaskLast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.SequenceMaskRandom.html">merlin.models.tf.SequenceMaskRandom</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ExpandDims.html">merlin.models.tf.ExpandDims</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.StochasticSwapNoise.html">merlin.models.tf.StochasticSwapNoise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.AsTabular.html">merlin.models.tf.AsTabular</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MMOEBlock.html">merlin.models.tf.MMOEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.CGCBlock.html">merlin.models.tf.CGCBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PLEBlock.html">merlin.models.tf.PLEBlock</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.Loader.html">merlin.models.tf.Loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.AvgPrecisionAt.html">merlin.models.tf.AvgPrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.MRRAt.html">merlin.models.tf.MRRAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.NDCGAt.html">merlin.models.tf.NDCGAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PrecisionAt.html">merlin.models.tf.PrecisionAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.RecallAt.html">merlin.models.tf.RecallAt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TopKMetricsAggregator.html">merlin.models.tf.TopKMetricsAggregator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.ItemSampler.html">merlin.models.tf.ItemSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.InBatchSampler.html">merlin.models.tf.InBatchSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.PopularityBasedSampler.html">merlin.models.tf.PopularityBasedSampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.CategoricalCrossEntropy.html">merlin.models.tf.losses.CategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.SparseCategoricalCrossEntropy.html">merlin.models.tf.losses.SparseCategoricalCrossEntropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.BPRLoss.html">merlin.models.tf.losses.BPRLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.BPRmaxLoss.html">merlin.models.tf.losses.BPRmaxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.HingeLoss.html">merlin.models.tf.losses.HingeLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.LogisticLoss.html">merlin.models.tf.losses.LogisticLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.TOP1Loss.html">merlin.models.tf.losses.TOP1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.TOP1maxLoss.html">merlin.models.tf.losses.TOP1maxLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.losses.TOP1v2Loss.html">merlin.models.tf.losses.TOP1v2Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.select_targets.html">merlin.models.utils.schema_utils.select_targets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json.html">merlin.models.utils.schema_utils.schema_to_tensorflow_metadata_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema.html">merlin.models.utils.schema_utils.tensorflow_metadata_json_to_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.create_categorical_column.html">merlin.models.utils.schema_utils.create_categorical_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.create_continuous_column.html">merlin.models.utils.schema_utils.create_continuous_column</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.filter_dict_by_schema.html">merlin.models.utils.schema_utils.filter_dict_by_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.categorical_cardinalities.html">merlin.models.utils.schema_utils.categorical_cardinalities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.categorical_domains.html">merlin.models.utils.schema_utils.categorical_domains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.get_embedding_sizes_from_schema.html">merlin.models.utils.schema_utils.get_embedding_sizes_from_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.schema_utils.get_embedding_size_from_cardinality.html">merlin.models.utils.schema_utils.get_embedding_size_from_cardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.tf.TensorInitializer.html">merlin.models.tf.TensorInitializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.filter_kwargs.html">merlin.models.utils.misc_utils.filter_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.safe_json.html">merlin.models.utils.misc_utils.safe_json</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_filenames.html">merlin.models.utils.misc_utils.get_filenames</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_label_feature_name.html">merlin.models.utils.misc_utils.get_label_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_timestamp_feature_name.html">merlin.models.utils.misc_utils.get_timestamp_feature_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_parquet_files_names.html">merlin.models.utils.misc_utils.get_parquet_files_names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.Timing.html">merlin.models.utils.misc_utils.Timing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.get_object_size.html">merlin.models.utils.misc_utils.get_object_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.misc_utils.validate_dataset.html">merlin.models.utils.misc_utils.validate_dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.camelcase_to_snakecase.html">merlin.models.utils.registry.camelcase_to_snakecase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.snakecase_to_camelcase.html">merlin.models.utils.registry.snakecase_to_camelcase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.default_name.html">merlin.models.utils.registry.default_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.default_object_name.html">merlin.models.utils.registry.default_object_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.Registry.html">merlin.models.utils.registry.Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.RegistryMixin.html">merlin.models.utils.registry.RegistryMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.models.utils.registry.display_list_by_prefix.html">merlin.models.utils.registry.display_list_by_prefix</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_core/merlin.schema.html">merlin.schema</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.schema.Schema.html">merlin.schema.Schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.schema.ColumnSchema.html">merlin.schema.ColumnSchema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_core/generated/merlin.schema.Tags.html">merlin.schema.Tags</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_systems.html">merlin.systems</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.Ensemble.html">merlin.systems.dag.Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.workflow.TransformWorkflow.html">merlin.systems.dag.ops.workflow.TransformWorkflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.tensorflow.PredictTensorflow.html">merlin.systems.dag.ops.tensorflow.PredictTensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.fil.PredictForest.html">merlin.systems.dag.ops.fil.PredictForest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.implicit.PredictImplicit.html">merlin.systems.dag.ops.implicit.PredictImplicit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling.html">merlin.systems.dag.ops.softmax_sampling.SoftmaxSampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.session_filter.FilterCandidates.html">merlin.systems.dag.ops.session_filter.FilterCandidates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.dag.ops.unroll_features.UnrollFeatures.html">merlin.systems.dag.ops.unroll_features.UnrollFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.triton.convert_df_to_triton_input.html">merlin.systems.triton.convert_df_to_triton_input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/merlin.systems.triton.convert_triton_output_to_df.html">merlin.systems.triton.convert_triton_output_to_df</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_nvtabular.html">nvtabular</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.workflow.workflow.Workflow.html">nvtabular.workflow.workflow.Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.workflow.workflow.WorkflowNode.html">nvtabular.workflow.workflow.WorkflowNode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Bucketize.html">nvtabular.ops.Bucketize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Categorify.html">nvtabular.ops.Categorify</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.DropLowCardinality.html">nvtabular.ops.DropLowCardinality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.HashBucket.html">nvtabular.ops.HashBucket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.HashedCross.html">nvtabular.ops.HashedCross</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TargetEncoding.html">nvtabular.ops.TargetEncoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Clip.html">nvtabular.ops.Clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.LogOp.html">nvtabular.ops.LogOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Normalize.html">nvtabular.ops.Normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.NormalizeMinMax.html">nvtabular.ops.NormalizeMinMax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Dropna.html">nvtabular.ops.Dropna</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.FillMissing.html">nvtabular.ops.FillMissing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.FillMedian.html">nvtabular.ops.FillMedian</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.DifferenceLag.html">nvtabular.ops.DifferenceLag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Filter.html">nvtabular.ops.Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Groupby.html">nvtabular.ops.Groupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.JoinExternal.html">nvtabular.ops.JoinExternal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.JoinGroupby.html">nvtabular.ops.JoinGroupby</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.AddMetadata.html">nvtabular.ops.AddMetadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.AddProperties.html">nvtabular.ops.AddProperties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.AddTags.html">nvtabular.ops.AddTags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Rename.html">nvtabular.ops.Rename</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ReduceDtypeSize.html">nvtabular.ops.ReduceDtypeSize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsItemFeatures.html">nvtabular.ops.TagAsItemFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsItemID.html">nvtabular.ops.TagAsItemID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsUserFeatures.html">nvtabular.ops.TagAsUserFeatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.TagAsUserID.html">nvtabular.ops.TagAsUserID</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ListSlice.html">nvtabular.ops.ListSlice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ValueCount.html">nvtabular.ops.ValueCount</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.ColumnSimilarity.html">nvtabular.ops.ColumnSimilarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.LambdaOp.html">nvtabular.ops.LambdaOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.Operator.html">nvtabular.ops.Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/nvtabular.ops.StatOperator.html">nvtabular.ops.StatOperator</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="modules.html">transformers4rec</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="transformers4rec.html">transformers4rec package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.config.html">transformers4rec.config package</a></li>
<li class="toctree-l3 current active has-children"><a class="reference internal" href="transformers4rec.torch.html">transformers4rec.torch package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html">transformers4rec.torch.block package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.features.html">transformers4rec.torch.features package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html">transformers4rec.torch.model package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html">transformers4rec.torch.tabular package</a></li>
<li class="toctree-l4 current active"><a class="current reference internal" href="#">transformers4rec.torch.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.utils.html">transformers4rec.utils package</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="merlin_standard_lib.html">merlin_standard_lib package</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="merlin_standard_lib.proto.html">merlin_standard_lib.proto package</a></li>
<li class="toctree-l3"><a class="reference internal" href="merlin_standard_lib.schema.html">merlin_standard_lib.schema package</a></li>
<li class="toctree-l3"><a class="reference internal" href="merlin_standard_lib.utils.html">merlin_standard_lib.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-merlin-ecosystem-nav" aria-label="Merlin Ecosystem Nav">
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul class="nav bd-sidenav">
      <li class="toctree-l1"><a class="reference external" href="/core/">Core</a></li>
      <li class="toctree-l1"><a class="reference external" href="/models/">Models</a></li>
      <li class="toctree-l1"><a class="reference external" href="/systems/">Systems</a></li>
      <li class="toctree-l1"><a class="reference external" href="/NVTabular/">NVTabular</a></li>
      <li class="toctree-l1"><a class="reference external" href="/Transformers4Rec/">Transformers4Rec</a></li>
      <li class="toctree-l1"><a class="reference external" href="/dataloader/">Dataloader</a></li>
      <li class="toctree-l1"><a class="reference external" href="/HugetCTR/">HugeCTR</a></li>
    </ul>
  </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>transformers4rec.torch.utils package</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.data_utils">transformers4rec.torch.utils.data_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.set_dataset()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.parse"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.parse()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.num_workers</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.pin_memory</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.drop_last</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.set_dataset()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.dataset</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.timeout</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.sampler</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.pin_memory_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader"><code class="docutils literal notranslate"><span class="pre">DLDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.device"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.dataset</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.num_workers</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.pin_memory</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.drop_last</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.timeout</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.sampler</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.pin_memory_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.drop_last</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.dataset</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.set_dataset()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.output_schema"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.output_schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.num_workers</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.pin_memory</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.timeout</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.sampler</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.pin_memory_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.ParquetDataset"><code class="docutils literal notranslate"><span class="pre">ParquetDataset</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.ParquetDataset.pad_seq_column_if_needed"><code class="docutils literal notranslate"><span class="pre">ParquetDataset.pad_seq_column_if_needed()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.ShuffleDataset"><code class="docutils literal notranslate"><span class="pre">ShuffleDataset</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.to_core_schema"><code class="docutils literal notranslate"><span class="pre">to_core_schema()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.examples_utils">transformers4rec.torch.utils.examples_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.list_files"><code class="docutils literal notranslate"><span class="pre">list_files()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.visualize_response"><code class="docutils literal notranslate"><span class="pre">visualize_response()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.fit_and_evaluate"><code class="docutils literal notranslate"><span class="pre">fit_and_evaluate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.wipe_memory"><code class="docutils literal notranslate"><span class="pre">wipe_memory()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.schema_utils">transformers4rec.torch.utils.schema_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.schema_utils.random_data_from_schema"><code class="docutils literal notranslate"><span class="pre">random_data_from_schema()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.torch_utils">transformers4rec.torch.utils.torch_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.build"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.output_size"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.forward_output_size"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LossMixin"><code class="docutils literal notranslate"><span class="pre">LossMixin</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LossMixin.compute_loss"><code class="docutils literal notranslate"><span class="pre">LossMixin.compute_loss()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin"><code class="docutils literal notranslate"><span class="pre">MetricsMixin</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.compute_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.reset_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.reset_metrics()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.requires_schema"><code class="docutils literal notranslate"><span class="pre">requires_schema()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.check_gpu"><code class="docutils literal notranslate"><span class="pre">check_gpu()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.get_output_sizes_from_schema"><code class="docutils literal notranslate"><span class="pre">get_output_sizes_from_schema()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.calculate_batch_size_from_input_size"><code class="docutils literal notranslate"><span class="pre">calculate_batch_size_from_input_size()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.check_inputs"><code class="docutils literal notranslate"><span class="pre">check_inputs()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.extract_topk"><code class="docutils literal notranslate"><span class="pre">extract_topk()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.create_output_placeholder"><code class="docutils literal notranslate"><span class="pre">create_output_placeholder()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.tranform_label_to_onehot"><code class="docutils literal notranslate"><span class="pre">tranform_label_to_onehot()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_detach"><code class="docutils literal notranslate"><span class="pre">nested_detach()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_concat"><code class="docutils literal notranslate"><span class="pre">nested_concat()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.torch_pad_and_concatenate"><code class="docutils literal notranslate"><span class="pre">torch_pad_and_concatenate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.atleast_1d"><code class="docutils literal notranslate"><span class="pre">atleast_1d()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_numpify"><code class="docutils literal notranslate"><span class="pre">nested_numpify()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_truncate"><code class="docutils literal notranslate"><span class="pre">nested_truncate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.numpy_pad_and_concatenate"><code class="docutils literal notranslate"><span class="pre">numpy_pad_and_concatenate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.one_hot_1d"><code class="docutils literal notranslate"><span class="pre">one_hot_1d()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LambdaModule"><code class="docutils literal notranslate"><span class="pre">LambdaModule</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LambdaModule.forward"><code class="docutils literal notranslate"><span class="pre">LambdaModule.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LambdaModule.training"><code class="docutils literal notranslate"><span class="pre">LambdaModule.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.CausalLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.CausalLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MaskedLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MaskedLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.PermutationLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.compute_masked_targets"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.PermutationLanguageModeling.compute_masked_targets()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.transformer_required_arguments"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.PermutationLanguageModeling.transformer_required_arguments()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ReplacementLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.get_fake_tokens"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ReplacementLanguageModeling.get_fake_tokens()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.sample_from_softmax"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ReplacementLanguageModeling.sample_from_softmax()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DEFAULT_MASKING"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DEFAULT_MASKING</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.BertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.BertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ConvBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ConvBertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DebertaConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DebertaConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DistilBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DistilBertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.GPT2Config"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.GPT2Config</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.LongformerConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.LongformerConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MegatronBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MegatronBertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MPNetConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MPNetConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RobertaConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.RobertaConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RoFormerConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.RoFormerConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.TransfoXLConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.TransfoXLConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.XLNetConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.XLNetConfig</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils">Module contents</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="transformers4rec-torch-utils-package">
<h1>transformers4rec.torch.utils package<a class="headerlink" href="#transformers4rec-torch-utils-package" title="Permalink to this heading">#</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading">#</a></h2>
</section>
<section id="module-transformers4rec.torch.utils.data_utils">
<span id="transformers4rec-torch-utils-data-utils-module"></span><h2>transformers4rec.torch.utils.data_utils module<a class="headerlink" href="#module-transformers4rec.torch.utils.data_utils" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.T4RecDataLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.data_utils.</span></span><span class="sig-name descname"><span class="pre">T4RecDataLoader</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#T4RecDataLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Base Helper class to build dataloader from the schema with properties
required by T4Rec Trainer class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.T4RecDataLoader.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">paths_or_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#T4RecDataLoader.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.from_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.T4RecDataLoader.set_dataset">
<span class="sig-name descname"><span class="pre">set_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_or_dataset</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#T4RecDataLoader.set_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.set_dataset" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.T4RecDataLoader.parse">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">class_or_str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#T4RecDataLoader.parse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.parse" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.data_utils.</span></span><span class="sig-name descname"><span class="pre">PyarrowDataLoader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_or_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols_to_read</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle_buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pin_memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#PyarrowDataLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader" title="transformers4rec.torch.utils.data_utils.T4RecDataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecDataLoader</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.batch_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.num_workers">
<span class="sig-name descname"><span class="pre">num_workers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.num_workers" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory">
<span class="sig-name descname"><span class="pre">pin_memory</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.drop_last">
<span class="sig-name descname"><span class="pre">drop_last</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.drop_last" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.set_dataset">
<span class="sig-name descname"><span class="pre">set_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cols_to_read</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#PyarrowDataLoader.set_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.set_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>set the Parquet dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>cols_to_read</strong> (<em>str</em>)  The list of features names to load</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paths_or_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuous_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle_buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pin_memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#PyarrowDataLoader.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiates <code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>)  Dataset schema</p></li>
<li><p><strong>paths_or_dataset</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset" title="merlin.io.Dataset"><em>Dataset</em></a><em>]</em>)  Path to paquet data of Dataset object.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>)  batch size of Dataloader.</p></li>
<li><p><strong>max_sequence_length</strong> (<em>int</em>)  The maximum length of list features.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.dataset">
<span class="sig-name descname"><span class="pre">dataset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dataset</span><span class="p"><span class="pre">[</span></span><span class="pre">T_co</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.dataset" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.timeout">
<span class="sig-name descname"><span class="pre">timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.timeout" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.sampler">
<span class="sig-name descname"><span class="pre">sampler</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sampler</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.sampler" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory_device">
<span class="sig-name descname"><span class="pre">pin_memory_device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory_device" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.PyarrowDataLoader.prefetch_factor">
<span class="sig-name descname"><span class="pre">prefetch_factor</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.prefetch_factor" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.data_utils.</span></span><span class="sig-name descname"><span class="pre">DLDataLoader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#DLDataLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></p>
<p>This class is an extension of the torch dataloader.
It is required to support the FastAI framework.</p>
<p>Setting the batch size directly to DLDataLoader makes it 3x slower.
So we set as an alternative attribute and use it within
T4Rec Trainer during evaluation
# TODO : run experiments with new merlin-dataloader</p>
<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.device" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.dataset">
<span class="sig-name descname"><span class="pre">dataset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dataset</span><span class="p"><span class="pre">[</span></span><span class="pre">T_co</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.dataset" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.batch_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.num_workers">
<span class="sig-name descname"><span class="pre">num_workers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.num_workers" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory">
<span class="sig-name descname"><span class="pre">pin_memory</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.drop_last">
<span class="sig-name descname"><span class="pre">drop_last</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.drop_last" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.timeout">
<span class="sig-name descname"><span class="pre">timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.timeout" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.sampler">
<span class="sig-name descname"><span class="pre">sampler</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sampler</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.sampler" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory_device">
<span class="sig-name descname"><span class="pre">pin_memory_device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory_device" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.DLDataLoader.prefetch_factor">
<span class="sig-name descname"><span class="pre">prefetch_factor</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.prefetch_factor" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.data_utils.</span></span><span class="sig-name descname"><span class="pre">MerlinDataLoader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_or_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conts=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cats=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lists=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collate_fn=&lt;function</span> <span class="pre">MerlinDataLoader.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size=0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reader_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed_fn=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parts_per_chunk=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_size=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_rank=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_last=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_groups_per_part=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#MerlinDataLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader" title="transformers4rec.torch.utils.data_utils.T4RecDataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">T4RecDataLoader</span></code></a>, <a class="reference internal" href="#transformers4rec.torch.utils.data_utils.DLDataLoader" title="transformers4rec.torch.utils.data_utils.DLDataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">DLDataLoader</span></code></a></p>
<p>This class extends the [Merlin data loader]
(<a class="github reference external" href="https://github.com/NVIDIA-Merlin/dataloader/blob/stable/merlin/dataloader/torch.py">NVIDIA-Merlin/dataloader</a>).
The data input requires a merlin.io.Dataset or a path to the data files.
It also sets the datasets schema with the necessary properties to prepare the input
list features as dense tensors (i.e. padded to the specified <cite>max_sequence_length</cite>).
The dense representation is required by the Transformers4Rec input modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>paths_or_dataset</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset" title="merlin.io.Dataset"><em>merlin.io.Dataset</em></a><em>]</em>)  The dataset to load.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>)  The size of each batch to supply to the model.</p></li>
<li><p><strong>max_sequence_length</strong> (<em>int</em>)  The maximum sequence length to use for padding list columns.
By default, <cite>0</cite> is used as the padding index.</p></li>
<li><p><strong>cats</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The list of categorical columns in the dataset.
By default None.</p></li>
<li><p><strong>conts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The list of continuous columns in the dataset.
By default None.</p></li>
<li><p><strong>labels</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The list of label columns in the dataset.
By default None.</p></li>
<li><p><strong>lists</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>)  The list of sequential columns in the dataset.
By default None.</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>optional</em>)  Enable/disable shuffling of dataset.
By default False.</p></li>
<li><p><strong>parts_per_chunk</strong> (<em>int</em>)  The number of partitions from the iterator, an Merlin Dataset,
to concatenate into a chunk. By default 1.</p></li>
<li><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>)  The device id of the selected GPU
By default None.</p></li>
<li><p><strong>drop_last</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether or not to drop the last batch in an epoch. This is useful when you need to
guarantee that each batch contains exactly <cite>batch_size</cite> rows - since the last batch
will usually contain fewer rows.</p></li>
<li><p><strong>seed_fn</strong> (<em>callable</em>)  Function used to initialize random state</p></li>
<li><p><strong>parts_per_chunk</strong>  Number of dataset partitions with size dictated by <cite>buffer_size</cite>
to load and concatenate asynchronously. More partitions leads to
better epoch-level randomness but can negatively impact throughput</p></li>
<li><p><strong>global_size</strong> (<em>int</em><em>, </em><em>optional</em>)  When doing distributed training, this indicates the number of total processes that are
training the model.</p></li>
<li><p><strong>global_rank</strong> (<em>int</em><em>, </em><em>optional</em>)  When doing distributed training, this indicates the local rank for the current process.</p></li>
<li><p><strong>schema</strong> (<a class="reference internal" href="../api_core/generated/merlin.schema.Schema.html#merlin.schema.Schema" title="merlin.schema.Schema"><em>Schema</em></a><em>, </em><em>optional</em>)  The <cite>Schema</cite> with the input features.</p></li>
<li><p><strong>reader_kwargs</strong>  Extra arguments to pass to the merlin.io.Dataset object, when the path to data files
is provided in <cite>paths_or_dataset</cite> argument.</p></li>
<li><p><strong>row_groups_per_part</strong> (<em>bool</em><em>, </em><em>optional</em>)  If true, preserve the group partitions when loading the dataset from parquet files.</p></li>
<li><p><strong>collate_fn</strong> (<em>Callable</em><em>, </em><em>optional</em>)  A processing function to collect and prepare the list samples
(tuple of (input, target) Tensor(s)) returned by the Merlin DataLoader.</p></li>
<li><p><strong>transforms</strong> (<em>List</em><em>[</em><a class="reference internal" href="../api_core/generated/merlin.dag.BaseOperator.html#merlin.dag.BaseOperator" title="merlin.dag.BaseOperator"><em>merlin.dag.BaseOperator</em></a><em>]</em>)  A list of operators that the Merlin dataloader applies on top of the loaded
batch, which is a tuple of input and target tensors.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.batch_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.drop_last">
<span class="sig-name descname"><span class="pre">drop_last</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.drop_last" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.dataset">
<span class="sig-name descname"><span class="pre">dataset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dataset</span><span class="p"><span class="pre">[</span></span><span class="pre">T_co</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.dataset" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.set_dataset">
<span class="sig-name descname"><span class="pre">set_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">engine</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reader_kwargs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#MerlinDataLoader.set_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.set_dataset" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.from_schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema:</span> <span class="pre">~merlin_standard_lib.schema.schema.Schema</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paths_or_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuous_features=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_features=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collate_fn=&lt;function</span> <span class="pre">MerlinDataLoader.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size=0.06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parts_per_chunk=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#MerlinDataLoader.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.from_schema" title="Permalink to this definition">#</a></dt>
<dd><blockquote>
<div><p>Instantitates <cite>MerlinDataLoader</cite> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code>.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>)  Dataset schema</p></li>
<li><p><strong>paths_or_dataset</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="../api_core/generated/merlin.io.Dataset.html#merlin.io.Dataset" title="merlin.io.Dataset"><em>Dataset</em></a><em>]</em>)  Path to paquet data of Dataset object.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>)  batch size of Dataloader.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.output_schema">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_schema</span></span><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.output_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.num_workers">
<span class="sig-name descname"><span class="pre">num_workers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.num_workers" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory">
<span class="sig-name descname"><span class="pre">pin_memory</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.timeout">
<span class="sig-name descname"><span class="pre">timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.timeout" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.sampler">
<span class="sig-name descname"><span class="pre">sampler</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sampler</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.sampler" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory_device">
<span class="sig-name descname"><span class="pre">pin_memory_device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory_device" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.MerlinDataLoader.prefetch_factor">
<span class="sig-name descname"><span class="pre">prefetch_factor</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.prefetch_factor" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.ParquetDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.data_utils.</span></span><span class="sig-name descname"><span class="pre">ParquetDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parquet_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols_to_read</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_features_len_pad_trim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#ParquetDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.ParquetDataset" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.ParquetDataset.pad_seq_column_if_needed">
<span class="sig-name descname"><span class="pre">pad_seq_column_if_needed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#ParquetDataset.pad_seq_column_if_needed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.ParquetDataset.pad_seq_column_if_needed" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.ShuffleDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.data_utils.</span></span><span class="sig-name descname"><span class="pre">ShuffleDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#ShuffleDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.ShuffleDataset" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">IterableDataset</span></code></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.data_utils.to_core_schema">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.data_utils.</span></span><span class="sig-name descname"><span class="pre">to_core_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t4rec_schema</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/data_utils.html#to_core_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.data_utils.to_core_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</section>
<section id="module-transformers4rec.torch.utils.examples_utils">
<span id="transformers4rec-torch-utils-examples-utils-module"></span><h2>transformers4rec.torch.utils.examples_utils module<a class="headerlink" href="#module-transformers4rec.torch.utils.examples_utils" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.examples_utils.list_files">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.examples_utils.</span></span><span class="sig-name descname"><span class="pre">list_files</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">startpath</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/examples_utils.html#list_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.examples_utils.list_files" title="Permalink to this definition">#</a></dt>
<dd><p>Util function to print the nested structure of a directory</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.examples_utils.visualize_response">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.examples_utils.</span></span><span class="sig-name descname"><span class="pre">visualize_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">response</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">session_col</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'session_id'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/examples_utils.html#visualize_response"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.examples_utils.visualize_response" title="Permalink to this definition">#</a></dt>
<dd><p>Util function to extract top-k encoded item-ids from logits</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>cudf.DataFrame</em>)  the batch of raw data sent to triton server.</p></li>
<li><p><strong>response</strong> (<em>tritonclient.grpc.InferResult</em>)  the response returned by grpc client.</p></li>
<li><p><strong>top_k</strong> (<em>int</em>)  the <cite>top_k</cite> top items to retrieve from predictions.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.examples_utils.fit_and_evaluate">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.examples_utils.</span></span><span class="sig-name descname"><span class="pre">fit_and_evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_time_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_time_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/examples_utils.html#fit_and_evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.examples_utils.fit_and_evaluate" title="Permalink to this definition">#</a></dt>
<dd><p>Util function for time-window based fine-tuning using the T4rec Trainer class.
Iteratively train using data of a given index and evaluate on the validation data
of the following index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start_time_index</strong> (<em>int</em>)  The start index for training, it should match the partitions of the data directory</p></li>
<li><p><strong>end_time_index</strong> (<em>int</em>)  The end index for training, it should match the partitions of the  data directory</p></li>
<li><p><strong>input_dir</strong> (<em>str</em>)  The input directory where the parquet files were saved based on partition column</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>indexed_by_time_metrics</strong>  The dictionary of ranking metrics: each item is the list of scores over time indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.examples_utils.wipe_memory">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.examples_utils.</span></span><span class="sig-name descname"><span class="pre">wipe_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/examples_utils.html#wipe_memory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.examples_utils.wipe_memory" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</section>
<section id="module-transformers4rec.torch.utils.schema_utils">
<span id="transformers4rec-torch-utils-schema-utils-module"></span><h2>transformers4rec.torch.utils.schema_utils module<a class="headerlink" href="#module-transformers4rec.torch.utils.schema_utils" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.schema_utils.random_data_from_schema">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.schema_utils.</span></span><span class="sig-name descname"><span class="pre">random_data_from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_rows</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_session_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_session_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragged</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/schema_utils.html#random_data_from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.schema_utils.random_data_from_schema" title="Permalink to this definition">#</a></dt>
<dd><p>Generates random tabular data based on a given schema.
The generated data can be used for testing
data preprocessing or model training pipelines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<a class="reference internal" href="../api_core/generated/merlin.schema.Schema.html#merlin.schema.Schema" title="merlin.schema.Schema"><em>Schema</em></a>)  The schema to be used for generating the random tabular data.</p></li>
<li><p><strong>num_rows</strong> (<em>int</em>)  The number of rows.</p></li>
<li><p><strong>max_session_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>)  The maximum session length.
If None, the session length will not be limited.
By default None</p></li>
<li><p><strong>min_session_length</strong> (<em>int</em>)  The minimum session length.
By default 5</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>)  The device on which the synthetic data should be created.
If None, the synthetic data will be created on the CPU.
By default None</p></li>
<li><p><strong>ragged</strong> (<em>bool</em>)  If True, the sequence features will be represented with __values and __offsets.
By default False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary where each key is a feature name and each value is the generated
tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>TabularData</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-transformers4rec.torch.utils.torch_utils">
<span id="transformers4rec-torch-utils-torch-utils-module"></span><h2>transformers4rec.torch.utils.torch_utils module<a class="headerlink" href="#module-transformers4rec.torch.utils.torch_utils" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.OutputSizeMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">OutputSizeMixin</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#OutputSizeMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.config.html#transformers4rec.config.schema.SchemaMixin" title="transformers4rec.config.schema.SchemaMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">SchemaMixin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.OutputSizeMixin.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#OutputSizeMixin.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.build" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.OutputSizeMixin.output_size">
<span class="sig-name descname"><span class="pre">output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#OutputSizeMixin.output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.OutputSizeMixin.forward_output_size">
<span class="sig-name descname"><span class="pre">forward_output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#OutputSizeMixin.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.forward_output_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.LossMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">LossMixin</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#LossMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.LossMixin" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Mixin to use for a <cite>torch.Module</cite> that can calculate a loss.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.LossMixin.compute_loss">
<span class="sig-name descname"><span class="pre">compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#LossMixin.compute_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.LossMixin.compute_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the loss on a batch of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><em>torch.Tensor</em><em>, </em><em>TabularData</em><em>]</em>)  TODO</p></li>
<li><p><strong>targets</strong> (<em>Union</em><em>[</em><em>torch.Tensor</em><em>, </em><em>TabularData</em><em>]</em>)  TODO</p></li>
<li><p><strong>compute_metrics</strong> (<em>bool</em><em>, </em><em>default=True</em>)  Boolean indicating whether or not to update the state of the metrics
(if they are defined).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MetricsMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">MetricsMixin</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#MetricsMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Mixin to use for a <cite>torch.Module</cite> that can calculate metrics.</p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MetricsMixin.calculate_metrics">
<span class="sig-name descname"><span class="pre">calculate_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#MetricsMixin.calculate_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.calculate_metrics" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate metrics on a batch of data, each metric is stateful and this updates the state.</p>
<p>The state of each metric can be retrieved by calling the <cite>compute_metrics</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Union</em><em>[</em><em>torch.Tensor</em><em>, </em><em>TabularData</em><em>]</em>)  Tensor or dictionary of predictions returned by the T4Rec model</p></li>
<li><p><strong>targets</strong> (<em>Union</em><em>[</em><em>torch.Tensor</em><em>, </em><em>TabularData</em><em>]</em>)  Tensor or dictionary of true labels returned by the T4Rec model</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MetricsMixin.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#MetricsMixin.compute_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.compute_metrics" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the current state of each metric.</p>
<p>The state is typically updated each batch by calling the <cite>calculate_metrics</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>str</em><em>, </em><em>default=&quot;val&quot;</em>)  </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Dict[str, Union[float, torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MetricsMixin.reset_metrics">
<span class="sig-name descname"><span class="pre">reset_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#MetricsMixin.reset_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.reset_metrics" title="Permalink to this definition">#</a></dt>
<dd><p>Reset all metrics.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.requires_schema">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">requires_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#requires_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.requires_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.check_gpu">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">check_gpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#check_gpu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.check_gpu" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.get_output_sizes_from_schema">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">get_output_sizes_from_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#get_output_sizes_from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.get_output_sizes_from_schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.calculate_batch_size_from_input_size">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">calculate_batch_size_from_input_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#calculate_batch_size_from_input_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.calculate_batch_size_from_input_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.check_inputs">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">check_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#check_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.check_inputs" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.extract_topk">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">extract_topk</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#extract_topk"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.extract_topk" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.create_output_placeholder">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">create_output_placeholder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#create_output_placeholder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.create_output_placeholder" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.tranform_label_to_onehot">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">tranform_label_to_onehot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#tranform_label_to_onehot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.tranform_label_to_onehot" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.nested_detach">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">nested_detach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#nested_detach"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.nested_detach" title="Permalink to this definition">#</a></dt>
<dd><p>Detach <cite>tensors</cite> (even if its a nested list/tuple/dict of tensors).
#TODO this method was copied from the latest version of HF transformers library to support
dict outputs. So we should remove it when T4Rec is updated to use the latest version</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.nested_concat">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">nested_concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#nested_concat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.nested_concat" title="Permalink to this definition">#</a></dt>
<dd><p>Concat the <cite>new_tensors</cite> to <cite>tensors</cite> on the first dim and pad them on the second if needed.
Works for tensors or nested list/tuples/dict of tensors.
#TODO this method was copied from the latest version of HF transformers library to support
dict outputs. So we should remove it when T4Rec is updated to use the latest version</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.torch_pad_and_concatenate">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">torch_pad_and_concatenate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#torch_pad_and_concatenate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.torch_pad_and_concatenate" title="Permalink to this definition">#</a></dt>
<dd><p>Concatenates <cite>tensor1</cite> and <cite>tensor2</cite> on first axis, applying padding on the second as needed</p>
<p>#TODO this method was copied from the latest version of HF transformers library to support
dict outputs. So we should remove it when T4Rec is updated to use the latest version</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.atleast_1d">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">atleast_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor_or_array</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#atleast_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.atleast_1d" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.nested_numpify">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">nested_numpify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#nested_numpify"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.nested_numpify" title="Permalink to this definition">#</a></dt>
<dd><p>Numpify <cite>tensors</cite> (even if its a nested list/tuple/dict of tensors).
#TODO this method was copied from the latest version of HF transformers library to support
dict outputs. So we should remove it when T4Rec is updated to use the latest version</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.nested_truncate">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">nested_truncate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">limit</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#nested_truncate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.nested_truncate" title="Permalink to this definition">#</a></dt>
<dd><p>Truncate <cite>tensors</cite> at <cite>limit</cite> (even if its a nested list/tuple/dict of tensors).
#TODO this method was copied from the latest version of HF transformers library to support
dict outputs. So we should remove it when T4Rec is updated to use the latest version</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.numpy_pad_and_concatenate">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">numpy_pad_and_concatenate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">array2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#numpy_pad_and_concatenate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.numpy_pad_and_concatenate" title="Permalink to this definition">#</a></dt>
<dd><p>Concatenates <cite>array1</cite> and <cite>array2</cite> on first axis, applying padding on the second if necessary.
#TODO this method was copied from the latest version of HF transformers library to support
dict outputs. So we should remove it when T4Rec is updated to use the latest version</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.one_hot_1d">
<span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">one_hot_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">device</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dtype</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">torch.float32</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#one_hot_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.one_hot_1d" title="Permalink to this definition">#</a></dt>
<dd><p>Coverts a 1d label tensor to one-hot representation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<em>torch.Tensor</em>)  tensor with labels of shape <span class="math notranslate nohighlight">\((N, H, W)\)</span>,
where N is batch size. Each value is an integer
representing correct classification.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em>)  number of classes in labels.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>torch.device</em><em>]</em>)  the desired device of returned tensor.
Default: if None, uses the current device for the default tensor type
(see torch.set_default_tensor_type()). device will be the CPU for CPU
tensor types and the current CUDA device for CUDA tensor types.</p></li>
<li><p><strong>dtype</strong> (<em>Optional</em><em>[</em><em>torch.dtype</em><em>]</em>)  the desired data type of returned
tensor. Default: torch.float32</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the labels in one hot tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<dl>
<dt>Examples::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">one_hot_1d</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="go">tensor([[1., 0., 0.],</span>
<span class="go">        [0., 1., 0.],</span>
<span class="go">        [0., 0., 1.],</span>
<span class="go">        [1., 0., 0.],</span>
<span class="go">       ])</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.LambdaModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">LambdaModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lambda_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#LambdaModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.LambdaModule" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.LambdaModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#LambdaModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.LambdaModule.forward" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.LambdaModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.LambdaModule.training" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformers4rec.torch.utils.torch_utils.</span></span><span class="sig-name descname"><span class="pre">MappingTransformerMasking</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/utils/torch_utils.html#MappingTransformerMasking"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">CausalLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskSequence</span></code></a></p>
<p>In Causal Language Modeling (clm) you predict the next item based on past positions of the
sequence. Future positions are masked.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>train_on_last_item_seq_only</strong> (<em>predict only last item during training</em>)  </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling.apply_mask_to_inputs">
<span class="sig-name descname"><span class="pre">apply_mask_to_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling.apply_mask_to_inputs" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">MaskedLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlm_probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.15</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskSequence</span></code></a></p>
<p>In Masked Language Modeling (mlm) you randomly select some positions of the sequence to be
predicted, which are masked.
During training, the Transformer layer is allowed to use positions on the right (future info).
During inference, all past items are visible for the Transformer layer, which tries to predict
the next item.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>mlm_probability</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>default = 0.15</em>)  Probability of an item to be selected (masked) as a label of the given sequence.
p.s. We enforce that at least one item is masked for each sequence, so that the network can
learn something with it.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling.apply_mask_to_inputs">
<span class="sig-name descname"><span class="pre">apply_mask_to_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling.apply_mask_to_inputs" title="Permalink to this definition">#</a></dt>
<dd><blockquote>
<div><p>Control the masked positions in the inputs by replacing the true interaction
by a learnable masked embedding.</p>
<dl class="simple">
<dt>inputs: torch.Tensor</dt><dd><p>The 3-D tensor of interaction embeddings resulting from the ops:
TabularFeatures + aggregation + projection(optional)</p>
</dd>
<dt>schema: MaskingSchema</dt><dd><p>The boolean mask indicating masked positions.</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>training: bool</dt><dd><p>Flag to indicate whether we are in <cite>Training</cite> mode or not.
During training, the labels can be any items within the sequence
based on the selected masking task.</p>
</dd>
<dt>testing: bool</dt><dd><p>Flag to indicate whether we are in <cite>Evaluation</cite> (=True)
or <cite>Inference</cite> (=False) mode.
During evaluation, we are predicting all next items or last item only
in the sequence based on the param <cite>eval_on_last_item_seq_only</cite>.
During inference, we dont mask the input sequence and use all available
information to predict the next item.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">PermutationLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plm_probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.16666666666666666</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_span_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">permute_all</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskSequence</span></code></a></p>
<p>In Permutation Language Modeling (plm) you use a permutation factorization at the level of the
self-attention layer to define the accessible bidirectional context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>max_span_length</strong> (<em>int</em>)  maximum length of a span of masked items</p></li>
<li><p><strong>plm_probability</strong> (<em>float</em>)  The ratio of surrounding items to unmask to define the context of the span-based
prediction segment of items</p></li>
<li><p><strong>permute_all</strong> (<em>bool</em>)  Compute partial span-based prediction (=False) or not.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.compute_masked_targets">
<span class="sig-name descname"><span class="pre">compute_masked_targets</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskingInfo" title="transformers4rec.torch.masking.MaskingInfo"><span class="pre">MaskingInfo</span></a></span></span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.compute_masked_targets" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.transformer_required_arguments">
<span class="sig-name descname"><span class="pre">transformer_required_arguments</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.transformer_required_arguments" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ReplacementLanguageModeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_on_last_item_seq_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_from_batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskedLanguageModeling" title="transformers4rec.torch.masking.MaskedLanguageModeling"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaskedLanguageModeling</span></code></a></p>
<p>Replacement Language Modeling (rtd) you use MLM to randomly select some items, but replace
them by random tokens.
Then, a discriminator model (that can share the weights with the generator or not), is asked
to classify whether the item at each position belongs or not to the original sequence.
The generator-discriminator architecture was jointly trained using Masked LM and RTD tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>)  The hidden dimension of input tensors, needed to initialize trainable vector of masked
positions.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em><em>, </em><em>default = 0</em>)  Index of padding item used for getting batch of sequences with the same length</p></li>
<li><p><strong>eval_on_last_item_seq_only</strong> (<em>bool</em><em>, </em><em>default = True</em>)  Predict only last item during evaluation</p></li>
<li><p><strong>sample_from_batch</strong> (<em>bool</em>)  Whether to sample replacement item ids from the same batch or not</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.get_fake_tokens">
<span class="sig-name descname"><span class="pre">get_fake_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">itemid_seq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_flat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.get_fake_tokens" title="Permalink to this definition">#</a></dt>
<dd><p>Second task of RTD is binary classification to train the discriminator.
The task consists of generating fake data by replacing [MASK] positions with random items,
ELECTRA discriminator learns to detect fake replacements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>itemid_seq</strong> (<em>torch.Tensor</em><em> of </em><em>shape</em><em> (</em><em>bs</em><em>, </em><em>max_seq_len</em><em>)</em>)  input sequence of item ids</p></li>
<li><p><strong>target_flat</strong> (<em>torch.Tensor</em><em> of </em><em>shape</em><em> (</em><em>bs*max_seq_len</em><em>)</em>)  flattened masked label sequences</p></li>
<li><p><strong>logits</strong> (<em>torch.Tensor</em><em> of </em><em>shape</em><em> (</em><em>#pos_item</em><em>, </em><em>vocab_size</em><em> or </em><em>#pos_item</em><em>)</em><em>,</em>)  mlm probabilities of positive items computed by the generator model.
The logits are over the whole corpus if sample_from_batch = False,
over the positive items (masked) of the current batch otherwise</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>corrupted_inputs</strong> (<em>torch.Tensor of shape (bs, max_seq_len)</em>)  input sequence of item ids with fake replacement</p></li>
<li><p><strong>discriminator_labels</strong> (<em>torch.Tensor of shape (bs, max_seq_len)</em>)  binary labels to distinguish between original and replaced items</p></li>
<li><p><strong>batch_updates</strong> (<em>torch.Tensor of shape (#pos_item)</em>)  the indices of replacement item within the current batch if sample_from_batch is enabled</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.sample_from_softmax">
<span class="sig-name descname"><span class="pre">sample_from_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.sample_from_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>Sampling method for replacement token modeling (ELECTRA)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logits</strong> (<em>torch.Tensor</em><em>(</em><em>pos_item</em><em>, </em><em>vocab_size</em><em>)</em>)  scores of probability of masked positions returned  by the generator model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>samples</strong>  ids of replacements items.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor(#pos_item)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DEFAULT_MASKING">
<span class="sig-name descname"><span class="pre">DEFAULT_MASKING</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.CausalLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.PermutationLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DEFAULT_MASKING" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.BertConfig">
<span class="sig-name descname"><span class="pre">BertConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.BertConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ConvBertConfig">
<span class="sig-name descname"><span class="pre">ConvBertConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ConvBertConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DebertaConfig">
<span class="sig-name descname"><span class="pre">DebertaConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DebertaConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DistilBertConfig">
<span class="sig-name descname"><span class="pre">DistilBertConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DistilBertConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.GPT2Config">
<span class="sig-name descname"><span class="pre">GPT2Config</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.CausalLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.GPT2Config" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.LongformerConfig">
<span class="sig-name descname"><span class="pre">LongformerConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.CausalLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.LongformerConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MegatronBertConfig">
<span class="sig-name descname"><span class="pre">MegatronBertConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MegatronBertConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MPNetConfig">
<span class="sig-name descname"><span class="pre">MPNetConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MPNetConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RobertaConfig">
<span class="sig-name descname"><span class="pre">RobertaConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RobertaConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RoFormerConfig">
<span class="sig-name descname"><span class="pre">RoFormerConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.CausalLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RoFormerConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.TransfoXLConfig">
<span class="sig-name descname"><span class="pre">TransfoXLConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.CausalLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.TransfoXLConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.XLNetConfig">
<span class="sig-name descname"><span class="pre">XLNetConfig</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[&lt;class</span> <span class="pre">'transformers4rec.torch.masking.CausalLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.MaskedLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.ReplacementLanguageModeling'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'transformers4rec.torch.masking.PermutationLanguageModeling'&gt;]</span></em><a class="headerlink" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.XLNetConfig" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-transformers4rec.torch.utils">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-transformers4rec.torch.utils" title="Permalink to this heading">#</a></h2>
</section>
</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="transformers4rec.torch.tabular.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">transformers4rec.torch.tabular package</p>
      </div>
    </a>
    <a class="right-next"
       href="transformers4rec.utils.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">transformers4rec.utils package</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.data_utils">transformers4rec.torch.utils.data_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.set_dataset()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.T4RecDataLoader.parse"><code class="docutils literal notranslate"><span class="pre">T4RecDataLoader.parse()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.num_workers</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.pin_memory</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.drop_last</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.set_dataset()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.dataset</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.timeout</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.sampler</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.pin_memory_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.PyarrowDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader"><code class="docutils literal notranslate"><span class="pre">DLDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.device"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.dataset</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.num_workers</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.pin_memory</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.drop_last</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.timeout</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.sampler</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.pin_memory_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.DLDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">DLDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.batch_size"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.drop_last"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.drop_last</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.dataset"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.dataset</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.set_dataset"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.set_dataset()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.from_schema"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.from_schema()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.output_schema"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.output_schema</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.num_workers"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.num_workers</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.pin_memory</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.timeout"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.timeout</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.sampler"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.sampler</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.pin_memory_device"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.pin_memory_device</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.MerlinDataLoader.prefetch_factor"><code class="docutils literal notranslate"><span class="pre">MerlinDataLoader.prefetch_factor</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.ParquetDataset"><code class="docutils literal notranslate"><span class="pre">ParquetDataset</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.ParquetDataset.pad_seq_column_if_needed"><code class="docutils literal notranslate"><span class="pre">ParquetDataset.pad_seq_column_if_needed()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.ShuffleDataset"><code class="docutils literal notranslate"><span class="pre">ShuffleDataset</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.data_utils.to_core_schema"><code class="docutils literal notranslate"><span class="pre">to_core_schema()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.examples_utils">transformers4rec.torch.utils.examples_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.list_files"><code class="docutils literal notranslate"><span class="pre">list_files()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.visualize_response"><code class="docutils literal notranslate"><span class="pre">visualize_response()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.fit_and_evaluate"><code class="docutils literal notranslate"><span class="pre">fit_and_evaluate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.examples_utils.wipe_memory"><code class="docutils literal notranslate"><span class="pre">wipe_memory()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.schema_utils">transformers4rec.torch.utils.schema_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.schema_utils.random_data_from_schema"><code class="docutils literal notranslate"><span class="pre">random_data_from_schema()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils.torch_utils">transformers4rec.torch.utils.torch_utils module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.build"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.output_size"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.output_size()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.OutputSizeMixin.forward_output_size"><code class="docutils literal notranslate"><span class="pre">OutputSizeMixin.forward_output_size()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LossMixin"><code class="docutils literal notranslate"><span class="pre">LossMixin</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LossMixin.compute_loss"><code class="docutils literal notranslate"><span class="pre">LossMixin.compute_loss()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin"><code class="docutils literal notranslate"><span class="pre">MetricsMixin</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.calculate_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.calculate_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.compute_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.compute_metrics()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MetricsMixin.reset_metrics"><code class="docutils literal notranslate"><span class="pre">MetricsMixin.reset_metrics()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.requires_schema"><code class="docutils literal notranslate"><span class="pre">requires_schema()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.check_gpu"><code class="docutils literal notranslate"><span class="pre">check_gpu()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.get_output_sizes_from_schema"><code class="docutils literal notranslate"><span class="pre">get_output_sizes_from_schema()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.calculate_batch_size_from_input_size"><code class="docutils literal notranslate"><span class="pre">calculate_batch_size_from_input_size()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.check_inputs"><code class="docutils literal notranslate"><span class="pre">check_inputs()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.extract_topk"><code class="docutils literal notranslate"><span class="pre">extract_topk()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.create_output_placeholder"><code class="docutils literal notranslate"><span class="pre">create_output_placeholder()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.tranform_label_to_onehot"><code class="docutils literal notranslate"><span class="pre">tranform_label_to_onehot()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_detach"><code class="docutils literal notranslate"><span class="pre">nested_detach()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_concat"><code class="docutils literal notranslate"><span class="pre">nested_concat()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.torch_pad_and_concatenate"><code class="docutils literal notranslate"><span class="pre">torch_pad_and_concatenate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.atleast_1d"><code class="docutils literal notranslate"><span class="pre">atleast_1d()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_numpify"><code class="docutils literal notranslate"><span class="pre">nested_numpify()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.nested_truncate"><code class="docutils literal notranslate"><span class="pre">nested_truncate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.numpy_pad_and_concatenate"><code class="docutils literal notranslate"><span class="pre">numpy_pad_and_concatenate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.one_hot_1d"><code class="docutils literal notranslate"><span class="pre">one_hot_1d()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LambdaModule"><code class="docutils literal notranslate"><span class="pre">LambdaModule</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LambdaModule.forward"><code class="docutils literal notranslate"><span class="pre">LambdaModule.forward()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.LambdaModule.training"><code class="docutils literal notranslate"><span class="pre">LambdaModule.training</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.CausalLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.CausalLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.CausalLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MaskedLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MaskedLanguageModeling.apply_mask_to_inputs"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MaskedLanguageModeling.apply_mask_to_inputs()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.PermutationLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.compute_masked_targets"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.PermutationLanguageModeling.compute_masked_targets()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.PermutationLanguageModeling.transformer_required_arguments"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.PermutationLanguageModeling.transformer_required_arguments()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ReplacementLanguageModeling</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.get_fake_tokens"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ReplacementLanguageModeling.get_fake_tokens()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ReplacementLanguageModeling.sample_from_softmax"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ReplacementLanguageModeling.sample_from_softmax()</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DEFAULT_MASKING"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DEFAULT_MASKING</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.BertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.BertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.ConvBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.ConvBertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DebertaConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DebertaConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.DistilBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.DistilBertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.GPT2Config"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.GPT2Config</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.LongformerConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.LongformerConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MegatronBertConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MegatronBertConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.MPNetConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.MPNetConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RobertaConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.RobertaConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.RoFormerConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.RoFormerConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.TransfoXLConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.TransfoXLConfig</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers4rec.torch.utils.torch_utils.MappingTransformerMasking.XLNetConfig"><code class="docutils literal notranslate"><span class="pre">MappingTransformerMasking.XLNetConfig</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-transformers4rec.torch.utils">Module contents</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 2023, NVIDIA.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>