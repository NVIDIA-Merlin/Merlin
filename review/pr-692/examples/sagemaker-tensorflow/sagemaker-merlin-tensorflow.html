<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training and Serving Merlin on AWS SageMaker &mdash; Merlin  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/togglebutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Merlin
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support_matrix/index.html">Merlin Support Matrix</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Merlin</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Training and Serving Merlin on AWS SageMaker</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
</pre></div>
</div>
</div>
</div>
<img alt="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-01-download-convert/nvidia_logo.png" src="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-01-download-convert/nvidia_logo.png" />
<div class="section" id="training-and-serving-merlin-on-aws-sagemaker">
<h1>Training and Serving Merlin on AWS SageMaker<a class="headerlink" href="#training-and-serving-merlin-on-aws-sagemaker" title="Permalink to this headline"></a></h1>
<p>This notebook is created using the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> container.
Note that AWS libraries in this notebook require AWS credentials, and if you are running this notebook in a container, you might need to restart the container with the AWS credentials mounted, e.g., <code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">$HOME/.aws:$HOME/.aws</span></code>.</p>
<p>With AWS Sagemaker, you can package your own models that can then be trained and deployed in the SageMaker environment. This notebook shows you how to use Merlin for training and inference in the SageMaker environment.</p>
<p>To run this notebook, you need to be able to run <a class="reference external" href="https://aws.amazon.com/cli/">AWS CLI</a> and also have <a class="reference external" href="https://sagemaker.readthedocs.io/en/stable/">Amazon SageMaker Python SDK</a> installed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> python3 -m pip -q install sagemaker
</pre></div>
</div>
</div>
</div>
<div class="section" id="part-1-preparing-your-merlin-model">
<h2>Part 1: Preparing your Merlin model<a class="headerlink" href="#part-1-preparing-your-merlin-model" title="Permalink to this headline"></a></h2>
</div>
<div class="section" id="testing-your-algorithm-on-your-local-machine">
<h2>Testing your algorithm on your local machine<a class="headerlink" href="#testing-your-algorithm-on-your-local-machine" title="Permalink to this headline"></a></h2>
<p>In this notebook, we use the synthetic train and test datasets generated by mimicking the real <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">Ali-CCP</a>: Alibaba Click and Conversion Prediction dataset to build our recommender system ranking models. The Ali-CCP is a dataset gathered from real-world traffic logs of the recommender system in Taobao, the largest online retail platform in the world.</p>
<p>If you would like to use real Ali-CCP dataset instead, you can download the training and test datasets on <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">tianchi.aliyun.com</a>. You can then use <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/main/merlin/datasets/ecommerce/aliccp/dataset.py#L43">get_aliccp()</a> function to curate the raw csv files and save them as parquet files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">merlin.datasets.synthetic</span> <span class="kn">import</span> <span class="n">generate_data</span>

<span class="n">DATA_FOLDER</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DATA_FOLDER&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>
<span class="n">NUM_ROWS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;NUM_ROWS&quot;</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">)</span>
<span class="n">SYNTHETIC_DATA</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SYNTHETIC_DATA&quot;</span><span class="p">,</span> <span class="s2">&quot;True&quot;</span><span class="p">))</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;BATCH_SIZE&quot;</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>

<span class="k">if</span> <span class="n">SYNTHETIC_DATA</span><span class="p">:</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="s2">&quot;aliccp-raw&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">NUM_ROWS</span><span class="p">),</span> <span class="n">set_sizes</span><span class="o">=</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
    <span class="c1"># save the datasets as parquet files</span>
    <span class="n">train</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">))</span>
    <span class="n">valid</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<p>Before you run your algorithm on SageMaker, you probably want to test and train your training algorithm locally first to make sure that it’s working correctly.
The training script <a class="reference download internal" download="" href="../../_downloads/08d85fba77615657906f6b1c7d98e7fd/train.py"><span class="xref download myst">train.py</span></a> in this example starts with the synthethic dataset we have created in the previous cell and produces a ranking model by performing the following tasks:</p>
<ul class="simple">
<li><p>Perform feature engineering and preprocessing with <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a>. NVTabular implements common feature engineering and preprocessing operators in easy-to-use, high-level APIs.</p></li>
<li><p>Use <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/">Merlin Models</a> to train <a class="reference external" href="https://arxiv.org/pdf/1906.00091.pdf">Facebook’s DLRM model</a> in Tensorflow.</p></li>
<li><p>Prepares <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/user_guide/architecture.md#ensemble-models">ensemble models</a> for serving on <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a>.
The training script outputs the final ensemble models to <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>. You want to make sure that your script generates any artifacts within <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>, since SageMaker packages any files in this directory into a compressed tar archive and made available at the S3 location. Ensemble models that are uploaded to S3 will be used later to handle predictions in Triton inference server later in this notebook.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>! python3 train.py \
    --train_dir={DATA_FOLDER}/train/ \
    --valid_dir={DATA_FOLDER}/valid/ \
    --model_dir=/tmp/ \
    --batch_size=512 \
    --epochs=1
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-10-20 17:49:52.902606: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn&#39;t match a supported version!
  warnings.warn(&quot;urllib3 ({}) or chardet ({}) doesn&#39;t match a supported &quot;
2022-10-20 17:49:53.887953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:53.888286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:53.888376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:53.897977: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-20 17:49:53.899071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:53.899184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:53.899263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:55.086163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:55.086301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:55.086385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-20 17:49:55.086467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2867 MB memory:  -&gt; device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5
2022-10-20 17:49:55.089622: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 2.80G (3006267392 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2022-10-20 17:49:55.089829: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 2.52G (2705640704 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2022-10-20 17:49:55.090027: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 2.27G (2435076608 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2022-10-20 17:49:55.090229: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 2.04G (2191568896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
Traceback (most recent call last):
  File &quot;train.py&quot;, line 193, in &lt;module&gt;
    train()
  File &quot;train.py&quot;, line 128, in train
    train_dataset = nvt.Dataset(train_path)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py&quot;, line 303, in __init__
    self.engine = ParquetDatasetEngine(
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/io/parquet.py&quot;, line 311, in __init__
    self._real_meta, rg_byte_size_0 = run_on_worker(
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/core/utils.py&quot;, line 486, in run_on_worker
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/io/parquet.py&quot;, line 1210, in _sample_row_group
    _df = cudf.io.read_parquet(path, row_groups=0, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py&quot;, line 101, in inner
    result = func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/cudf/io/parquet.py&quot;, line 470, in read_parquet
    return _parquet_to_frame(
  File &quot;/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py&quot;, line 101, in inner
    result = func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/cudf/io/parquet.py&quot;, line 499, in _parquet_to_frame
    return _read_parquet(
  File &quot;/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py&quot;, line 101, in inner
    result = func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/cudf/io/parquet.py&quot;, line 576, in _read_parquet
    return libparquet.read_parquet(
  File &quot;cudf/_lib/parquet.pyx&quot;, line 113, in cudf._lib.parquet.read_parquet
  File &quot;cudf/_lib/parquet.pyx&quot;, line 173, in cudf._lib.parquet.read_parquet
MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /opt/rapids/rmm/include/rmm/mr/device/cuda_memory_resource.hpp:70: cudaErrorMemoryAllocation out of memory
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-dockerfile">
<h3>The <code class="docutils literal notranslate"><span class="pre">Dockerfile</span></code><a class="headerlink" href="#the-dockerfile" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Dockerfile</span></code> describes the image that will be used on SageMaker for training and inference.
We start from the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> docker image and install the <a class="reference external" href="https://github.com/aws/sagemaker-training-toolkit">sagemaker-training-toolkit</a> library, which makes the image compatible with Sagemaker for training models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> cat container/Dockerfile
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09

RUN pip3 install sagemaker-training
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="building-and-registering-the-container">
<h3>Building and registering the container<a class="headerlink" href="#building-and-registering-the-container" title="Permalink to this headline"></a></h3>
<p>The following shell code shows how to build the container image using <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">build</span></code> and push the container image to ECR using <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">push</span></code>. This code is available as the shell script <code class="docutils literal notranslate"><span class="pre">build_and_push_image.sh</span></code>. If you are running this notebook inside the <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> docker container, you probably want to execute the script outside the container.</p>
<p>This code looks for an ECR repository in the account you’re using and the current default region (if you’re using a SageMaker notebook instance, this is the region where the notebook instance was created). If the repository doesn’t exist, the script will create it.</p>
<p>Note that running the following script requires permissions to create new repositories on Amazon ECR.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> cat ./build_and_push_image.sh
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>#!/bin/bash

set -euo pipefail

# The name of our algorithm
ALGORITHM_NAME=sagemaker-merlin-tensorflow
REGION=us-east-1

cd container

ACCOUNT=$(aws sts get-caller-identity --query Account --output text --region ${REGION})

# Get the region defined in the current configuration (default to us-west-2 if none defined)

REPOSITORY=&quot;${ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com&quot;
IMAGE_URI=&quot;${REPOSITORY}/${ALGORITHM_NAME}:latest&quot;

# Get the login command from ECR and execute it directly
aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin ${REPOSITORY}

# If the repository doesn&#39;t exist in ECR, create it.

aws ecr describe-repositories --repository-names &quot;${ALGORITHM_NAME}&quot; --region ${REGION} &gt; /dev/null 2&gt;&amp;1

if [ $? -ne 0 ]
then
    aws ecr create-repository --repository-name &quot;${ALGORITHM_NAME}&quot; --region ${REGION} &gt; /dev/null
fi

# Build the docker image locally with the image name and then push it to ECR
# with the full name.

docker build  -t ${ALGORITHM_NAME} .
docker tag ${ALGORITHM_NAME} ${IMAGE_URI}

docker push ${IMAGE_URI}
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="part-2-training-your-merlin-model-on-sagemaker">
<h2>Part 2: Training your Merlin model on Sagemaker<a class="headerlink" href="#part-2-training-your-merlin-model-on-sagemaker" title="Permalink to this headline"></a></h2>
<p>Once you have tested your script that creates a Merlin ensemble graph, you can use it to train it on Sagemaker.</p>
<p>Here, we create a Sagemaker session that we will use to perform our Sagemaker operations, specify the bucket to use, and the role for working with Sagemaker.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sagemaker</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>

<span class="c1"># S3 prefix</span>
<span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;DEMO-merlin-tensorflow-aliccp&quot;</span>

<span class="n">role</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">get_execution_role</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">role</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">line</span> <span class="mi">8</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># S3 prefix</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;DEMO-merlin-tensorflow-aliccp&quot;</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="n">data_location</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">upload_data</span><span class="p">(</span><span class="n">DATA_DIRECTORY</span><span class="p">,</span> <span class="n">key_prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="nb">print</span><span class="p">(</span><span class="n">data_location</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="n">role</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">get_execution_role</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;DATA_DIRECTORY&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p>We can use the Sagemaker Python SDK to upload the Ali-CCP synthetic data to our S3 bucket.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_location</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">upload_data</span><span class="p">(</span><span class="n">DATA_DIRECTORY</span><span class="p">,</span> <span class="n">key_prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data_location</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="training-on-sagemaker-using-the-python-sdk">
<h3>Training on Sagemaker using the Python SDK<a class="headerlink" href="#training-on-sagemaker-using-the-python-sdk" title="Permalink to this headline"></a></h3>
<p>Sagemaker provides the Python SDK for training a model on Sagemaker.</p>
<p>Here, we start by using the ECR image URL of the image we pushed in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;sts&quot;</span><span class="p">)</span>
<span class="n">account</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_caller_identity</span><span class="p">()[</span><span class="s2">&quot;Account&quot;</span><span class="p">]</span>

<span class="n">my_session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">region</span> <span class="o">=</span> <span class="n">my_session</span><span class="o">.</span><span class="n">region_name</span>

<span class="n">algorithm_name</span> <span class="o">=</span> <span class="s2">&quot;sagemaker-merlin-tensorflow&quot;</span>

<span class="n">ecr_image</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.dkr.ecr.</span><span class="si">{}</span><span class="s2">.amazonaws.com/</span><span class="si">{}</span><span class="s2">:latest&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">account</span><span class="p">,</span> <span class="n">region</span><span class="p">,</span> <span class="n">algorithm_name</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ecr_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>843263297212.dkr.ecr.us-east-1.amazonaws.com/sagemaker-merlin-tensorflow:latest
</pre></div>
</div>
</div>
</div>
<p>We can call <code class="docutils literal notranslate"><span class="pre">Estimator.fit()</span></code> to start training on Sagemaker. Here, we use a <code class="docutils literal notranslate"><span class="pre">g4dn</span></code> GPU instance that are equipped with NVIDIA T4 GPUs.
Our training script <code class="docutils literal notranslate"><span class="pre">train.py</span></code> is passed to the Estimator through the <code class="docutils literal notranslate"><span class="pre">entry_point</span></code> parameter, and we can adjust our hyperparameters in the <code class="docutils literal notranslate"><span class="pre">hyperparameters</span></code>.
We have uploaded our training dataset to our S3 bucket in the previous code cell, and the S3 URLs to our training and validation sets are passed into the <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sagemaker.estimator</span> <span class="kn">import</span> <span class="n">Estimator</span>


<span class="n">training_instance_type</span> <span class="o">=</span> <span class="s2">&quot;ml.g4dn.xlarge&quot;</span>  <span class="c1"># GPU instance, T4</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">Estimator</span><span class="p">(</span>
    <span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span>
    <span class="n">instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">instance_type</span><span class="o">=</span><span class="n">training_instance_type</span><span class="p">,</span>
    <span class="n">image_uri</span><span class="o">=</span><span class="n">ecr_image</span><span class="p">,</span>
    <span class="n">entry_point</span><span class="o">=</span><span class="s2">&quot;train.py&quot;</span><span class="p">,</span>
    <span class="n">hyperparameters</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">1_024</span><span class="p">,</span>
        <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> 
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_location</span><span class="si">}</span><span class="s2">/train/&quot;</span><span class="p">,</span>
        <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_location</span><span class="si">}</span><span class="s2">/valid/&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-10-18 23:05:16 Starting - Starting the training job...
2022-10-18 23:05:41 Starting - Preparing the instances for trainingProfilerReport-1666134315: InProgress
......
2022-10-18 23:06:52 Downloading - Downloading input data...
2022-10-18 23:07:22 Training - Downloading the training image......................................<span class=" -Color -Color-Blue">==================================</span>
<span class=" -Color -Color-Blue">== Triton Inference Server Base ==</span>
<span class=" -Color -Color-Blue">==================================</span>
<span class=" -Color -Color-Blue">NVIDIA Release 22.08 (build 42766143)</span>
<span class=" -Color -Color-Blue">Copyright (c) 2018-2022, NVIDIA CORPORATION &amp; AFFILIATES.  All rights reserved.</span>
<span class=" -Color -Color-Blue">Various files include modifications (c) NVIDIA CORPORATION &amp; AFFILIATES.  All rights reserved.</span>
<span class=" -Color -Color-Blue">This container image and its contents are governed by the NVIDIA Deep Learning Container License.</span>
<span class=" -Color -Color-Blue">By pulling and using the container, you accept the terms and conditions of this license:</span>
<span class=" -Color -Color-Blue">https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license</span>
<span class=" -Color -Color-Blue">NOTE: CUDA Forward Compatibility mode ENABLED.</span>
<span class=" -Color -Color-Blue">  Using CUDA 11.7 driver version 515.65.01 with kernel driver version 510.47.03.</span>
<span class=" -Color -Color-Blue">  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.</span>
<span class=" -Color -Color-Blue">2022-10-18 23:13:53,855 sagemaker-training-toolkit INFO     Invoking user script</span>
<span class=" -Color -Color-Blue">Training Env:</span>
<span class=" -Color -Color-Blue">{</span>
<span class=" -Color -Color-Blue">    &quot;additional_framework_parameters&quot;: {},</span>
<span class=" -Color -Color-Blue">    &quot;channel_input_dirs&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;train&quot;: &quot;/opt/ml/input/data/train&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;valid&quot;: &quot;/opt/ml/input/data/valid&quot;</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;current_host&quot;: &quot;algo-1&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;current_instance_group&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;current_instance_group_hosts&quot;: [</span>
<span class=" -Color -Color-Blue">        &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">    ],</span>
<span class=" -Color -Color-Blue">    &quot;current_instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;distribution_hosts&quot;: [],</span>
<span class=" -Color -Color-Blue">    &quot;distribution_instance_groups&quot;: [],</span>
<span class=" -Color -Color-Blue">    &quot;framework_module&quot;: null,</span>
<span class=" -Color -Color-Blue">    &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">        &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">    ],</span>
<span class=" -Color -Color-Blue">    &quot;hyperparameters&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;batch_size&quot;: 1024,</span>
<span class=" -Color -Color-Blue">        &quot;epoch&quot;: 10</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;input_config_dir&quot;: &quot;/opt/ml/input/config&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;input_data_config&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;train&quot;: {</span>
<span class=" -Color -Color-Blue">            &quot;TrainingInputMode&quot;: &quot;File&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;S3DistributionType&quot;: &quot;FullyReplicated&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;RecordWrapperType&quot;: &quot;None&quot;</span>
<span class=" -Color -Color-Blue">        },</span>
<span class=" -Color -Color-Blue">        &quot;valid&quot;: {</span>
<span class=" -Color -Color-Blue">            &quot;TrainingInputMode&quot;: &quot;File&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;S3DistributionType&quot;: &quot;FullyReplicated&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;RecordWrapperType&quot;: &quot;None&quot;</span>
<span class=" -Color -Color-Blue">        }</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;input_dir&quot;: &quot;/opt/ml/input&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;instance_groups&quot;: [</span>
<span class=" -Color -Color-Blue">        &quot;homogeneousCluster&quot;</span>
<span class=" -Color -Color-Blue">    ],</span>
<span class=" -Color -Color-Blue">    &quot;instance_groups_dict&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;homogeneousCluster&quot;: {</span>
<span class=" -Color -Color-Blue">            &quot;instance_group_name&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">                &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">            ]</span>
<span class=" -Color -Color-Blue">        }</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;is_hetero&quot;: false,</span>
<span class=" -Color -Color-Blue">    &quot;is_master&quot;: true,</span>
<span class=" -Color -Color-Blue">    &quot;is_modelparallel_enabled&quot;: null,</span>
<span class=" -Color -Color-Blue">    &quot;job_name&quot;: &quot;sagemaker-merlin-tensorflow-2022-10-18-23-05-14-440&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;log_level&quot;: 20,</span>
<span class=" -Color -Color-Blue">    &quot;master_hostname&quot;: &quot;algo-1&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;model_dir&quot;: &quot;/opt/ml/model&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;module_dir&quot;: &quot;s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-18-23-05-14-440/source/sourcedir.tar.gz&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;module_name&quot;: &quot;train&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;network_interface_name&quot;: &quot;eth0&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;num_cpus&quot;: 4,</span>
<span class=" -Color -Color-Blue">    &quot;num_gpus&quot;: 1,</span>
<span class=" -Color -Color-Blue">    &quot;output_data_dir&quot;: &quot;/opt/ml/output/data&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;output_dir&quot;: &quot;/opt/ml/output&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;output_intermediate_dir&quot;: &quot;/opt/ml/output/intermediate&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;resource_config&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;current_host&quot;: &quot;algo-1&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;current_instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;current_group_name&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">            &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">        ],</span>
<span class=" -Color -Color-Blue">        &quot;instance_groups&quot;: [</span>
<span class=" -Color -Color-Blue">            {</span>
<span class=" -Color -Color-Blue">                &quot;instance_group_name&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">                &quot;instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">                &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">                    &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">                ]</span>
<span class=" -Color -Color-Blue">            }</span>
<span class=" -Color -Color-Blue">        ],</span>
<span class=" -Color -Color-Blue">        &quot;network_interface_name&quot;: &quot;eth0&quot;</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;user_entry_point&quot;: &quot;train.py&quot;</span>
<span class=" -Color -Color-Blue">}</span>
<span class=" -Color -Color-Blue">Environment variables:</span>
<span class=" -Color -Color-Blue">SM_HOSTS=[&quot;algo-1&quot;]</span>
<span class=" -Color -Color-Blue">SM_NETWORK_INTERFACE_NAME=eth0</span>
<span class=" -Color -Color-Blue">SM_HPS={&quot;batch_size&quot;:1024,&quot;epoch&quot;:10}</span>
<span class=" -Color -Color-Blue">SM_USER_ENTRY_POINT=train.py</span>
<span class=" -Color -Color-Blue">SM_FRAMEWORK_PARAMS={}</span>
<span class=" -Color -Color-Blue">SM_RESOURCE_CONFIG={&quot;current_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;current_host&quot;:&quot;algo-1&quot;,&quot;current_instance_type&quot;:&quot;ml.g4dn.xlarge&quot;,&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_groups&quot;:[{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}],&quot;network_interface_name&quot;:&quot;eth0&quot;}</span>
<span class=" -Color -Color-Blue">SM_INPUT_DATA_CONFIG={&quot;train&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;},&quot;valid&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;}}</span>
<span class=" -Color -Color-Blue">SM_OUTPUT_DATA_DIR=/opt/ml/output/data</span>
<span class=" -Color -Color-Blue">SM_CHANNELS=[&quot;train&quot;,&quot;valid&quot;]</span>
<span class=" -Color -Color-Blue">SM_CURRENT_HOST=algo-1</span>
<span class=" -Color -Color-Blue">SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge</span>
<span class=" -Color -Color-Blue">SM_CURRENT_INSTANCE_GROUP=homogeneousCluster</span>
<span class=" -Color -Color-Blue">SM_CURRENT_INSTANCE_GROUP_HOSTS=[&quot;algo-1&quot;]</span>
<span class=" -Color -Color-Blue">SM_INSTANCE_GROUPS=[&quot;homogeneousCluster&quot;]</span>
<span class=" -Color -Color-Blue">SM_INSTANCE_GROUPS_DICT={&quot;homogeneousCluster&quot;:{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}}</span>
<span class=" -Color -Color-Blue">SM_DISTRIBUTION_INSTANCE_GROUPS=[]</span>
<span class=" -Color -Color-Blue">SM_IS_HETERO=false</span>
<span class=" -Color -Color-Blue">SM_MODULE_NAME=train</span>
<span class=" -Color -Color-Blue">SM_LOG_LEVEL=20</span>
<span class=" -Color -Color-Blue">SM_FRAMEWORK_MODULE=</span>
<span class=" -Color -Color-Blue">SM_INPUT_DIR=/opt/ml/input</span>
<span class=" -Color -Color-Blue">SM_INPUT_CONFIG_DIR=/opt/ml/input/config</span>
<span class=" -Color -Color-Blue">SM_OUTPUT_DIR=/opt/ml/output</span>
<span class=" -Color -Color-Blue">SM_NUM_CPUS=4</span>
<span class=" -Color -Color-Blue">SM_NUM_GPUS=1</span>
<span class=" -Color -Color-Blue">SM_MODEL_DIR=/opt/ml/model</span>
<span class=" -Color -Color-Blue">SM_MODULE_DIR=s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-18-23-05-14-440/source/sourcedir.tar.gz</span>
<span class=" -Color -Color-Blue">SM_TRAINING_ENV={&quot;additional_framework_parameters&quot;:{},&quot;channel_input_dirs&quot;:{&quot;train&quot;:&quot;/opt/ml/input/data/train&quot;,&quot;valid&quot;:&quot;/opt/ml/input/data/valid&quot;},&quot;current_host&quot;:&quot;algo-1&quot;,&quot;current_instance_group&quot;:&quot;homogeneousCluster&quot;,&quot;current_instance_group_hosts&quot;:[&quot;algo-1&quot;],&quot;current_instance_type&quot;:&quot;ml.g4dn.xlarge&quot;,&quot;distribution_hosts&quot;:[],&quot;distribution_instance_groups&quot;:[],&quot;framework_module&quot;:null,&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;hyperparameters&quot;:{&quot;batch_size&quot;:1024,&quot;epoch&quot;:10},&quot;input_config_dir&quot;:&quot;/opt/ml/input/config&quot;,&quot;input_data_config&quot;:{&quot;train&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;},&quot;valid&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;}},&quot;input_dir&quot;:&quot;/opt/ml/input&quot;,&quot;instance_groups&quot;:[&quot;homogeneousCluster&quot;],&quot;instance_groups_dict&quot;:{&quot;homogeneousCluster&quot;:{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}},&quot;is_hetero&quot;:false,&quot;is_master&quot;:true,&quot;is_modelparallel_enabled&quot;:null,&quot;job_name&quot;:&quot;sagemaker-merlin-tensorflow-2022-10-18-23-05-14-440&quot;,&quot;log_level&quot;:20,&quot;master_hostname&quot;:&quot;algo-1&quot;,&quot;model_dir&quot;:&quot;/opt/ml/model&quot;,&quot;module_dir&quot;:&quot;s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-18-23-05-14-440/source/sourcedir.tar.gz&quot;,&quot;module_name&quot;:&quot;train&quot;,&quot;network_interface_name&quot;:&quot;eth0&quot;,&quot;num_cpus&quot;:4,&quot;num_gpus&quot;:1,&quot;output_data_dir&quot;:&quot;/opt/ml/output/data&quot;,&quot;output_dir&quot;:&quot;/opt/ml/output&quot;,&quot;output_intermediate_dir&quot;:&quot;/opt/ml/output/intermediate&quot;,&quot;resource_config&quot;:{&quot;current_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;current_host&quot;:&quot;algo-1&quot;,&quot;current_instance_type&quot;:&quot;ml.g4dn.xlarge&quot;,&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_groups&quot;:[{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}],&quot;network_interface_name&quot;:&quot;eth0&quot;},&quot;user_entry_point&quot;:&quot;train.py&quot;}</span>
<span class=" -Color -Color-Blue">SM_USER_ARGS=[&quot;--batch_size&quot;,&quot;1024&quot;,&quot;--epoch&quot;,&quot;10&quot;]</span>
<span class=" -Color -Color-Blue">SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate</span>
<span class=" -Color -Color-Blue">SM_CHANNEL_TRAIN=/opt/ml/input/data/train</span>
<span class=" -Color -Color-Blue">SM_CHANNEL_VALID=/opt/ml/input/data/valid</span>
<span class=" -Color -Color-Blue">SM_HP_BATCH_SIZE=1024</span>
<span class=" -Color -Color-Blue">SM_HP_EPOCH=10</span>
<span class=" -Color -Color-Blue">PYTHONPATH=/opt/ml/code:/usr/local/bin:/opt/tritonserver:/usr/local/lib/python3.8/dist-packages:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages/faiss-1.7.2-py3.8.egg:/usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg:/usr/local/lib/python3.8/dist-packages/merlin_hps-1.0.0-py3.8-linux-x86_64.egg:/usr/lib/python3/dist-packages</span>
<span class=" -Color -Color-Blue">Invoking script with the following command:</span>
<span class=" -Color -Color-Blue">/usr/bin/python3 train.py --batch_size 1024 --epoch 10</span>
<span class=" -Color -Color-Blue">2022-10-18 23:13:53,856 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.</span>
<span class=" -Color -Color-Blue">2022-10-18 23:13:59.437699: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.</span>

2022-10-18 23:14:03 Training - Training image download completed. Training in progress.<span class=" -Color -Color-Blue">2022-10-18 23:14:04.196211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:04.197986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:04.198261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:04.236763: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX</span>
<span class=" -Color -Color-Blue">To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:04.238319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:04.238639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:04.238863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:08.392792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:08.393079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:08.393286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-18 23:14:08.394189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10752 MB memory:  -&gt; device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5</span>
<span class=" -Color -Color-Blue">Workflow saved to /tmp/tmp1nv79anb/workflow.</span>
<span class=" -Color -Color-Blue">batch_size = 1024, epochs = 10</span>
<span class=" -Color -Color-Blue">Epoch 1/10</span>
<span class=" -Color -Color-Blue">684/684 - 16s - loss: 0.6932 - auc: 0.4996 - regularization_loss: 0.0000e+00 - val_loss: 0.6932 - val_auc: 0.4990 - val_regularization_loss: 0.0000e+00 - 16s/epoch - 24ms/step</span>
<span class=" -Color -Color-Blue">Epoch 2/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6931 - auc: 0.5024 - regularization_loss: 0.0000e+00 - val_loss: 0.6932 - val_auc: 0.4996 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 13ms/step</span>
<span class=" -Color -Color-Blue">Epoch 3/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6924 - auc: 0.5198 - regularization_loss: 0.0000e+00 - val_loss: 0.6937 - val_auc: 0.4989 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 13ms/step</span>
<span class=" -Color -Color-Blue">Epoch 4/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6868 - auc: 0.5470 - regularization_loss: 0.0000e+00 - val_loss: 0.6976 - val_auc: 0.4983 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 14ms/step</span>
<span class=" -Color -Color-Blue">Epoch 5/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6797 - auc: 0.5643 - regularization_loss: 0.0000e+00 - val_loss: 0.7043 - val_auc: 0.4980 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 14ms/step</span>
<span class=" -Color -Color-Blue">Epoch 6/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6754 - auc: 0.5715 - regularization_loss: 0.0000e+00 - val_loss: 0.7102 - val_auc: 0.4980 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 13ms/step</span>
<span class=" -Color -Color-Blue">Epoch 7/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6723 - auc: 0.5751 - regularization_loss: 0.0000e+00 - val_loss: 0.7219 - val_auc: 0.4981 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 14ms/step</span>
<span class=" -Color -Color-Blue">Epoch 8/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6701 - auc: 0.5770 - regularization_loss: 0.0000e+00 - val_loss: 0.7366 - val_auc: 0.4984 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 13ms/step</span>
<span class=" -Color -Color-Blue">Epoch 9/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6688 - auc: 0.5787 - regularization_loss: 0.0000e+00 - val_loss: 0.7509 - val_auc: 0.4983 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 13ms/step</span>
<span class=" -Color -Color-Blue">Epoch 10/10</span>
<span class=" -Color -Color-Blue">684/684 - 9s - loss: 0.6680 - auc: 0.5797 - regularization_loss: 0.0000e+00 - val_loss: 0.7519 - val_auc: 0.4984 - val_regularization_loss: 0.0000e+00 - 9s/epoch - 14ms/step</span>
<span class=" -Color -Color-Blue">/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn&#39;t match a supported version!</span>
<span class=" -Color -Color-Blue">  warnings.warn(&quot;urllib3 ({}) or chardet ({}) doesn&#39;t match a supported &quot;</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.</span>
<span class=" -Color -Color-Blue">INFO:__main__:Model saved to /tmp/tmp1nv79anb/dlrm.</span>
<span class=" -Color -Color-Blue">Model saved to /tmp/tmp1nv79anb/dlrm.</span>
<span class=" -Color -Color-Blue">WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.</span>
<span class=" -Color -Color-Blue">WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.</span>
<span class=" -Color -Color-Blue">WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.</span>
<span class=" -Color -Color-Blue">INFO:__main__:Ensemble graph saved to /opt/ml/model.</span>
<span class=" -Color -Color-Blue">Ensemble graph saved to /opt/ml/model.</span>
<span class=" -Color -Color-Blue">2022-10-18 23:16:37,392 sagemaker-training-toolkit INFO     Reporting training SUCCESS</span>

2022-10-18 23:16:57 Uploading - Uploading generated training model
2022-10-18 23:16:57 Completed - Training job completed
Training seconds: 604
Billable seconds: 604
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">model_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-18-23-05-14-440/output/model.tar.gz
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> aws s3 cp <span class="o">{</span>estimator.model_data<span class="o">}</span> /tmp/ensemble/
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>download: s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-18-23-05-14-440/output/model.tar.gz to ../../../../tmp/ensemble/model.tar.gz
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> tar xvzf /tmp/ensemble/model.tar.gz
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1_predicttensorflow/
1_predicttensorflow/1/
1_predicttensorflow/1/model.savedmodel/
1_predicttensorflow/1/model.savedmodel/saved_model.pb
1_predicttensorflow/1/model.savedmodel/variables/
1_predicttensorflow/1/model.savedmodel/variables/variables.index
1_predicttensorflow/1/model.savedmodel/variables/variables.data-00000-of-00001
1_predicttensorflow/1/model.savedmodel/keras_metadata.pb
1_predicttensorflow/1/model.savedmodel/assets/
1_predicttensorflow/config.pbtxt
ensemble_model/
ensemble_model/1/
ensemble_model/config.pbtxt
0_transformworkflow/
0_transformworkflow/1/
0_transformworkflow/1/model.py
0_transformworkflow/1/workflow/
0_transformworkflow/1/workflow/metadata.json
0_transformworkflow/1/workflow/workflow.pkl
0_transformworkflow/1/workflow/categories/
0_transformworkflow/1/workflow/categories/unique.user_consumption_2.parquet
0_transformworkflow/1/workflow/categories/unique.item_category.parquet
0_transformworkflow/1/workflow/categories/unique.user_profile.parquet
0_transformworkflow/1/workflow/categories/unique.user_id.parquet
0_transformworkflow/1/workflow/categories/unique.item_shop.parquet
0_transformworkflow/1/workflow/categories/unique.user_categories.parquet
0_transformworkflow/1/workflow/categories/unique.user_shops.parquet
0_transformworkflow/1/workflow/categories/unique.user_gender.parquet
0_transformworkflow/1/workflow/categories/unique.user_geography.parquet
0_transformworkflow/1/workflow/categories/unique.item_id.parquet
0_transformworkflow/1/workflow/categories/unique.user_brands.parquet
0_transformworkflow/1/workflow/categories/unique.user_age.parquet
0_transformworkflow/1/workflow/categories/unique.user_group.parquet
0_transformworkflow/1/workflow/categories/unique.user_intentions.parquet
0_transformworkflow/1/workflow/categories/unique.item_brand.parquet
0_transformworkflow/1/workflow/categories/unique.user_is_occupied.parquet
0_transformworkflow/config.pbtxt
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="part-3-retrieving-recommendations-from-triton-inference-server">
<h2>Part 3: Retrieving Recommendations from Triton Inference Server<a class="headerlink" href="#part-3-retrieving-recommendations-from-triton-inference-server" title="Permalink to this headline"></a></h2>
<p>Although we use the Sagemaker Python SDK to train our model, here we will use <code class="docutils literal notranslate"><span class="pre">boto3</span></code> to launch our inference endpoint as it offers more low-level control than the Python SDK.</p>
<p>The model artificat <code class="docutils literal notranslate"><span class="pre">model.tar.gz</span></code> uploaded to S3 from the Sagemaker training job contained three directories: <code class="docutils literal notranslate"><span class="pre">0_transformworkflow</span></code> for the NVTabular workflow, <code class="docutils literal notranslate"><span class="pre">1_predicttensorflow</span></code> for the Tensorflow model, and <code class="docutils literal notranslate"><span class="pre">ensemble_model</span></code> for the ensemble graph that we can use in Triton.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>/tmp/ensemble/
├── 0_transformworkflow
│   ├── <span class="m">1</span>
│   │   ├── model.py
│   │   └── workflow
│   │       ├── categories
│   │       │   ├── unique.item_brand.parquet
│   │       │   ├── unique.item_category.parquet
│   │       │   ├── unique.item_id.parquet
│   │       │   ├── unique.item_shop.parquet
│   │       │   ├── unique.user_age.parquet
│   │       │   ├── unique.user_brands.parquet
│   │       │   ├── unique.user_categories.parquet
│   │       │   ├── unique.user_consumption_2.parquet
│   │       │   ├── unique.user_gender.parquet
│   │       │   ├── unique.user_geography.parquet
│   │       │   ├── unique.user_group.parquet
│   │       │   ├── unique.user_id.parquet
│   │       │   ├── unique.user_intentions.parquet
│   │       │   ├── unique.user_is_occupied.parquet
│   │       │   ├── unique.user_profile.parquet
│   │       │   └── unique.user_shops.parquet
│   │       ├── metadata.json
│   │       └── workflow.pkl
│   └── config.pbtxt
├── 1_predicttensorflow
│   ├── <span class="m">1</span>
│   │   └── model.savedmodel
│   │       ├── assets
│   │       ├── keras_metadata.pb
│   │       ├── saved_model.pb
│   │       └── variables
│   │           ├── variables.data-00000-of-00001
│   │           └── variables.index
│   └── config.pbtxt
├── ensemble_model
│   ├── <span class="m">1</span>
│   └── config.pbtxt
└── model.tar.gz
</pre></div>
</div>
<p>We specify that we only want to use <code class="docutils literal notranslate"><span class="pre">ensemble_model</span></code> in Triton by passing the environment variable <code class="docutils literal notranslate"><span class="pre">SAGEMAKER_TRITON_DEFAULT_MODEL_NAME</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">sm_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="n">service_name</span><span class="o">=</span><span class="s2">&quot;sagemaker&quot;</span><span class="p">)</span>

<span class="n">container</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Image&quot;</span><span class="p">:</span> <span class="n">ecr_image</span><span class="p">,</span>
    <span class="s2">&quot;ModelDataUrl&quot;</span><span class="p">:</span> <span class="n">estimator</span><span class="o">.</span><span class="n">model_data</span><span class="p">,</span>
    <span class="s2">&quot;Environment&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;SAGEMAKER_TRITON_TENSORFLOW_VERSION&quot;</span><span class="p">:</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span>
        <span class="s2">&quot;SAGEMAKER_TRITON_DEFAULT_MODEL_NAME&quot;</span><span class="p">:</span> <span class="s2">&quot;ensemble_model&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;model-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>

<span class="n">create_model_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span>
    <span class="n">ModelName</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">ExecutionRoleArn</span><span class="o">=</span><span class="n">role</span><span class="p">,</span> <span class="n">PrimaryContainer</span><span class="o">=</span><span class="n">container</span>
<span class="p">)</span>

<span class="n">model_arn</span> <span class="o">=</span> <span class="n">create_model_response</span><span class="p">[</span><span class="s2">&quot;ModelArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model Arn: </span><span class="si">{</span><span class="n">model_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model Arn: arn:aws:sagemaker:us-east-1:843263297212:model/model-triton-merlin-ensemble-2022-10-18-23-17-19
</pre></div>
</div>
</div>
</div>
<p>We again use the <code class="docutils literal notranslate"><span class="pre">g4dn</span></code> GPU instance that are equipped with NVIDIA T4 GPUs for launching the Triton inference server.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint_instance_type</span> <span class="o">=</span> <span class="s2">&quot;ml.g4dn.xlarge&quot;</span>

<span class="n">endpoint_config_name</span> <span class="o">=</span> <span class="s2">&quot;endpoint-config-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>

<span class="n">create_endpoint_config_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_endpoint_config</span><span class="p">(</span>
    <span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span><span class="p">,</span>
    <span class="n">ProductionVariants</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;InstanceType&quot;</span><span class="p">:</span> <span class="n">endpoint_instance_type</span><span class="p">,</span>
            <span class="s2">&quot;InitialVariantWeight&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;InitialInstanceCount&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;ModelName&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
            <span class="s2">&quot;VariantName&quot;</span><span class="p">:</span> <span class="s2">&quot;AllTraffic&quot;</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="n">endpoint_config_arn</span> <span class="o">=</span> <span class="n">create_endpoint_config_response</span><span class="p">[</span><span class="s2">&quot;EndpointConfigArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Config Arn: </span><span class="si">{</span><span class="n">endpoint_config_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Endpoint Config Arn: arn:aws:sagemaker:us-east-1:843263297212:endpoint-config/endpoint-config-triton-merlin-ensemble-2022-10-18-23-17-20
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint_name</span> <span class="o">=</span> <span class="s2">&quot;endpoint-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>

<span class="n">create_endpoint_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_endpoint</span><span class="p">(</span>
    <span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span> <span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span>
<span class="p">)</span>

<span class="n">endpoint_arn</span> <span class="o">=</span> <span class="n">create_endpoint_response</span><span class="p">[</span><span class="s2">&quot;EndpointArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Arn: </span><span class="si">{</span><span class="n">endpoint_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Endpoint Arn: arn:aws:sagemaker:us-east-1:843263297212:endpoint/endpoint-triton-merlin-ensemble-2022-10-18-23-17-21
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">status</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">describe_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)[</span><span class="s2">&quot;EndpointStatus&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Creation Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">while</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;Creating&quot;</span><span class="p">:</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">describe_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">rv</span><span class="p">[</span><span class="s2">&quot;EndpointStatus&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Creation Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">endpoint_arn</span> <span class="o">=</span> <span class="n">rv</span><span class="p">[</span><span class="s2">&quot;EndpointArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Arn: </span><span class="si">{</span><span class="n">endpoint_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: InService
Endpoint Arn: arn:aws:sagemaker:us-east-1:843263297212:endpoint/endpoint-triton-merlin-ensemble-2022-10-18-23-17-21
Endpoint Status: InService
</pre></div>
</div>
</div>
</div>
<div class="section" id="send-a-request-to-triton-inference-server-to-transform-a-raw-dataset">
<h3>Send a Request to Triton Inference Server to Transform a Raw Dataset<a class="headerlink" href="#send-a-request-to-triton-inference-server-to-transform-a-raw-dataset" title="Permalink to this headline"></a></h3>
<p>Once we have an endpoint running, we can test it by sending requests.
Here, we use the raw validation set and transform it using the saved VTabular workflow we have downloaded from S3 in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.schema.tags</span> <span class="kn">import</span> <span class="n">Tags</span>
<span class="kn">from</span> <span class="nn">merlin.core.dispatch</span> <span class="kn">import</span> <span class="n">get_lib</span>
<span class="kn">from</span> <span class="nn">nvtabular.workflow</span> <span class="kn">import</span> <span class="n">Workflow</span>

<span class="n">df_lib</span> <span class="o">=</span> <span class="n">get_lib</span><span class="p">()</span>

<span class="n">original_data_path</span> <span class="o">=</span> <span class="n">DATA_DIRECTORY</span>
<span class="n">workflow</span> <span class="o">=</span> <span class="n">Workflow</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/tmp/ensemble/0_transformworkflow/1/workflow/&quot;</span><span class="p">)</span>

<span class="n">label_columns</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">TARGET</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">remove_inputs</span><span class="p">(</span><span class="n">label_columns</span><span class="p">)</span>

<span class="c1"># read in data for request</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">df_lib</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">original_data_path</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;part.0.parquet&quot;</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">column_names</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3553,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:424,</span> in <span class="ni">cuda._cuda.ccuda.cuPythonInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Failed to dlopen libcuda.so
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3553, in cuda._cuda.ccuda._cuInit
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 424, in cuda._cuda.ccuda.cuPythonInit
RuntimeError: Failed to dlopen libcuda.so
/usr/local/lib/python3.8/dist-packages/cudf/utils/gpu_utils.py:62: UserWarning: Function &quot;cuDeviceGetCount&quot; not found
  warnings.warn(str(e))
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">File /usr/local/lib/python3.8/dist-packages/cuda/_cuda/ccuda.pyx:3556,</span> in <span class="ni">cuda._cuda.ccuda._cuInit</span><span class="nt">()</span>

<span class="ne">RuntimeError</span>: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception ignored in: &#39;cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit&#39;
Traceback (most recent call last):
  File &quot;cuda/_cuda/ccuda.pyx&quot;, line 3556, in cuda._cuda.ccuda._cuInit
RuntimeError: Function &quot;cuInit&quot; not found
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                     user_id  item_id  item_category  item_shop  item_brand  \
__null_dask_index__                                                           
700000                    23       23             66       4590        1581   
700001                    11       10             27       1878         647   
700002                    30       25             72       5007        1725   

                     user_shops  user_profile  user_group  user_gender  \
__null_dask_index__                                                      
700000                     1024             1           1            1   
700001                      466             1           1            1   
700002                     1349             2           1            1   

                     user_age  user_consumption_2  user_is_occupied  \
__null_dask_index__                                                   
700000                      1                   1                 1   
700001                      1                   1                 1   
700002                      1                   1                 1   

                     user_geography  user_intentions  user_brands  \
__null_dask_index__                                                 
700000                            1              297          509   
700001                            1              135          232   
700002                            1              391          671   

                     user_categories  
__null_dask_index__                   
700000                            54  
700001                            25  
700002                            71  
</pre></div>
</div>
</div>
</div>
<p>In the following code cell, we use a utility function provided in <a class="reference external" href="https://github.com/NVIDIA-Merlin/systems">Merlin Systems</a> to convert our dataframe to the payload format that can be used as inference request format for Triton.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.triton</span> <span class="kn">import</span> <span class="n">convert_df_to_triton_input</span>
<span class="kn">import</span> <span class="nn">tritonclient.http</span> <span class="k">as</span> <span class="nn">httpclient</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">convert_df_to_triton_input</span><span class="p">(</span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferInput</span><span class="p">)</span>

<span class="n">request_body</span><span class="p">,</span> <span class="n">header_length</span> <span class="o">=</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="o">.</span><span class="n">generate_request_body</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">request_body</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b&#39;{&quot;inputs&quot;:[{&quot;name&quot;:&quot;user_id&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;item_id&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;item_category&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;item_shop&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;item_brand&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_shops&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_profile&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_group&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_gender&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_age&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_consumption_2&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_is_occupied&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_geography&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_intentions&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_brands&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}},{&quot;name&quot;:&quot;user_categories&quot;,&quot;shape&quot;:[3,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:12}}],&quot;parameters&quot;:{&quot;binary_data_output&quot;:true}}\x17\x00\x00\x00\x0b\x00\x00\x00\x1e\x00\x00\x00\x17\x00\x00\x00\n\x00\x00\x00\x19\x00\x00\x00B\x00\x00\x00\x1b\x00\x00\x00H\x00\x00\x00\xee\x11\x00\x00V\x07\x00\x00\x8f\x13\x00\x00-\x06\x00\x00\x87\x02\x00\x00\xbd\x06\x00\x00\x00\x04\x00\x00\xd2\x01\x00\x00E\x05\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00)\x01\x00\x00\x87\x00\x00\x00\x87\x01\x00\x00\xfd\x01\x00\x00\xe8\x00\x00\x00\x9f\x02\x00\x006\x00\x00\x00\x19\x00\x00\x00G\x00\x00\x00&#39;
</pre></div>
</div>
</div>
</div>
<p>Triton uses the <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/protocol/README.md">KServe community standard inference protocols</a>.
Here, we use the <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/protocol/extension_binary_data.md">binary+json format</a> for optimal performance in the inference request.</p>
<p>In order for Triton to correctly parse the binary payload, we have to specify the length of the request metadata in the header <code class="docutils literal notranslate"><span class="pre">json-header-size</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">runtime_sm_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;sagemaker-runtime&quot;</span><span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">runtime_sm_client</span><span class="o">.</span><span class="n">invoke_endpoint</span><span class="p">(</span>
    <span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span>
    <span class="n">ContentType</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;application/vnd.sagemaker-triton.binary+json;json-header-size=</span><span class="si">{</span><span class="n">header_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">Body</span><span class="o">=</span><span class="n">request_body</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Parse json header size length from the response</span>
<span class="n">header_length_prefix</span> <span class="o">=</span> <span class="s2">&quot;application/vnd.sagemaker-triton.binary+json;json-header-size=&quot;</span>
<span class="n">header_length_str</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;ContentType&quot;</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">header_length_prefix</span><span class="p">)</span> <span class="p">:]</span>

<span class="c1"># Read response body</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="o">.</span><span class="n">parse_response_body</span><span class="p">(</span>
    <span class="n">response</span><span class="p">[</span><span class="s2">&quot;Body&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">header_length</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">header_length_str</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="s2">&quot;click/binary_classification_task&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;predicted sigmoid result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">output_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0.5257045]
 [0.5127169]
 [0.4523193]]
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="terminate-endpoint-and-clean-up-artifacts">
<h2>Terminate endpoint and clean up artifacts<a class="headerlink" href="#terminate-endpoint-and-clean-up-artifacts" title="Permalink to this headline"></a></h2>
<p>Don’t forget to clean up artifacts and terminate the endpoint, or the endpoint will continue to incur costs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_client</span><span class="o">.</span><span class="n">delete_model</span><span class="p">(</span><span class="n">ModelName</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">sm_client</span><span class="o">.</span><span class="n">delete_endpoint_config</span><span class="p">(</span><span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span><span class="p">)</span>
<span class="n">sm_client</span><span class="o">.</span><span class="n">delete_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;ResponseMetadata&#39;: {&#39;RequestId&#39;: &#39;a3731da7-55d9-49be-886d-9f77d550a312&#39;,
  &#39;HTTPStatusCode&#39;: 200,
  &#39;HTTPHeaders&#39;: {&#39;x-amzn-requestid&#39;: &#39;a3731da7-55d9-49be-886d-9f77d550a312&#39;,
   &#39;content-type&#39;: &#39;application/x-amz-json-1.1&#39;,
   &#39;content-length&#39;: &#39;0&#39;,
   &#39;date&#39;: &#39;Tue, 18 Oct 2022 23:24:30 GMT&#39;},
  &#39;RetryAttempts&#39;: 0}}
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>