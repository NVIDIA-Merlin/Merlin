<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training and Serving Merlin on AWS SageMaker &mdash; Merlin  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/togglebutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Merlin
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support_matrix/index.html">Merlin Support Matrix</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Merlin</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Training and Serving Merlin on AWS SageMaker</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
</pre></div>
</div>
</div>
</div>
<img alt="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-01-download-convert/nvidia_logo.png" src="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-01-download-convert/nvidia_logo.png" />
<div class="section" id="training-and-serving-merlin-on-aws-sagemaker">
<h1>Training and Serving Merlin on AWS SageMaker<a class="headerlink" href="#training-and-serving-merlin-on-aws-sagemaker" title="Permalink to this headline"></a></h1>
<p>This notebook is created using the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> container.
Note that AWS libraries in this notebook require AWS credentials, and if you are running this notebook in a container, you might need to restart the container with the AWS credentials mounted, e.g., <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">-v</span> <span class="pre">$HOME/.aws:$HOME/.aws</span> <span class="pre">...</span></code>.</p>
<p>With AWS Sagemaker, you can package your own models that can then be trained and deployed in the SageMaker environment. This notebook shows you how to use Merlin for training and inference in the SageMaker environment.</p>
<p>To run this notebook, you need to be able to run <a class="reference external" href="https://aws.amazon.com/cli/">AWS CLI</a> and also have <a class="reference external" href="https://sagemaker.readthedocs.io/en/stable/">Amazon SageMaker Python SDK</a> installed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> python3 -m pip -q install sagemaker
</pre></div>
</div>
</div>
</div>
<div class="section" id="part-1-preparing-your-merlin-model">
<h2>Part 1: Preparing your Merlin model<a class="headerlink" href="#part-1-preparing-your-merlin-model" title="Permalink to this headline"></a></h2>
</div>
<div class="section" id="testing-your-algorithm-on-your-local-machine">
<h2>Testing your algorithm on your local machine<a class="headerlink" href="#testing-your-algorithm-on-your-local-machine" title="Permalink to this headline"></a></h2>
<p>In this notebook, we use the synthetic train and test datasets generated by mimicking the real <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">Ali-CCP</a>: Alibaba Click and Conversion Prediction dataset to build our recommender system ranking models. The Ali-CCP is a dataset gathered from real-world traffic logs of the recommender system in Taobao, the largest online retail platform in the world.</p>
<p>If you would like to use real Ali-CCP dataset instead, you can download the training and test datasets on <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">tianchi.aliyun.com</a>. You can then use <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/main/merlin/datasets/ecommerce/aliccp/dataset.py#L43">get_aliccp()</a> function to curate the raw csv files and save them as parquet files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">merlin.datasets.synthetic</span> <span class="kn">import</span> <span class="n">generate_data</span>

<span class="n">DATA_FOLDER</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DATA_FOLDER&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/aliccp-raw&quot;</span><span class="p">)</span>
<span class="c1">#NUM_ROWS = os.environ.get(&quot;NUM_ROWS&quot;, 1000000)</span>
<span class="n">NUM_ROWS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;NUM_ROWS&quot;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">SYNTHETIC_DATA</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SYNTHETIC_DATA&quot;</span><span class="p">,</span> <span class="s2">&quot;True&quot;</span><span class="p">))</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;BATCH_SIZE&quot;</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>

<span class="k">if</span> <span class="n">SYNTHETIC_DATA</span><span class="p">:</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="s2">&quot;aliccp-raw&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">NUM_ROWS</span><span class="p">),</span> <span class="n">set_sizes</span><span class="o">=</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
    <span class="c1"># save the datasets as parquet files</span>
    <span class="n">train</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">))</span>
    <span class="n">valid</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Before you run your algorithm on SageMaker, you probably want to test and train your training algorithm locally first to make sure that it’s working correctly.
The training script <a class="reference download internal" download="" href="../../_downloads/08d85fba77615657906f6b1c7d98e7fd/train.py"><span class="xref download myst">train.py</span></a> in this example starts with the synthethic dataset we have created in the previous cell and produces a ranking model by performing the following tasks:</p>
<ul class="simple">
<li><p>Perform feature engineering and preprocessing with <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a>. NVTabular implements common feature engineering and preprocessing operators in easy-to-use, high-level APIs.</p></li>
<li><p>Use <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/">Merlin Models</a> to train <a class="reference external" href="https://arxiv.org/pdf/1906.00091.pdf">Facebook’s DLRM model</a> in Tensorflow.</p></li>
<li><p>Prepares <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/user_guide/architecture.md#ensemble-models">ensemble models</a> for serving on <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a>.
The training script outputs the final ensemble models to <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>. You want to make sure that your script generates any artifacts within <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>, since SageMaker packages any files in this directory into a compressed tar archive and made available at the S3 location. Ensemble models that are uploaded to S3 will be used later to handle predictions in Triton inference server later in this notebook.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>! python3 train.py \
    --train_dir={DATA_FOLDER}/train/ \
    --valid_dir={DATA_FOLDER}/valid/ \
    --model_dir=/tmp/ \
    --batch_size=512 \
    --epochs=1
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-10-22 21:41:27.164737: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn&#39;t match a supported version!
  warnings.warn(&quot;urllib3 ({}) or chardet ({}) doesn&#39;t match a supported &quot;
2022-10-22 21:41:28.123185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.123505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.123585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.134792: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-22 21:41:28.135740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.135875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.135967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.995050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.995185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.995266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-22 21:41:28.995352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2867 MB memory:  -&gt; device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5
2022-10-22 21:41:28.999180: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 2.80G (3006267392 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2022-10-22 21:41:28.999404: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 2.52G (2705640704 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2022-10-22 21:41:28.999616: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 2.27G (2435076608 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
Workflow saved to /tmp/tmp88u49_j7/workflow.
batch_size = 512, epochs = 1
2022-10-22 21:41:30.492481: E tensorflow/stream_executor/cuda/cuda_blas.cc:245] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2022-10-22 21:41:30.492513: E tensorflow/stream_executor/cuda/cuda_blas.cc:247] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.
2022-10-22 21:41:30.492533: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:445 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support
Traceback (most recent call last):
  File &quot;train.py&quot;, line 193, in &lt;module&gt;
    train()
  File &quot;train.py&quot;, line 165, in train
    model.fit(
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/models/base.py&quot;, line 721, in fit
    return super().fit(**fit_kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py&quot;, line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/models/base.py&quot;, line 919, in call
    outputs, context = self._call_child(block, outputs, context)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/models/base.py&quot;, line 948, in _call_child
    outputs = call_layer(child, inputs, **call_kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py&quot;, line 398, in call_layer
    return layer(inputs, *args, **filtered_kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/config/schema.py&quot;, line 58, in __call__
    return super().__call__(*args, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py&quot;, line 269, in call
    return call_sequentially(self.layers, inputs, training=training, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py&quot;, line 819, in call_sequentially
    outputs = call_layer(layer, outputs, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py&quot;, line 398, in call_layer
    return layer(inputs, *args, **filtered_kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/config/schema.py&quot;, line 58, in __call__
    return super().__call__(*args, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py&quot;, line 269, in call
    return call_sequentially(self.layers, inputs, training=training, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py&quot;, line 819, in call_sequentially
    outputs = call_layer(layer, outputs, **kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py&quot;, line 398, in call_layer
    return layer(inputs, *args, **filtered_kwargs)
  File &quot;/usr/local/lib/python3.8/dist-packages/merlin/models/tf/blocks/interaction.py&quot;, line 102, in call
    interactions = tf.matmul(left, right, transpose_b=True)
tensorflow.python.framework.errors_impl.InternalError: Exception encountered when calling layer &quot;dot_product_interaction&quot; (type DotProductInteraction).

Attempting to perform BLAS operation using StreamExecutor without BLAS support [Op:BatchMatMulV2]

Call arguments received by layer &quot;dot_product_interaction&quot; (type DotProductInteraction):
  • inputs=tf.Tensor(shape=(512, 16, 64), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-dockerfile">
<h3>The <code class="docutils literal notranslate"><span class="pre">Dockerfile</span></code><a class="headerlink" href="#the-dockerfile" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Dockerfile</span></code> describes the image that will be used on SageMaker for training and inference.
We start from the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> docker image and install the <a class="reference external" href="https://github.com/aws/sagemaker-training-toolkit">sagemaker-training-toolkit</a> library, which makes the image compatible with Sagemaker for training models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> cat container/Dockerfile
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09

RUN pip3 install sagemaker-training
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="building-and-registering-the-container">
<h3>Building and registering the container<a class="headerlink" href="#building-and-registering-the-container" title="Permalink to this headline"></a></h3>
<p>The following shell code shows how to build the container image using <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">build</span></code> and push the container image to ECR using <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">push</span></code>. This code is available as the shell script <code class="docutils literal notranslate"><span class="pre">build_and_push_image.sh</span></code>. If you are running this notebook inside the <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> docker container, you probably want to execute the script outside the container.</p>
<p>This code looks for an ECR repository in the account you’re using and the current default region (if you’re using a SageMaker notebook instance, this is the region where the notebook instance was created). If the repository doesn’t exist, the script will create it.</p>
<p>Note that running the following script requires permissions to create new repositories on Amazon ECR.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> cat ./build_and_push_image.sh
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>#!/bin/bash

set -euo pipefail

# The name of our algorithm
ALGORITHM_NAME=sagemaker-merlin-tensorflow
REGION=us-east-1

cd container

ACCOUNT=$(aws sts get-caller-identity --query Account --output text --region ${REGION})

# Get the region defined in the current configuration (default to us-west-2 if none defined)

REPOSITORY=&quot;${ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com&quot;
IMAGE_URI=&quot;${REPOSITORY}/${ALGORITHM_NAME}:latest&quot;

# Get the login command from ECR and execute it directly
aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin ${REPOSITORY}

# If the repository doesn&#39;t exist in ECR, create it.

aws ecr describe-repositories --repository-names &quot;${ALGORITHM_NAME}&quot; --region ${REGION} &gt; /dev/null 2&gt;&amp;1

if [ $? -ne 0 ]
then
    aws ecr create-repository --repository-name &quot;${ALGORITHM_NAME}&quot; --region ${REGION} &gt; /dev/null
fi

# Build the docker image locally with the image name and then push it to ECR
# with the full name.

docker build  -t ${ALGORITHM_NAME} .
docker tag ${ALGORITHM_NAME} ${IMAGE_URI}

docker push ${IMAGE_URI}
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="part-2-training-your-merlin-model-on-sagemaker">
<h2>Part 2: Training your Merlin model on Sagemaker<a class="headerlink" href="#part-2-training-your-merlin-model-on-sagemaker" title="Permalink to this headline"></a></h2>
<p>Once you have tested your script that creates a Merlin ensemble graph, you can use it to train it on Sagemaker.</p>
<p>Here, we create a Sagemaker session that we will use to perform our Sagemaker operations, specify the bucket to use, and the role for working with Sagemaker.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sagemaker</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>

<span class="c1"># S3 prefix</span>
<span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;DEMO-merlin-tensorflow-aliccp&quot;</span>

<span class="n">role</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">get_execution_role</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">role</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Couldn&#39;t call &#39;get_role&#39; to get Role ARN from role name AWSOS-AD-Engineer to get Role path.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>arn:aws:iam::843263297212:role/AWSOS-AD-Engineer
</pre></div>
</div>
</div>
</div>
<p>We can use the Sagemaker Python SDK to upload the Ali-CCP synthetic data to our S3 bucket.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_location</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">upload_data</span><span class="p">(</span><span class="n">DATA_DIRECTORY</span><span class="p">,</span> <span class="n">key_prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data_location</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">data_location</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">upload_data</span><span class="p">(</span><span class="n">DATA_DIRECTORY</span><span class="p">,</span> <span class="n">key_prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="nb">print</span><span class="p">(</span><span class="n">data_location</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;DATA_DIRECTORY&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="section" id="training-on-sagemaker-using-the-python-sdk">
<h3>Training on Sagemaker using the Python SDK<a class="headerlink" href="#training-on-sagemaker-using-the-python-sdk" title="Permalink to this headline"></a></h3>
<p>Sagemaker provides the Python SDK for training a model on Sagemaker.</p>
<p>Here, we start by using the ECR image URL of the image we pushed in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;sts&quot;</span><span class="p">)</span>
<span class="n">account</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_caller_identity</span><span class="p">()[</span><span class="s2">&quot;Account&quot;</span><span class="p">]</span>

<span class="n">my_session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">region</span> <span class="o">=</span> <span class="n">my_session</span><span class="o">.</span><span class="n">region_name</span>

<span class="n">algorithm_name</span> <span class="o">=</span> <span class="s2">&quot;sagemaker-merlin-tensorflow&quot;</span>

<span class="n">ecr_image</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.dkr.ecr.</span><span class="si">{}</span><span class="s2">.amazonaws.com/</span><span class="si">{}</span><span class="s2">:latest&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">account</span><span class="p">,</span> <span class="n">region</span><span class="p">,</span> <span class="n">algorithm_name</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ecr_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can call <code class="docutils literal notranslate"><span class="pre">Estimator.fit()</span></code> to start training on Sagemaker. Here, we use a <code class="docutils literal notranslate"><span class="pre">g4dn</span></code> GPU instance that are equipped with NVIDIA T4 GPUs.
Our training script <code class="docutils literal notranslate"><span class="pre">train.py</span></code> is passed to the Estimator through the <code class="docutils literal notranslate"><span class="pre">entry_point</span></code> parameter, and we can adjust our hyperparameters in the <code class="docutils literal notranslate"><span class="pre">hyperparameters</span></code>.
We have uploaded our training dataset to our S3 bucket in the previous code cell, and the S3 URLs to our training and validation sets are passed into the <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sagemaker.estimator</span> <span class="kn">import</span> <span class="n">Estimator</span>


<span class="n">training_instance_type</span> <span class="o">=</span> <span class="s2">&quot;ml.g4dn.xlarge&quot;</span>  <span class="c1"># GPU instance, T4</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">Estimator</span><span class="p">(</span>
    <span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span>
    <span class="n">instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">instance_type</span><span class="o">=</span><span class="n">training_instance_type</span><span class="p">,</span>
    <span class="n">image_uri</span><span class="o">=</span><span class="n">ecr_image</span><span class="p">,</span>
    <span class="n">entry_point</span><span class="o">=</span><span class="s2">&quot;train.py&quot;</span><span class="p">,</span>
    <span class="n">hyperparameters</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">1_024</span><span class="p">,</span>
        <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> 
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_location</span><span class="si">}</span><span class="s2">/train/&quot;</span><span class="p">,</span>
        <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_location</span><span class="si">}</span><span class="s2">/valid/&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">model_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> aws s3 cp <span class="o">{</span>estimator.model_data<span class="o">}</span> /tmp/ensemble/
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> tar xvzf /tmp/ensemble/model.tar.gz
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="part-3-retrieving-recommendations-from-triton-inference-server">
<h2>Part 3: Retrieving Recommendations from Triton Inference Server<a class="headerlink" href="#part-3-retrieving-recommendations-from-triton-inference-server" title="Permalink to this headline"></a></h2>
<p>Although we use the Sagemaker Python SDK to train our model, here we will use <code class="docutils literal notranslate"><span class="pre">boto3</span></code> to launch our inference endpoint as it offers more low-level control than the Python SDK.</p>
<p>The model artificat <code class="docutils literal notranslate"><span class="pre">model.tar.gz</span></code> uploaded to S3 from the Sagemaker training job contained three directories: <code class="docutils literal notranslate"><span class="pre">0_transformworkflow</span></code> for the NVTabular workflow, <code class="docutils literal notranslate"><span class="pre">1_predicttensorflow</span></code> for the Tensorflow model, and <code class="docutils literal notranslate"><span class="pre">ensemble_model</span></code> for the ensemble graph that we can use in Triton.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>/tmp/ensemble/
├── 0_transformworkflow
│   ├── <span class="m">1</span>
│   │   ├── model.py
│   │   └── workflow
│   │       ├── categories
│   │       │   ├── unique.item_brand.parquet
│   │       │   ├── unique.item_category.parquet
│   │       │   ├── unique.item_id.parquet
│   │       │   ├── unique.item_shop.parquet
│   │       │   ├── unique.user_age.parquet
│   │       │   ├── unique.user_brands.parquet
│   │       │   ├── unique.user_categories.parquet
│   │       │   ├── unique.user_consumption_2.parquet
│   │       │   ├── unique.user_gender.parquet
│   │       │   ├── unique.user_geography.parquet
│   │       │   ├── unique.user_group.parquet
│   │       │   ├── unique.user_id.parquet
│   │       │   ├── unique.user_intentions.parquet
│   │       │   ├── unique.user_is_occupied.parquet
│   │       │   ├── unique.user_profile.parquet
│   │       │   └── unique.user_shops.parquet
│   │       ├── metadata.json
│   │       └── workflow.pkl
│   └── config.pbtxt
├── 1_predicttensorflow
│   ├── <span class="m">1</span>
│   │   └── model.savedmodel
│   │       ├── assets
│   │       ├── keras_metadata.pb
│   │       ├── saved_model.pb
│   │       └── variables
│   │           ├── variables.data-00000-of-00001
│   │           └── variables.index
│   └── config.pbtxt
├── ensemble_model
│   ├── <span class="m">1</span>
│   └── config.pbtxt
└── model.tar.gz
</pre></div>
</div>
<p>We specify that we only want to use <code class="docutils literal notranslate"><span class="pre">ensemble_model</span></code> in Triton by passing the environment variable <code class="docutils literal notranslate"><span class="pre">SAGEMAKER_TRITON_DEFAULT_MODEL_NAME</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">sm_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="n">service_name</span><span class="o">=</span><span class="s2">&quot;sagemaker&quot;</span><span class="p">)</span>

<span class="n">container</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Image&quot;</span><span class="p">:</span> <span class="n">ecr_image</span><span class="p">,</span>
    <span class="s2">&quot;ModelDataUrl&quot;</span><span class="p">:</span> <span class="n">estimator</span><span class="o">.</span><span class="n">model_data</span><span class="p">,</span>
    <span class="s2">&quot;Environment&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;SAGEMAKER_TRITON_TENSORFLOW_VERSION&quot;</span><span class="p">:</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span>
        <span class="s2">&quot;SAGEMAKER_TRITON_DEFAULT_MODEL_NAME&quot;</span><span class="p">:</span> <span class="s2">&quot;ensemble_model&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;model-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>

<span class="n">create_model_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span>
    <span class="n">ModelName</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">ExecutionRoleArn</span><span class="o">=</span><span class="n">role</span><span class="p">,</span> <span class="n">PrimaryContainer</span><span class="o">=</span><span class="n">container</span>
<span class="p">)</span>

<span class="n">model_arn</span> <span class="o">=</span> <span class="n">create_model_response</span><span class="p">[</span><span class="s2">&quot;ModelArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model Arn: </span><span class="si">{</span><span class="n">model_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We again use the <code class="docutils literal notranslate"><span class="pre">g4dn</span></code> GPU instance that are equipped with NVIDIA T4 GPUs for launching the Triton inference server.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint_instance_type</span> <span class="o">=</span> <span class="s2">&quot;ml.g4dn.xlarge&quot;</span>

<span class="n">endpoint_config_name</span> <span class="o">=</span> <span class="s2">&quot;endpoint-config-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>

<span class="n">create_endpoint_config_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_endpoint_config</span><span class="p">(</span>
    <span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span><span class="p">,</span>
    <span class="n">ProductionVariants</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;InstanceType&quot;</span><span class="p">:</span> <span class="n">endpoint_instance_type</span><span class="p">,</span>
            <span class="s2">&quot;InitialVariantWeight&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;InitialInstanceCount&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;ModelName&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
            <span class="s2">&quot;VariantName&quot;</span><span class="p">:</span> <span class="s2">&quot;AllTraffic&quot;</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="n">endpoint_config_arn</span> <span class="o">=</span> <span class="n">create_endpoint_config_response</span><span class="p">[</span><span class="s2">&quot;EndpointConfigArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Config Arn: </span><span class="si">{</span><span class="n">endpoint_config_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint_name</span> <span class="o">=</span> <span class="s2">&quot;endpoint-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">())</span>

<span class="n">create_endpoint_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_endpoint</span><span class="p">(</span>
    <span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span> <span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span>
<span class="p">)</span>

<span class="n">endpoint_arn</span> <span class="o">=</span> <span class="n">create_endpoint_response</span><span class="p">[</span><span class="s2">&quot;EndpointArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Arn: </span><span class="si">{</span><span class="n">endpoint_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">status</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">describe_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)[</span><span class="s2">&quot;EndpointStatus&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Creation Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">while</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;Creating&quot;</span><span class="p">:</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">describe_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">rv</span><span class="p">[</span><span class="s2">&quot;EndpointStatus&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Creation Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">endpoint_arn</span> <span class="o">=</span> <span class="n">rv</span><span class="p">[</span><span class="s2">&quot;EndpointArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Arn: </span><span class="si">{</span><span class="n">endpoint_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="send-a-request-to-triton-inference-server-to-transform-a-raw-dataset">
<h3>Send a Request to Triton Inference Server to Transform a Raw Dataset<a class="headerlink" href="#send-a-request-to-triton-inference-server-to-transform-a-raw-dataset" title="Permalink to this headline"></a></h3>
<p>Once we have an endpoint running, we can test it by sending requests.
Here, we use the raw validation set and transform it using the saved VTabular workflow we have downloaded from S3 in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.schema.tags</span> <span class="kn">import</span> <span class="n">Tags</span>
<span class="kn">from</span> <span class="nn">merlin.core.dispatch</span> <span class="kn">import</span> <span class="n">get_lib</span>
<span class="kn">from</span> <span class="nn">nvtabular.workflow</span> <span class="kn">import</span> <span class="n">Workflow</span>

<span class="n">df_lib</span> <span class="o">=</span> <span class="n">get_lib</span><span class="p">()</span>

<span class="n">original_data_path</span> <span class="o">=</span> <span class="n">DATA_DIRECTORY</span>
<span class="n">workflow</span> <span class="o">=</span> <span class="n">Workflow</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/tmp/ensemble/0_transformworkflow/1/workflow/&quot;</span><span class="p">)</span>

<span class="n">label_columns</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">TARGET</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">remove_inputs</span><span class="p">(</span><span class="n">label_columns</span><span class="p">)</span>

<span class="c1"># read in data for request</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">df_lib</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">original_data_path</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;part.0.parquet&quot;</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">column_names</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In the following code cell, we use a utility function provided in <a class="reference external" href="https://github.com/NVIDIA-Merlin/systems">Merlin Systems</a> to convert our dataframe to the payload format that can be used as inference request format for Triton.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.triton</span> <span class="kn">import</span> <span class="n">convert_df_to_triton_input</span>
<span class="kn">import</span> <span class="nn">tritonclient.http</span> <span class="k">as</span> <span class="nn">httpclient</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">convert_df_to_triton_input</span><span class="p">(</span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferInput</span><span class="p">)</span>

<span class="n">request_body</span><span class="p">,</span> <span class="n">header_length</span> <span class="o">=</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="o">.</span><span class="n">generate_request_body</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">request_body</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Triton uses the <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/protocol/README.md">KServe community standard inference protocols</a>.
Here, we use the <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/protocol/extension_binary_data.md">binary+json format</a> for optimal performance in the inference request.</p>
<p>In order for Triton to correctly parse the binary payload, we have to specify the length of the request metadata in the header <code class="docutils literal notranslate"><span class="pre">json-header-size</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">runtime_sm_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;sagemaker-runtime&quot;</span><span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">runtime_sm_client</span><span class="o">.</span><span class="n">invoke_endpoint</span><span class="p">(</span>
    <span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span>
    <span class="n">ContentType</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;application/vnd.sagemaker-triton.binary+json;json-header-size=</span><span class="si">{</span><span class="n">header_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">Body</span><span class="o">=</span><span class="n">request_body</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Parse json header size length from the response</span>
<span class="n">header_length_prefix</span> <span class="o">=</span> <span class="s2">&quot;application/vnd.sagemaker-triton.binary+json;json-header-size=&quot;</span>
<span class="n">header_length_str</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;ContentType&quot;</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">header_length_prefix</span><span class="p">)</span> <span class="p">:]</span>

<span class="c1"># Read response body</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="o">.</span><span class="n">parse_response_body</span><span class="p">(</span>
    <span class="n">response</span><span class="p">[</span><span class="s2">&quot;Body&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">header_length</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">header_length_str</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="s2">&quot;click/binary_classification_task&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;predicted sigmoid result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">output_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="terminate-endpoint-and-clean-up-artifacts">
<h2>Terminate endpoint and clean up artifacts<a class="headerlink" href="#terminate-endpoint-and-clean-up-artifacts" title="Permalink to this headline"></a></h2>
<p>Don’t forget to clean up artifacts and terminate the endpoint, or the endpoint will continue to incur costs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_client</span><span class="o">.</span><span class="n">delete_model</span><span class="p">(</span><span class="n">ModelName</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">sm_client</span><span class="o">.</span><span class="n">delete_endpoint_config</span><span class="p">(</span><span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span><span class="p">)</span>
<span class="n">sm_client</span><span class="o">.</span><span class="n">delete_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>