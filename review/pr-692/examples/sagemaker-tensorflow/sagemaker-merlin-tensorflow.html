<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training and Serving Merlin on AWS SageMaker &mdash; Merlin  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/togglebutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Merlin
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support_matrix/index.html">Merlin Support Matrix</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Merlin</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Training and Serving Merlin on AWS SageMaker</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
</pre></div>
</div>
</div>
</div>
<img alt="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-01-download-convert/nvidia_logo.png" src="https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-01-download-convert/nvidia_logo.png" />
<div class="section" id="training-and-serving-merlin-on-aws-sagemaker">
<h1>Training and Serving Merlin on AWS SageMaker<a class="headerlink" href="#training-and-serving-merlin-on-aws-sagemaker" title="Permalink to this headline"></a></h1>
<p>This notebook is created using the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> container.
Note that AWS libraries in this notebook require AWS credentials, and if you are running this notebook in a container, you might need to restart the container with the AWS credentials mounted, e.g., <code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">$HOME/.aws:$HOME/.aws</span></code>.</p>
<p>With AWS Sagemaker, you can package your own models that can then be trained and deployed in the SageMaker environment. This notebook shows you how to use Merlin for training and inference in the SageMaker environment.</p>
<p>It assumes that readers are familiar wtth some basic concepts in NVIDIA Merlin,
such as:</p>
<ul class="simple">
<li><p>Using NVTabular to GPU-accelerate preprocessing and feature engineering,</p></li>
<li><p>Training a ranking model using Merlin Models, and</p></li>
<li><p>Inference with the Triton Inference Server and Merlin Models for Tensorflow.</p></li>
</ul>
<p>To learn more about these concepts in NVIDIA Merlin, see for example
<span class="xref myst">Deploying a Multi-Stage Recommender System</span>
in this repository or example notebooks in
<a class="reference external" href="https://github.com/NVIDIA-Merlin/models/tree/main/examples">Merlin Models</a>.</p>
<p>To run this notebook, you need to be able to run <a class="reference external" href="https://aws.amazon.com/cli/">AWS CLI</a> and also have <a class="reference external" href="https://sagemaker.readthedocs.io/en/stable/">Amazon SageMaker Python SDK</a> installed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> python3 -m pip -q install awscliv2 sagemaker
</pre></div>
</div>
</div>
</div>
<div class="section" id="part-1-generating-dataset-and-docker-image">
<h2>Part 1: Generating Dataset and Docker image<a class="headerlink" href="#part-1-generating-dataset-and-docker-image" title="Permalink to this headline"></a></h2>
<div class="section" id="generating-dataset">
<h3>Generating Dataset<a class="headerlink" href="#generating-dataset" title="Permalink to this headline"></a></h3>
<p>In this notebook, we use the synthetic train and test datasets generated by mimicking the real <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">Ali-CCP</a>: Alibaba Click and Conversion Prediction dataset to build our recommender system ranking models. The Ali-CCP is a dataset gathered from real-world traffic logs of the recommender system in Taobao, the largest online retail platform in the world.</p>
<p>If you would like to use real Ali-CCP dataset instead, you can download the training and test datasets on <a class="reference external" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1">tianchi.aliyun.com</a>. You can then use <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/main/merlin/datasets/ecommerce/aliccp/dataset.py#L43">get_aliccp()</a> function to curate the raw csv files and save them as parquet files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">merlin.datasets.synthetic</span> <span class="kn">import</span> <span class="n">generate_data</span>

<span class="n">DATA_FOLDER</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DATA_FOLDER&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>
<span class="n">NUM_ROWS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;NUM_ROWS&quot;</span><span class="p">,</span> <span class="mi">1_000_000</span><span class="p">)</span>
<span class="n">SYNTHETIC_DATA</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SYNTHETIC_DATA&quot;</span><span class="p">,</span> <span class="s2">&quot;True&quot;</span><span class="p">))</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;BATCH_SIZE&quot;</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>

<span class="k">if</span> <span class="n">SYNTHETIC_DATA</span><span class="p">:</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="s2">&quot;aliccp-raw&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">NUM_ROWS</span><span class="p">),</span> <span class="n">set_sizes</span><span class="o">=</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
    <span class="c1"># save the datasets as parquet files</span>
    <span class="n">train</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">))</span>
    <span class="n">valid</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].
  warnings.warn(
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-script">
<h3>Training Script<a class="headerlink" href="#training-script" title="Permalink to this headline"></a></h3>
<p>The training script <a class="reference download internal" download="" href="../../_downloads/08d85fba77615657906f6b1c7d98e7fd/train.py"><span class="xref download myst">train.py</span></a> in this example starts with the synthethic dataset we have created in the previous cell and produces a ranking model by performing the following tasks:</p>
<ul class="simple">
<li><p>Perform feature engineering and preprocessing with <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a>. NVTabular implements common feature engineering and preprocessing operators in easy-to-use, high-level APIs.</p></li>
<li><p>Use <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/">Merlin Models</a> to train <a class="reference external" href="https://arxiv.org/pdf/1906.00091.pdf">Facebook’s DLRM model</a> in Tensorflow.</p></li>
<li><p>Prepares <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/user_guide/architecture.md#ensemble-models">ensemble models</a> for serving on <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a>.
The training script outputs to <code class="docutils literal notranslate"><span class="pre">model_dir</span></code> the final NVTabular workflow and the trained DLRM model as an ensemble model. You want to make sure that your script generates any artifacts within <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>, since SageMaker packages any files in this directory into a compressed tar archive and made available at the S3 location. The ensemble model that is uploaded to S3 will be used later to handle predictions in Triton inference server later in this notebook.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> train.py
<span class="c1">#</span>
<span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="c1"># We can control how much memory to give tensorflow with this environment variable</span>
<span class="c1"># IMPORTANT: make sure you do this before you initialize TF&#39;s runtime, otherwise</span>
<span class="c1"># TF will have claimed all free GPU memory</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_MEMORY_ALLOCATION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0.7&quot;</span>  <span class="c1"># fraction of free memory</span>

<span class="kn">import</span> <span class="nn">merlin.io</span>
<span class="kn">import</span> <span class="nn">merlin.models.tf</span> <span class="k">as</span> <span class="nn">mm</span>
<span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">merlin.schema.tags</span> <span class="kn">import</span> <span class="n">Tags</span>
<span class="kn">from</span> <span class="nn">merlin.systems.dag.ops.workflow</span> <span class="kn">import</span> <span class="n">TransformWorkflow</span>
<span class="kn">from</span> <span class="nn">merlin.systems.dag.ops.tensorflow</span> <span class="kn">import</span> <span class="n">PredictTensorflow</span>
<span class="kn">from</span> <span class="nn">merlin.systems.dag.ensemble</span> <span class="kn">import</span> <span class="n">Ensemble</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">nvtabular.ops</span> <span class="kn">import</span> <span class="o">*</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">parse_args</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse arguments passed from the SageMaker API to the container.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>

    <span class="c1"># Hyperparameters sent by the client are passed as command-line arguments to the script</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--epochs&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--batch_size&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>

    <span class="c1"># Data directories</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--train_dir&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SM_CHANNEL_TRAIN&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--valid_dir&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SM_CHANNEL_VALID&quot;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Model directory: we will use the default set by SageMaker, /opt/ml/model</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--model_dir&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SM_MODEL_DIR&quot;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">create_nvtabular_workflow</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">valid_path</span><span class="p">):</span>
    <span class="n">user_id</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;user_id&quot;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">Categorify</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">TagAsUserID</span><span class="p">()</span>
    <span class="n">item_id</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;item_id&quot;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">Categorify</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">TagAsItemID</span><span class="p">()</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;click&quot;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">AddMetadata</span><span class="p">(</span><span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="n">Tags</span><span class="o">.</span><span class="n">BINARY_CLASSIFICATION</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">])</span>

    <span class="n">item_features</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[</span><span class="s2">&quot;item_category&quot;</span><span class="p">,</span> <span class="s2">&quot;item_shop&quot;</span><span class="p">,</span> <span class="s2">&quot;item_brand&quot;</span><span class="p">]</span>
        <span class="o">&gt;&gt;</span> <span class="n">Categorify</span><span class="p">()</span>
        <span class="o">&gt;&gt;</span> <span class="n">TagAsItemFeatures</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="n">user_features</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[</span>
            <span class="s2">&quot;user_shops&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_profile&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_group&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_gender&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_age&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_consumption_2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_is_occupied&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_geography&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_intentions&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_brands&quot;</span><span class="p">,</span>
            <span class="s2">&quot;user_categories&quot;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="o">&gt;&gt;</span> <span class="n">Categorify</span><span class="p">()</span>
        <span class="o">&gt;&gt;</span> <span class="n">TagAsUserFeatures</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">user_id</span> <span class="o">+</span> <span class="n">item_id</span> <span class="o">+</span> <span class="n">item_features</span> <span class="o">+</span> <span class="n">user_features</span> <span class="o">+</span> <span class="n">targets</span>

    <span class="n">workflow</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">workflow</span>


<span class="k">def</span> <span class="nf">create_ensemble</span><span class="p">(</span><span class="n">workflow</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">serving_operators</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">column_names</span>
        <span class="o">&gt;&gt;</span> <span class="n">TransformWorkflow</span><span class="p">(</span><span class="n">workflow</span><span class="p">)</span>
        <span class="o">&gt;&gt;</span> <span class="n">PredictTensorflow</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">ensemble</span> <span class="o">=</span> <span class="n">Ensemble</span><span class="p">(</span><span class="n">serving_operators</span><span class="p">,</span> <span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ensemble</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train the Merlin model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_dir</span><span class="p">,</span> <span class="s2">&quot;*.parquet&quot;</span><span class="p">)</span>
    <span class="n">valid_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">valid_dir</span><span class="p">,</span> <span class="s2">&quot;*.parquet&quot;</span><span class="p">)</span>

    <span class="n">workflow</span> <span class="o">=</span> <span class="n">create_nvtabular_workflow</span><span class="p">(</span>
        <span class="n">train_path</span><span class="o">=</span><span class="n">train_path</span><span class="p">,</span>
        <span class="n">valid_path</span><span class="o">=</span><span class="n">valid_path</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">train_path</span><span class="p">)</span>
    <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">valid_path</span><span class="p">)</span>

    <span class="n">output_path</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
    <span class="n">workflow_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;workflow&quot;</span><span class="p">)</span>

    <span class="n">workflow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
    <span class="n">workflow</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span>
        <span class="n">output_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">workflow</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">)</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span>
        <span class="n">output_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">workflow</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">workflow_path</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Workflow saved to </span><span class="si">{</span><span class="n">workflow_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">merlin</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;*.parquet&quot;</span><span class="p">))</span>
    <span class="n">valid_data</span> <span class="o">=</span> <span class="n">merlin</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;*.parquet&quot;</span><span class="p">))</span>

    <span class="n">schema</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">schema</span>
    <span class="n">target_column</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">TARGET</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">DLRMModel</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">bottom_block</span><span class="o">=</span><span class="n">mm</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">]),</span>
        <span class="n">top_block</span><span class="o">=</span><span class="n">mm</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span>
        <span class="n">prediction_tasks</span><span class="o">=</span><span class="n">mm</span><span class="o">.</span><span class="n">BinaryClassificationTask</span><span class="p">(</span><span class="n">target_column</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">AUC</span><span class="p">()])</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;batch_size = </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">, epochs = </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">train_data</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_data</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;dlrm&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="c1"># We remove the label columns from its inputs.</span>
    <span class="c1"># This removes all columns with the TARGET tag from the workflow.</span>
    <span class="c1"># We do this because we need to set the workflow to only require the</span>
    <span class="c1"># features needed to predict, not train, when creating an inference</span>
    <span class="c1"># pipeline.</span>
    <span class="n">label_columns</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">TARGET</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span>
    <span class="n">workflow</span><span class="o">.</span><span class="n">remove_inputs</span><span class="p">(</span><span class="n">label_columns</span><span class="p">)</span>

    <span class="n">ensemble</span> <span class="o">=</span> <span class="n">create_ensemble</span><span class="p">(</span><span class="n">workflow</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">ensemble_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">model_dir</span>
    <span class="n">ensemble</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">ensemble_path</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble graph saved to </span><span class="si">{</span><span class="n">ensemble_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
    <span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting train.py
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-dockerfile">
<h3>The <code class="docutils literal notranslate"><span class="pre">Dockerfile</span></code><a class="headerlink" href="#the-dockerfile" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Dockerfile</span></code> describes the image that will be used on SageMaker for training and inference.
We start from the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> docker image and install the <a class="reference external" href="https://github.com/aws/sagemaker-training-toolkit">sagemaker-training-toolkit</a> library, which makes the image compatible with Sagemaker for training models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> container/Dockerfile

<span class="n">FROM</span> <span class="n">nvcr</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">nvidia</span><span class="o">/</span><span class="n">merlin</span><span class="o">/</span><span class="n">merlin</span><span class="o">-</span><span class="n">tensorflow</span><span class="p">:</span><span class="mf">22.09</span>

<span class="n">RUN</span> <span class="n">pip3</span> <span class="n">install</span> <span class="n">sagemaker</span><span class="o">-</span><span class="n">training</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting container/Dockerfile
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="building-and-registering-the-container">
<h3>Building and registering the container<a class="headerlink" href="#building-and-registering-the-container" title="Permalink to this headline"></a></h3>
<p>The following shell code shows how to build the container image using <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">build</span></code> and push the container image to ECR using <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">push</span></code>. This code is available as the shell script <code class="docutils literal notranslate"><span class="pre">build_and_push_image.sh</span></code>. If you are running this notebook inside the <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> docker container, you probably need to execute the script outside the container (e.g., in your terminal where you can run the <code class="docutils literal notranslate"><span class="pre">docker</span></code> command).</p>
<p>This code looks for an ECR repository in the account you’re using and the current default region (if you’re using a SageMaker notebook instance, this is the region where the notebook instance was created). If the repository doesn’t exist, the script will create it.</p>
<p>Note that running the following script requires permissions to create new repositories on Amazon ECR.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%writefile ./build_and_push_image.sh

#!/bin/bash

set -euo pipefail

# The name of our algorithm
ALGORITHM_NAME=sagemaker-merlin-tensorflow
REGION=us-east-1

cd container

ACCOUNT=$(aws sts get-caller-identity --query Account --output text --region ${REGION})

# Get the region defined in the current configuration (default to us-west-2 if none defined)

REPOSITORY=&quot;${ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com&quot;
IMAGE_URI=&quot;${REPOSITORY}/${ALGORITHM_NAME}:latest&quot;

# Get the login command from ECR and execute it directly
aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin ${REPOSITORY}

# If the repository doesn&#39;t exist in ECR, create it.

aws ecr describe-repositories --repository-names &quot;${ALGORITHM_NAME}&quot; --region ${REGION} &gt; /dev/null 2&gt;&amp;1

if [ $? -ne 0 ]
then
    aws ecr create-repository --repository-name &quot;${ALGORITHM_NAME}&quot; --region ${REGION} &gt; /dev/null
fi

# Build the docker image locally with the image name and then push it to ECR
# with the full name.

docker build  -t ${ALGORITHM_NAME} .
docker tag ${ALGORITHM_NAME} ${IMAGE_URI}

docker push ${IMAGE_URI}
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting ./build_and_push_image.sh
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you are able to run `docker` from the notebook environment, you can uncomment and run the below script.</span>
<span class="c1"># ! ./build_and_push_image.sh</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="part-2-training-your-merlin-model-on-sagemaker">
<h2>Part 2: Training your Merlin model on Sagemaker<a class="headerlink" href="#part-2-training-your-merlin-model-on-sagemaker" title="Permalink to this headline"></a></h2>
<p>To deploy the training script onto Sagemaker, we use the Sagemaker Python SDK.
Here, we create a Sagemaker session that we will use to perform our Sagemaker operations, specify the bucket to use, and the role for working with Sagemaker.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sagemaker</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>

<span class="c1"># S3 prefix</span>
<span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;DEMO-merlin-tensorflow-aliccp&quot;</span>

<span class="n">role</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">get_execution_role</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">role</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Couldn&#39;t call &#39;get_role&#39; to get Role ARN from role name AWSOS-AD-Engineer to get Role path.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>arn:aws:iam::843263297212:role/AWSOS-AD-Engineer
</pre></div>
</div>
</div>
</div>
<p>We can use the Sagemaker Python SDK to upload the Ali-CCP synthetic data to our S3 bucket.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_location</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">upload_data</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="n">key_prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data_location</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>s3://sagemaker-us-east-1-843263297212/DEMO-merlin-tensorflow-aliccp
</pre></div>
</div>
</div>
</div>
<div class="section" id="training-on-sagemaker-using-the-python-sdk">
<h3>Training on Sagemaker using the Python SDK<a class="headerlink" href="#training-on-sagemaker-using-the-python-sdk" title="Permalink to this headline"></a></h3>
<p>Sagemaker provides the Python SDK for training a model on Sagemaker.</p>
<p>Here, we start by using the ECR image URL of the image we pushed in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;sts&quot;</span><span class="p">)</span>
<span class="n">account</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_caller_identity</span><span class="p">()[</span><span class="s2">&quot;Account&quot;</span><span class="p">]</span>

<span class="n">my_session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">region</span> <span class="o">=</span> <span class="n">my_session</span><span class="o">.</span><span class="n">region_name</span>

<span class="n">algorithm_name</span> <span class="o">=</span> <span class="s2">&quot;sagemaker-merlin-tensorflow&quot;</span>

<span class="n">ecr_image</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.dkr.ecr.</span><span class="si">{}</span><span class="s2">.amazonaws.com/</span><span class="si">{}</span><span class="s2">:latest&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">account</span><span class="p">,</span> <span class="n">region</span><span class="p">,</span> <span class="n">algorithm_name</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ecr_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>843263297212.dkr.ecr.us-east-1.amazonaws.com/sagemaker-merlin-tensorflow:latest
</pre></div>
</div>
</div>
</div>
<p>We can call <code class="docutils literal notranslate"><span class="pre">Estimator.fit()</span></code> to start training on Sagemaker. Here, we use a <code class="docutils literal notranslate"><span class="pre">g4dn</span></code> GPU instance that are equipped with NVIDIA T4 GPUs.
Our training script <code class="docutils literal notranslate"><span class="pre">train.py</span></code> is passed to the Estimator through the <code class="docutils literal notranslate"><span class="pre">entry_point</span></code> parameter.
Behind the scenes, the Sagemaker Python SDK will upload the training script specified in the<code class="docutils literal notranslate"><span class="pre">entry_point</span></code> field (<code class="docutils literal notranslate"><span class="pre">train.py</span></code> in our case)
to the S3 bucket and set the <code class="docutils literal notranslate"><span class="pre">SAGEMAKER_PROGRAM</span></code> environment variable in the training instance to the S3 location so that the training instance
can download the training script on S3 to the training instance.
We also adjust our hyperparameters in the <code class="docutils literal notranslate"><span class="pre">hyperparameters</span></code> field.
We have uploaded our training dataset to our S3 bucket in the previous code cell, and the S3 URLs to our training and validation sets are passed into the <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sagemaker.estimator</span> <span class="kn">import</span> <span class="n">Estimator</span>


<span class="n">training_instance_type</span> <span class="o">=</span> <span class="s2">&quot;ml.g4dn.xlarge&quot;</span>  <span class="c1"># GPU instance, T4</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">Estimator</span><span class="p">(</span>
    <span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span>
    <span class="n">instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">instance_type</span><span class="o">=</span><span class="n">training_instance_type</span><span class="p">,</span>
    <span class="n">image_uri</span><span class="o">=</span><span class="n">ecr_image</span><span class="p">,</span>
    <span class="n">entry_point</span><span class="o">=</span><span class="s2">&quot;train.py&quot;</span><span class="p">,</span>
    <span class="n">hyperparameters</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">1_024</span><span class="p">,</span>
        <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_location</span><span class="si">}</span><span class="s2">/train/&quot;</span><span class="p">,</span>
        <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_location</span><span class="si">}</span><span class="s2">/valid/&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-10-27 17:04:59 Starting - Starting the training job...ProfilerReport-1666890298: InProgress
...
2022-10-27 17:05:44 Starting - Preparing the instances for training............
2022-10-27 17:08:04 Downloading - Downloading input data...
2022-10-27 17:08:34 Training - Downloading the training image............................................<span class=" -Color -Color-Blue">==================================</span>
<span class=" -Color -Color-Blue">== Triton Inference Server Base ==</span>
<span class=" -Color -Color-Blue">==================================</span>
<span class=" -Color -Color-Blue">NVIDIA Release 22.08 (build 42766143)</span>
<span class=" -Color -Color-Blue">Copyright (c) 2018-2022, NVIDIA CORPORATION &amp; AFFILIATES.  All rights reserved.</span>
<span class=" -Color -Color-Blue">Various files include modifications (c) NVIDIA CORPORATION &amp; AFFILIATES.  All rights reserved.</span>
<span class=" -Color -Color-Blue">This container image and its contents are governed by the NVIDIA Deep Learning Container License.</span>
<span class=" -Color -Color-Blue">By pulling and using the container, you accept the terms and conditions of this license:</span>
<span class=" -Color -Color-Blue">https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license</span>
<span class=" -Color -Color-Blue">NOTE: CUDA Forward Compatibility mode ENABLED.</span>
<span class=" -Color -Color-Blue">  Using CUDA 11.7 driver version 515.65.01 with kernel driver version 510.47.03.</span>
<span class=" -Color -Color-Blue">  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:16,602 sagemaker-training-toolkit INFO     Invoking user script</span>
<span class=" -Color -Color-Blue">Training Env:</span>
<span class=" -Color -Color-Blue">{</span>
<span class=" -Color -Color-Blue">    &quot;additional_framework_parameters&quot;: {},</span>
<span class=" -Color -Color-Blue">    &quot;channel_input_dirs&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;train&quot;: &quot;/opt/ml/input/data/train&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;valid&quot;: &quot;/opt/ml/input/data/valid&quot;</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;current_host&quot;: &quot;algo-1&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;current_instance_group&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;current_instance_group_hosts&quot;: [</span>
<span class=" -Color -Color-Blue">        &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">    ],</span>
<span class=" -Color -Color-Blue">    &quot;current_instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;distribution_hosts&quot;: [],</span>
<span class=" -Color -Color-Blue">    &quot;distribution_instance_groups&quot;: [],</span>
<span class=" -Color -Color-Blue">    &quot;framework_module&quot;: null,</span>
<span class=" -Color -Color-Blue">    &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">        &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">    ],</span>
<span class=" -Color -Color-Blue">    &quot;hyperparameters&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;batch_size&quot;: 1024,</span>
<span class=" -Color -Color-Blue">        &quot;epoch&quot;: 10</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;input_config_dir&quot;: &quot;/opt/ml/input/config&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;input_data_config&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;train&quot;: {</span>
<span class=" -Color -Color-Blue">            &quot;TrainingInputMode&quot;: &quot;File&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;S3DistributionType&quot;: &quot;FullyReplicated&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;RecordWrapperType&quot;: &quot;None&quot;</span>
<span class=" -Color -Color-Blue">        },</span>
<span class=" -Color -Color-Blue">        &quot;valid&quot;: {</span>
<span class=" -Color -Color-Blue">            &quot;TrainingInputMode&quot;: &quot;File&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;S3DistributionType&quot;: &quot;FullyReplicated&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;RecordWrapperType&quot;: &quot;None&quot;</span>
<span class=" -Color -Color-Blue">        }</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;input_dir&quot;: &quot;/opt/ml/input&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;instance_groups&quot;: [</span>
<span class=" -Color -Color-Blue">        &quot;homogeneousCluster&quot;</span>
<span class=" -Color -Color-Blue">    ],</span>
<span class=" -Color -Color-Blue">    &quot;instance_groups_dict&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;homogeneousCluster&quot;: {</span>
<span class=" -Color -Color-Blue">            &quot;instance_group_name&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">            &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">                &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">            ]</span>
<span class=" -Color -Color-Blue">        }</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;is_hetero&quot;: false,</span>
<span class=" -Color -Color-Blue">    &quot;is_master&quot;: true,</span>
<span class=" -Color -Color-Blue">    &quot;is_modelparallel_enabled&quot;: null,</span>
<span class=" -Color -Color-Blue">    &quot;job_name&quot;: &quot;sagemaker-merlin-tensorflow-2022-10-27-17-04-57-249&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;log_level&quot;: 20,</span>
<span class=" -Color -Color-Blue">    &quot;master_hostname&quot;: &quot;algo-1&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;model_dir&quot;: &quot;/opt/ml/model&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;module_dir&quot;: &quot;s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-27-17-04-57-249/source/sourcedir.tar.gz&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;module_name&quot;: &quot;train&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;network_interface_name&quot;: &quot;eth0&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;num_cpus&quot;: 4,</span>
<span class=" -Color -Color-Blue">    &quot;num_gpus&quot;: 1,</span>
<span class=" -Color -Color-Blue">    &quot;output_data_dir&quot;: &quot;/opt/ml/output/data&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;output_dir&quot;: &quot;/opt/ml/output&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;output_intermediate_dir&quot;: &quot;/opt/ml/output/intermediate&quot;,</span>
<span class=" -Color -Color-Blue">    &quot;resource_config&quot;: {</span>
<span class=" -Color -Color-Blue">        &quot;current_host&quot;: &quot;algo-1&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;current_instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;current_group_name&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">        &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">            &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">        ],</span>
<span class=" -Color -Color-Blue">        &quot;instance_groups&quot;: [</span>
<span class=" -Color -Color-Blue">            {</span>
<span class=" -Color -Color-Blue">                &quot;instance_group_name&quot;: &quot;homogeneousCluster&quot;,</span>
<span class=" -Color -Color-Blue">                &quot;instance_type&quot;: &quot;ml.g4dn.xlarge&quot;,</span>
<span class=" -Color -Color-Blue">                &quot;hosts&quot;: [</span>
<span class=" -Color -Color-Blue">                    &quot;algo-1&quot;</span>
<span class=" -Color -Color-Blue">                ]</span>
<span class=" -Color -Color-Blue">            }</span>
<span class=" -Color -Color-Blue">        ],</span>
<span class=" -Color -Color-Blue">        &quot;network_interface_name&quot;: &quot;eth0&quot;</span>
<span class=" -Color -Color-Blue">    },</span>
<span class=" -Color -Color-Blue">    &quot;user_entry_point&quot;: &quot;train.py&quot;</span>
<span class=" -Color -Color-Blue">}</span>
<span class=" -Color -Color-Blue">Environment variables:</span>
<span class=" -Color -Color-Blue">SM_HOSTS=[&quot;algo-1&quot;]</span>
<span class=" -Color -Color-Blue">SM_NETWORK_INTERFACE_NAME=eth0</span>
<span class=" -Color -Color-Blue">SM_HPS={&quot;batch_size&quot;:1024,&quot;epoch&quot;:10}</span>
<span class=" -Color -Color-Blue">SM_USER_ENTRY_POINT=train.py</span>
<span class=" -Color -Color-Blue">SM_FRAMEWORK_PARAMS={}</span>
<span class=" -Color -Color-Blue">SM_RESOURCE_CONFIG={&quot;current_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;current_host&quot;:&quot;algo-1&quot;,&quot;current_instance_type&quot;:&quot;ml.g4dn.xlarge&quot;,&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_groups&quot;:[{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}],&quot;network_interface_name&quot;:&quot;eth0&quot;}</span>
<span class=" -Color -Color-Blue">SM_INPUT_DATA_CONFIG={&quot;train&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;},&quot;valid&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;}}</span>
<span class=" -Color -Color-Blue">SM_OUTPUT_DATA_DIR=/opt/ml/output/data</span>
<span class=" -Color -Color-Blue">SM_CHANNELS=[&quot;train&quot;,&quot;valid&quot;]</span>
<span class=" -Color -Color-Blue">SM_CURRENT_HOST=algo-1</span>
<span class=" -Color -Color-Blue">SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge</span>
<span class=" -Color -Color-Blue">SM_CURRENT_INSTANCE_GROUP=homogeneousCluster</span>
<span class=" -Color -Color-Blue">SM_CURRENT_INSTANCE_GROUP_HOSTS=[&quot;algo-1&quot;]</span>
<span class=" -Color -Color-Blue">SM_INSTANCE_GROUPS=[&quot;homogeneousCluster&quot;]</span>
<span class=" -Color -Color-Blue">SM_INSTANCE_GROUPS_DICT={&quot;homogeneousCluster&quot;:{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}}</span>
<span class=" -Color -Color-Blue">SM_DISTRIBUTION_INSTANCE_GROUPS=[]</span>
<span class=" -Color -Color-Blue">SM_IS_HETERO=false</span>
<span class=" -Color -Color-Blue">SM_MODULE_NAME=train</span>
<span class=" -Color -Color-Blue">SM_LOG_LEVEL=20</span>
<span class=" -Color -Color-Blue">SM_FRAMEWORK_MODULE=</span>
<span class=" -Color -Color-Blue">SM_INPUT_DIR=/opt/ml/input</span>
<span class=" -Color -Color-Blue">SM_INPUT_CONFIG_DIR=/opt/ml/input/config</span>
<span class=" -Color -Color-Blue">SM_OUTPUT_DIR=/opt/ml/output</span>
<span class=" -Color -Color-Blue">SM_NUM_CPUS=4</span>
<span class=" -Color -Color-Blue">SM_NUM_GPUS=1</span>
<span class=" -Color -Color-Blue">SM_MODEL_DIR=/opt/ml/model</span>
<span class=" -Color -Color-Blue">SM_MODULE_DIR=s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-27-17-04-57-249/source/sourcedir.tar.gz</span>
<span class=" -Color -Color-Blue">SM_TRAINING_ENV={&quot;additional_framework_parameters&quot;:{},&quot;channel_input_dirs&quot;:{&quot;train&quot;:&quot;/opt/ml/input/data/train&quot;,&quot;valid&quot;:&quot;/opt/ml/input/data/valid&quot;},&quot;current_host&quot;:&quot;algo-1&quot;,&quot;current_instance_group&quot;:&quot;homogeneousCluster&quot;,&quot;current_instance_group_hosts&quot;:[&quot;algo-1&quot;],&quot;current_instance_type&quot;:&quot;ml.g4dn.xlarge&quot;,&quot;distribution_hosts&quot;:[],&quot;distribution_instance_groups&quot;:[],&quot;framework_module&quot;:null,&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;hyperparameters&quot;:{&quot;batch_size&quot;:1024,&quot;epoch&quot;:10},&quot;input_config_dir&quot;:&quot;/opt/ml/input/config&quot;,&quot;input_data_config&quot;:{&quot;train&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;},&quot;valid&quot;:{&quot;RecordWrapperType&quot;:&quot;None&quot;,&quot;S3DistributionType&quot;:&quot;FullyReplicated&quot;,&quot;TrainingInputMode&quot;:&quot;File&quot;}},&quot;input_dir&quot;:&quot;/opt/ml/input&quot;,&quot;instance_groups&quot;:[&quot;homogeneousCluster&quot;],&quot;instance_groups_dict&quot;:{&quot;homogeneousCluster&quot;:{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}},&quot;is_hetero&quot;:false,&quot;is_master&quot;:true,&quot;is_modelparallel_enabled&quot;:null,&quot;job_name&quot;:&quot;sagemaker-merlin-tensorflow-2022-10-27-17-04-57-249&quot;,&quot;log_level&quot;:20,&quot;master_hostname&quot;:&quot;algo-1&quot;,&quot;model_dir&quot;:&quot;/opt/ml/model&quot;,&quot;module_dir&quot;:&quot;s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-27-17-04-57-249/source/sourcedir.tar.gz&quot;,&quot;module_name&quot;:&quot;train&quot;,&quot;network_interface_name&quot;:&quot;eth0&quot;,&quot;num_cpus&quot;:4,&quot;num_gpus&quot;:1,&quot;output_data_dir&quot;:&quot;/opt/ml/output/data&quot;,&quot;output_dir&quot;:&quot;/opt/ml/output&quot;,&quot;output_intermediate_dir&quot;:&quot;/opt/ml/output/intermediate&quot;,&quot;resource_config&quot;:{&quot;current_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;current_host&quot;:&quot;algo-1&quot;,&quot;current_instance_type&quot;:&quot;ml.g4dn.xlarge&quot;,&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_groups&quot;:[{&quot;hosts&quot;:[&quot;algo-1&quot;],&quot;instance_group_name&quot;:&quot;homogeneousCluster&quot;,&quot;instance_type&quot;:&quot;ml.g4dn.xlarge&quot;}],&quot;network_interface_name&quot;:&quot;eth0&quot;},&quot;user_entry_point&quot;:&quot;train.py&quot;}</span>
<span class=" -Color -Color-Blue">SM_USER_ARGS=[&quot;--batch_size&quot;,&quot;1024&quot;,&quot;--epoch&quot;,&quot;10&quot;]</span>
<span class=" -Color -Color-Blue">SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate</span>
<span class=" -Color -Color-Blue">SM_CHANNEL_TRAIN=/opt/ml/input/data/train</span>
<span class=" -Color -Color-Blue">SM_CHANNEL_VALID=/opt/ml/input/data/valid</span>
<span class=" -Color -Color-Blue">SM_HP_BATCH_SIZE=1024</span>
<span class=" -Color -Color-Blue">SM_HP_EPOCH=10</span>
<span class=" -Color -Color-Blue">PYTHONPATH=/opt/ml/code:/usr/local/bin:/opt/tritonserver:/usr/local/lib/python3.8/dist-packages:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages/faiss-1.7.2-py3.8.egg:/usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg:/usr/local/lib/python3.8/dist-packages/merlin_hps-1.0.0-py3.8-linux-x86_64.egg:/usr/lib/python3/dist-packages</span>
<span class=" -Color -Color-Blue">Invoking script with the following command:</span>
<span class=" -Color -Color-Blue">/usr/bin/python3 train.py --batch_size 1024 --epoch 10</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:16,602 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.</span>

2022-10-27 17:16:26 Training - Training image download completed. Training in progress.<span class=" -Color -Color-Blue">2022-10-27 17:16:24.235067: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:30.062651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:30.064245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:30.064471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:30.101024: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX</span>
<span class=" -Color -Color-Blue">To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:30.102734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:30.103022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:30.103228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:35.192756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:35.193037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:35.193276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span>
<span class=" -Color -Color-Blue">2022-10-27 17:16:35.194420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10752 MB memory:  -&gt; device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5</span>
<span class=" -Color -Color-Blue">Workflow saved to /tmp/tmp9xoq76au/workflow.</span>
<span class=" -Color -Color-Blue">batch_size = 1024, epochs = 10</span>
<span class=" -Color -Color-Blue">Epoch 1/10</span>
<span class=" -Color -Color-Blue">684/684 - 18s - loss: 0.6932 - auc: 0.5010 - regularization_loss: 0.0000e+00 - val_loss: 0.6932 - val_auc: 0.5009 - val_regularization_loss: 0.0000e+00 - 18s/epoch - 26ms/step</span>
<span class=" -Color -Color-Blue">Epoch 2/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6931 - auc: 0.5080 - regularization_loss: 0.0000e+00 - val_loss: 0.6932 - val_auc: 0.5004 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 15ms/step</span>
<span class=" -Color -Color-Blue">Epoch 3/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6905 - auc: 0.5347 - regularization_loss: 0.0000e+00 - val_loss: 0.6965 - val_auc: 0.4982 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 15ms/step</span>
<span class=" -Color -Color-Blue">Epoch 4/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6830 - auc: 0.5579 - regularization_loss: 0.0000e+00 - val_loss: 0.7020 - val_auc: 0.4982 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 14ms/step</span>
<span class=" -Color -Color-Blue">Epoch 5/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6774 - auc: 0.5689 - regularization_loss: 0.0000e+00 - val_loss: 0.7069 - val_auc: 0.4984 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 14ms/step</span>
<span class=" -Color -Color-Blue">Epoch 6/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6742 - auc: 0.5739 - regularization_loss: 0.0000e+00 - val_loss: 0.7118 - val_auc: 0.4984 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 15ms/step</span>
<span class=" -Color -Color-Blue">Epoch 7/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6715 - auc: 0.5765 - regularization_loss: 0.0000e+00 - val_loss: 0.7210 - val_auc: 0.4978 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 15ms/step</span>
<span class=" -Color -Color-Blue">Epoch 8/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6697 - auc: 0.5781 - regularization_loss: 0.0000e+00 - val_loss: 0.7341 - val_auc: 0.4977 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 15ms/step</span>
<span class=" -Color -Color-Blue">Epoch 9/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6686 - auc: 0.5796 - regularization_loss: 0.0000e+00 - val_loss: 0.7434 - val_auc: 0.4980 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 15ms/step</span>
<span class=" -Color -Color-Blue">Epoch 10/10</span>
<span class=" -Color -Color-Blue">684/684 - 10s - loss: 0.6679 - auc: 0.5803 - regularization_loss: 0.0000e+00 - val_loss: 0.7546 - val_auc: 0.4984 - val_regularization_loss: 0.0000e+00 - 10s/epoch - 15ms/step</span>
<span class=" -Color -Color-Blue">/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn&#39;t match a supported version!</span>
<span class=" -Color -Color-Blue">  warnings.warn(&quot;urllib3 ({}) or chardet ({}) doesn&#39;t match a supported &quot;</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.</span>
<span class=" -Color -Color-Blue">Model saved to /tmp/tmp9xoq76au/dlrm.</span>
<span class=" -Color -Color-Blue">INFO:__main__:Model saved to /tmp/tmp9xoq76au/dlrm.</span>
<span class=" -Color -Color-Blue">WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.USER: &#39;user&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [&lt;Tags.ITEM: &#39;item&#39;&gt;, &lt;Tags.ID: &#39;id&#39;&gt;].</span>
<span class=" -Color -Color-Blue">  warnings.warn(</span>
<span class=" -Color -Color-Blue">WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.</span>
<span class=" -Color -Color-Blue">WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.</span>
<span class=" -Color -Color-Blue">WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.</span>
<span class=" -Color -Color-Blue">INFO:__main__:Ensemble graph saved to /opt/ml/model.</span>
<span class=" -Color -Color-Blue">Ensemble graph saved to /opt/ml/model.</span>
<span class=" -Color -Color-Blue">2022-10-27 17:19:12,767 sagemaker-training-toolkit INFO     Reporting training SUCCESS</span>

2022-10-27 17:19:33 Uploading - Uploading generated training model
2022-10-27 17:19:33 Completed - Training job completed
Training seconds: 700
Billable seconds: 700
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">model_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-27-17-04-57-249/output/model.tar.gz
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> aws s3 cp <span class="o">{</span>estimator.model_data<span class="o">}</span> /tmp/ensemble/
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>download: s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-27-17-04-57-249/output/model.tar.gz to ../../../../tmp/ensemble/model.tar.gz
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> <span class="nb">cd</span> /tmp/ensemble <span class="o">&amp;&amp;</span> tar xvzf model.tar.gz
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ensemble_model/
ensemble_model/config.pbtxt
ensemble_model/1/
0_transformworkflow/
0_transformworkflow/config.pbtxt
0_transformworkflow/1/
0_transformworkflow/1/workflow/
0_transformworkflow/1/workflow/metadata.json
0_transformworkflow/1/workflow/workflow.pkl
0_transformworkflow/1/workflow/categories/
0_transformworkflow/1/workflow/categories/unique.user_gender.parquet
0_transformworkflow/1/workflow/categories/unique.user_age.parquet
0_transformworkflow/1/workflow/categories/unique.user_categories.parquet
0_transformworkflow/1/workflow/categories/unique.user_group.parquet
0_transformworkflow/1/workflow/categories/unique.user_geography.parquet
0_transformworkflow/1/workflow/categories/unique.user_intentions.parquet
0_transformworkflow/1/workflow/categories/unique.item_shop.parquet
0_transformworkflow/1/workflow/categories/unique.user_brands.parquet
0_transformworkflow/1/workflow/categories/unique.item_id.parquet
0_transformworkflow/1/workflow/categories/unique.user_is_occupied.parquet
0_transformworkflow/1/workflow/categories/unique.user_consumption_2.parquet
0_transformworkflow/1/workflow/categories/unique.user_profile.parquet
0_transformworkflow/1/workflow/categories/unique.user_shops.parquet
0_transformworkflow/1/workflow/categories/unique.item_category.parquet
0_transformworkflow/1/workflow/categories/unique.user_id.parquet
0_transformworkflow/1/workflow/categories/unique.item_brand.parquet
0_transformworkflow/1/model.py
1_predicttensorflow/
1_predicttensorflow/config.pbtxt
1_predicttensorflow/1/
1_predicttensorflow/1/model.savedmodel/
1_predicttensorflow/1/model.savedmodel/variables/
1_predicttensorflow/1/model.savedmodel/variables/variables.index
1_predicttensorflow/1/model.savedmodel/variables/variables.data-00000-of-00001
1_predicttensorflow/1/model.savedmodel/saved_model.pb
1_predicttensorflow/1/model.savedmodel/keras_metadata.pb
1_predicttensorflow/1/model.savedmodel/assets/
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="part-3-retrieving-recommendations-from-triton-inference-server">
<h2>Part 3: Retrieving Recommendations from Triton Inference Server<a class="headerlink" href="#part-3-retrieving-recommendations-from-triton-inference-server" title="Permalink to this headline"></a></h2>
<p>Although we use the Sagemaker Python SDK to train our model, here we will use <code class="docutils literal notranslate"><span class="pre">boto3</span></code> to launch our inference endpoint as it offers more low-level control than the Python SDK.</p>
<p>The model artificat <code class="docutils literal notranslate"><span class="pre">model.tar.gz</span></code> uploaded to S3 from the Sagemaker training job contained three directories: <code class="docutils literal notranslate"><span class="pre">0_transformworkflow</span></code> for the NVTabular workflow, <code class="docutils literal notranslate"><span class="pre">1_predicttensorflow</span></code> for the Tensorflow model, and <code class="docutils literal notranslate"><span class="pre">ensemble_model</span></code> for the ensemble graph that we can use in Triton.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>/tmp/ensemble/
├── 0_transformworkflow
│   ├── <span class="m">1</span>
│   │   ├── model.py
│   │   └── workflow
│   │       ├── categories
│   │       │   ├── unique.item_brand.parquet
│   │       │   ├── unique.item_category.parquet
│   │       │   ├── unique.item_id.parquet
│   │       │   ├── unique.item_shop.parquet
│   │       │   ├── unique.user_age.parquet
│   │       │   ├── unique.user_brands.parquet
│   │       │   ├── unique.user_categories.parquet
│   │       │   ├── unique.user_consumption_2.parquet
│   │       │   ├── unique.user_gender.parquet
│   │       │   ├── unique.user_geography.parquet
│   │       │   ├── unique.user_group.parquet
│   │       │   ├── unique.user_id.parquet
│   │       │   ├── unique.user_intentions.parquet
│   │       │   ├── unique.user_is_occupied.parquet
│   │       │   ├── unique.user_profile.parquet
│   │       │   └── unique.user_shops.parquet
│   │       ├── metadata.json
│   │       └── workflow.pkl
│   └── config.pbtxt
├── 1_predicttensorflow
│   ├── <span class="m">1</span>
│   │   └── model.savedmodel
│   │       ├── assets
│   │       ├── keras_metadata.pb
│   │       ├── saved_model.pb
│   │       └── variables
│   │           ├── variables.data-00000-of-00001
│   │           └── variables.index
│   └── config.pbtxt
├── ensemble_model
│   ├── <span class="m">1</span>
│   └── config.pbtxt
└── model.tar.gz
</pre></div>
</div>
<p>We specify that we only want to use <code class="docutils literal notranslate"><span class="pre">ensemble_model</span></code> in Triton by passing the environment variable <code class="docutils literal notranslate"><span class="pre">SAGEMAKER_TRITON_DEFAULT_MODEL_NAME</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">sm_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="n">service_name</span><span class="o">=</span><span class="s2">&quot;sagemaker&quot;</span><span class="p">)</span>

<span class="n">container</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Image&quot;</span><span class="p">:</span> <span class="n">ecr_image</span><span class="p">,</span>
    <span class="s2">&quot;ModelDataUrl&quot;</span><span class="p">:</span> <span class="n">estimator</span><span class="o">.</span><span class="n">model_data</span><span class="p">,</span>
    <span class="s2">&quot;Environment&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;SAGEMAKER_TRITON_TENSORFLOW_VERSION&quot;</span><span class="p">:</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span>
        <span class="s2">&quot;SAGEMAKER_TRITON_DEFAULT_MODEL_NAME&quot;</span><span class="p">:</span> <span class="s2">&quot;ensemble_model&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;model-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span>
    <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">create_model_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span>
    <span class="n">ModelName</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">ExecutionRoleArn</span><span class="o">=</span><span class="n">role</span><span class="p">,</span> <span class="n">PrimaryContainer</span><span class="o">=</span><span class="n">container</span>
<span class="p">)</span>

<span class="n">model_arn</span> <span class="o">=</span> <span class="n">create_model_response</span><span class="p">[</span><span class="s2">&quot;ModelArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model Arn: </span><span class="si">{</span><span class="n">model_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model Arn: arn:aws:sagemaker:us-east-1:843263297212:model/model-triton-merlin-ensemble-2022-10-27-17-20-08
</pre></div>
</div>
</div>
</div>
<p>We again use the <code class="docutils literal notranslate"><span class="pre">g4dn</span></code> GPU instance that are equipped with NVIDIA T4 GPUs for launching the Triton inference server.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint_instance_type</span> <span class="o">=</span> <span class="s2">&quot;ml.g4dn.xlarge&quot;</span>

<span class="n">endpoint_config_name</span> <span class="o">=</span> <span class="s2">&quot;endpoint-config-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span>
    <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">create_endpoint_config_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_endpoint_config</span><span class="p">(</span>
    <span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span><span class="p">,</span>
    <span class="n">ProductionVariants</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;InstanceType&quot;</span><span class="p">:</span> <span class="n">endpoint_instance_type</span><span class="p">,</span>
            <span class="s2">&quot;InitialVariantWeight&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;InitialInstanceCount&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;ModelName&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
            <span class="s2">&quot;VariantName&quot;</span><span class="p">:</span> <span class="s2">&quot;AllTraffic&quot;</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="n">endpoint_config_arn</span> <span class="o">=</span> <span class="n">create_endpoint_config_response</span><span class="p">[</span><span class="s2">&quot;EndpointConfigArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Config Arn: </span><span class="si">{</span><span class="n">endpoint_config_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Endpoint Config Arn: arn:aws:sagemaker:us-east-1:843263297212:endpoint-config/endpoint-config-triton-merlin-ensemble-2022-10-27-17-20-09
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint_name</span> <span class="o">=</span> <span class="s2">&quot;endpoint-triton-merlin-ensemble-&quot;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span>
    <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">-%H-%M-%S&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">gmtime</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">create_endpoint_response</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">create_endpoint</span><span class="p">(</span>
    <span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span> <span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span>
<span class="p">)</span>

<span class="n">endpoint_arn</span> <span class="o">=</span> <span class="n">create_endpoint_response</span><span class="p">[</span><span class="s2">&quot;EndpointArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Arn: </span><span class="si">{</span><span class="n">endpoint_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Endpoint Arn: arn:aws:sagemaker:us-east-1:843263297212:endpoint/endpoint-triton-merlin-ensemble-2022-10-27-17-20-09
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">status</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">describe_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)[</span><span class="s2">&quot;EndpointStatus&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Creation Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">while</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;Creating&quot;</span><span class="p">:</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">sm_client</span><span class="o">.</span><span class="n">describe_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">rv</span><span class="p">[</span><span class="s2">&quot;EndpointStatus&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Creation Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">endpoint_arn</span> <span class="o">=</span> <span class="n">rv</span><span class="p">[</span><span class="s2">&quot;EndpointArn&quot;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Arn: </span><span class="si">{</span><span class="n">endpoint_arn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Endpoint Status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: Creating
Endpoint Creation Status: InService
Endpoint Arn: arn:aws:sagemaker:us-east-1:843263297212:endpoint/endpoint-triton-merlin-ensemble-2022-10-27-17-20-09
Endpoint Status: InService
</pre></div>
</div>
</div>
</div>
<div class="section" id="send-a-request-to-triton-inference-server-to-transform-a-raw-dataset">
<h3>Send a Request to Triton Inference Server to Transform a Raw Dataset<a class="headerlink" href="#send-a-request-to-triton-inference-server-to-transform-a-raw-dataset" title="Permalink to this headline"></a></h3>
<p>Once we have an endpoint running, we can test it by sending requests.
Here, we use the raw validation set and transform it using the saved NVTabular workflow we have downloaded from S3 in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.schema.tags</span> <span class="kn">import</span> <span class="n">Tags</span>
<span class="kn">from</span> <span class="nn">merlin.core.dispatch</span> <span class="kn">import</span> <span class="n">get_lib</span>
<span class="kn">from</span> <span class="nn">nvtabular.workflow</span> <span class="kn">import</span> <span class="n">Workflow</span>

<span class="n">df_lib</span> <span class="o">=</span> <span class="n">get_lib</span><span class="p">()</span>

<span class="n">workflow</span> <span class="o">=</span> <span class="n">Workflow</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/tmp/ensemble/0_transformworkflow/1/workflow/&quot;</span><span class="p">)</span>

<span class="n">label_columns</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">TARGET</span><span class="p">)</span><span class="o">.</span><span class="n">column_names</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">remove_inputs</span><span class="p">(</span><span class="n">label_columns</span><span class="p">)</span>

<span class="c1"># read in data for request</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">df_lib</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;part.0.parquet&quot;</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
<span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                     user_id  item_id  item_category  item_shop  item_brand  \
__null_dask_index__                                                           
700000                    66       43            147      10304        3549   
700001                     7       31            105       7360        2535   
700002                     8        9             28       1963         676   
700003                    25        6             18       1227         423   
700004                    56       13             42       2944        1014   
700005                   226       26             88       6134        2113   
700006                     3       14             46       3190        1099   
700007                    81       28             95       6624        2282   
700008                    15        7             21       1472         507   
700009                    39       42            143      10059        3465   

                     user_shops  user_profile  user_group  user_gender  \
__null_dask_index__                                                      
700000                     3267             3           1            1   
700001                      302             1           1            1   
700002                      352             1           1            1   
700003                     1207             2           1            1   
700004                     2764             3           1            1   
700005                    11308            10           2            1   
700006                      101             1           1            1   
700007                     4021             4           1            1   
700008                      704             1           1            1   
700009                     1910             2           1            1   

                     user_age  user_consumption_2  user_is_occupied  \
__null_dask_index__                                                   
700000                      1                   1                 1   
700001                      1                   1                 1   
700002                      1                   1                 1   
700003                      1                   1                 1   
700004                      1                   1                 1   
700005                      1                   1                 1   
700006                      1                   1                 1   
700007                      1                   1                 1   
700008                      1                   1                 1   
700009                      1                   1                 1   

                     user_geography  user_intentions  user_brands  \
__null_dask_index__                                                 
700000                            1              946         1624   
700001                            1               88          150   
700002                            1              102          175   
700003                            1              350          600   
700004                            1              800         1374   
700005                            1             3273         5620   
700006                            1               30           50   
700007                            1             1164         1998   
700008                            1              204          350   
700009                            1              553          950   

                     user_categories  
__null_dask_index__                   
700000                           171  
700001                            16  
700002                            19  
700003                            63  
700004                           145  
700005                           590  
700006                             6  
700007                           210  
700008                            37  
700009                           100  
</pre></div>
</div>
</div>
</div>
<p>In the following code cell, we use a utility function provided in <a class="reference external" href="https://github.com/NVIDIA-Merlin/systems">Merlin Systems</a> to convert our dataframe to the payload format that can be used as inference request format for Triton.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.triton</span> <span class="kn">import</span> <span class="n">convert_df_to_triton_input</span>
<span class="kn">import</span> <span class="nn">tritonclient.http</span> <span class="k">as</span> <span class="nn">httpclient</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">convert_df_to_triton_input</span><span class="p">(</span><span class="n">workflow</span><span class="o">.</span><span class="n">input_schema</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferInput</span><span class="p">)</span>

<span class="n">request_body</span><span class="p">,</span> <span class="n">header_length</span> <span class="o">=</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="o">.</span><span class="n">generate_request_body</span><span class="p">(</span>
    <span class="n">inputs</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">request_body</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b&#39;{&quot;inputs&quot;:[{&quot;name&quot;:&quot;user_id&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;item_id&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;item_category&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;item_shop&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;item_brand&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_shops&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_profile&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_group&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_gender&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_age&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_consumption_2&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_is_occupied&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_geography&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_intentions&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_brands&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}},{&quot;name&quot;:&quot;user_categories&quot;,&quot;shape&quot;:[10,1],&quot;datatype&quot;:&quot;INT32&quot;,&quot;parameters&quot;:{&quot;binary_data_size&quot;:40}}],&quot;parameters&quot;:{&quot;binary_data_output&quot;:true}}B\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\x19\x00\x00\x008\x00\x00\x00\xe2\x00\x00\x00\x03\x00\x00\x00Q\x00\x00\x00\x0f\x00\x00\x00\&#39;\x00\x00\x00+\x00\x00\x00\x1f\x00\x00\x00\t\x00\x00\x00\x06\x00\x00\x00\r\x00\x00\x00\x1a\x00\x00\x00\x0e\x00\x00\x00\x1c\x00\x00\x00\x07\x00\x00\x00*\x00\x00\x00\x93\x00\x00\x00i\x00\x00\x00\x1c\x00\x00\x00\x12\x00\x00\x00*\x00\x00\x00X\x00\x00\x00.\x00\x00\x00_\x00\x00\x00\x15\x00\x00\x00\x8f\x00\x00\x00@(\x00\x00\xc0\x1c\x00\x00\xab\x07\x00\x00\xcb\x04\x00\x00\x80\x0b\x00\x00\xf6\x17\x00\x00v\x0c\x00\x00\xe0\x19\x00\x00\xc0\x05\x00\x00K\&#39;\x00\x00\xdd\r\x00\x00\xe7\t\x00\x00\xa4\x02\x00\x00\xa7\x01\x00\x00\xf6\x03\x00\x00A\x08\x00\x00K\x04\x00\x00\xea\x08\x00\x00\xfb\x01\x00\x00\x89\r\x00\x00\xc3\x0c\x00\x00.\x01\x00\x00`\x01\x00\x00\xb7\x04\x00\x00\xcc\n\x00\x00,,\x00\x00e\x00\x00\x00\xb5\x0f\x00\x00\xc0\x02\x00\x00v\x07\x00\x00\x03\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\n\x00\x00\x00\x01\x00\x00\x00\x04\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\xb2\x03\x00\x00X\x00\x00\x00f\x00\x00\x00^\x01\x00\x00 \x03\x00\x00\xc9\x0c\x00\x00\x1e\x00\x00\x00\x8c\x04\x00\x00\xcc\x00\x00\x00)\x02\x00\x00X\x06\x00\x00\x96\x00\x00\x00\xaf\x00\x00\x00X\x02\x00\x00^\x05\x00\x00\xf4\x15\x00\x002\x00\x00\x00\xce\x07\x00\x00^\x01\x00\x00\xb6\x03\x00\x00\xab\x00\x00\x00\x10\x00\x00\x00\x13\x00\x00\x00?\x00\x00\x00\x91\x00\x00\x00N\x02\x00\x00\x06\x00\x00\x00\xd2\x00\x00\x00%\x00\x00\x00d\x00\x00\x00&#39;
</pre></div>
</div>
</div>
</div>
<p>Triton uses the <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/protocol/README.md">KServe community standard inference protocols</a>.
Here, we use the <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/protocol/extension_binary_data.md">binary+json format</a> for optimal performance in the inference request.</p>
<p>In order for Triton to correctly parse the binary payload, we have to specify the length of the request metadata in the header <code class="docutils literal notranslate"><span class="pre">json-header-size</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">runtime_sm_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s2">&quot;sagemaker-runtime&quot;</span><span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">runtime_sm_client</span><span class="o">.</span><span class="n">invoke_endpoint</span><span class="p">(</span>
    <span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span>
    <span class="n">ContentType</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;application/vnd.sagemaker-triton.binary+json;json-header-size=</span><span class="si">{</span><span class="n">header_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">Body</span><span class="o">=</span><span class="n">request_body</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Parse json header size length from the response</span>
<span class="n">header_length_prefix</span> <span class="o">=</span> <span class="s2">&quot;application/vnd.sagemaker-triton.binary+json;json-header-size=&quot;</span>
<span class="n">header_length_str</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;ContentType&quot;</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">header_length_prefix</span><span class="p">)</span> <span class="p">:]</span>

<span class="c1"># Read response body</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">httpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="o">.</span><span class="n">parse_response_body</span><span class="p">(</span>
    <span class="n">response</span><span class="p">[</span><span class="s2">&quot;Body&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">header_length</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">header_length_str</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="s2">&quot;click/binary_classification_task&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;predicted sigmoid result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">output_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>predicted sigmoid result:
 [[0.54874367]
 [0.47998998]
 [0.4931008 ]
 [0.49097434]
 [0.46077013]
 [0.50256795]
 [0.5188403 ]
 [0.41781098]
 [0.4932457 ]
 [0.570881  ]]
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="terminate-endpoint-and-clean-up-artifacts">
<h2>Terminate endpoint and clean up artifacts<a class="headerlink" href="#terminate-endpoint-and-clean-up-artifacts" title="Permalink to this headline"></a></h2>
<p>Don’t forget to clean up artifacts and terminate the endpoint, or the endpoint will continue to incur costs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_client</span><span class="o">.</span><span class="n">delete_model</span><span class="p">(</span><span class="n">ModelName</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">sm_client</span><span class="o">.</span><span class="n">delete_endpoint_config</span><span class="p">(</span><span class="n">EndpointConfigName</span><span class="o">=</span><span class="n">endpoint_config_name</span><span class="p">)</span>
<span class="n">sm_client</span><span class="o">.</span><span class="n">delete_endpoint</span><span class="p">(</span><span class="n">EndpointName</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;ResponseMetadata&#39;: {&#39;RequestId&#39;: &#39;84f6f8a7-3d1f-4e5c-a3c8-c555195c958f&#39;,
  &#39;HTTPStatusCode&#39;: 200,
  &#39;HTTPHeaders&#39;: {&#39;x-amzn-requestid&#39;: &#39;84f6f8a7-3d1f-4e5c-a3c8-c555195c958f&#39;,
   &#39;content-type&#39;: &#39;application/x-amz-json-1.1&#39;,
   &#39;content-length&#39;: &#39;0&#39;,
   &#39;date&#39;: &#39;Thu, 27 Oct 2022 17:27:17 GMT&#39;},
  &#39;RetryAttempts&#39;: 0}}
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>