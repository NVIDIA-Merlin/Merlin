Merlin Inference Support Matrix
===============================

This container enables you to deploy NVTabular workflows and HugeCTR or TensorFlow
models to the Triton Inference Server for production.

.. include:: ../generated/nvcr.io-nvidia-merlin-merlin-inference.rst

