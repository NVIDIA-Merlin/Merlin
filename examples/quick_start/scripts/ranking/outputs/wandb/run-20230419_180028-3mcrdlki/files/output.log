INFO:root:TARGETS: {<Task.BINARY_CLASSIFICATION: 'binary_classification'>: ['is_clicked']}
INFO:root:Starting to train the model
[34m[1mwandb[39m[22m: [33mWARNING[39m Unable to compute FLOPs for this model.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0667s vs `on_train_batch_end` time: 0.1509s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0667s vs `on_train_batch_end` time: 0.1509s). Check your callbacks.
10/10 [==============================] - ETA: 0s - loss: 2.9781 - auc: 0.4789 - prauc: 0.1656 - logloss: 0.5941 - regularization_loss: 1.9024 - loss_batch: 2.9781
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.
INFO:root:Starting the evaluation of the model
INFO:root:EVALUATION METRICS: {'loss': 2.370023488998413, 'auc': 0.6258885860443115, 'prauc': 0.27826350927352905, 'logloss': 0.6431499123573303, 'regularization_loss': 1.7268733978271484, 'loss_batch': 2.3702914714813232}
INFO:root:Finished training / evaluation / prediction
10/10 [==============================] - 11s 449ms/step - loss: 2.9781 - auc: 0.4789 - prauc: 0.1656 - logloss: 0.5941 - regularization_loss: 1.8864 - loss_batch: 2.9592 - val_loss: 2.3700 - val_auc: 0.6259 - val_prauc: 0.2783 - val_logloss: 0.6431 - val_regularization_loss: 1.7269 - val_loss_batch: 2.3703
2/2 [==============================] - 1s 63ms/step - loss: 2.3700 - auc: 0.6259 - prauc: 0.2783 - logloss: 0.6431 - regularization_loss: 1.7269 - loss_batch: 2.3702