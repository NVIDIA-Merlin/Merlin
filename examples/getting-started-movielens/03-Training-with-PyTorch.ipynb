{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-03-training-with-pytorch/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Getting Started MovieLens: Training with PyTorch\n",
    "\n",
    "This notebook is created using the latest stable [merlin-pytorch-training](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-pytorch-training/tags) container.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We observed that PyTorch training pipelines can be slow as the dataloader is a bottleneck. The native dataloader in PyTorch randomly samples each item from the dataset, which is very slow. In our experiments, we are able to speed-up existing PyTorch pipelines using a highly optimized dataloader.<br><br>\n",
    "\n",
    "In this tutorial we will be using the highly optimized Merlin Dataloader. To learn more about it, please consult the examples in its repository [here](https://github.com/NVIDIA-Merlin/dataloader/tree/main/examples).\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "This notebook explains, how to use the NVTabular dataloader to accelerate PyTorch training.\n",
    "\n",
    "1. Use **Merlin dataloader** with PyTorch\n",
    "2. Leverage **multi-hot encoded input features**\n",
    "\n",
    "### MovieLens25M\n",
    "\n",
    "The [MovieLens25M](https://grouplens.org/datasets/movielens/25m/) is a popular dataset for recommender systems and is used in academic publications. The dataset contains 25M movie ratings for 62,000 movies given by 162,000 users. Many projects use only the user/item/rating information of MovieLens, but the original dataset provides metadata for the movies, as well. For example, which genres a movie has. Although we may not improve state-of-the-art results with our neural network architecture, the purpose of this notebook is to explain how to integrate multi-hot categorical features into a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# External dependencies\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import nvtabular as nvt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our base directory, containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\n",
    "    \"INPUT_DATA_DIR\", os.path.expanduser(\"~/nvt-examples/movielens/data/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the data schema and differentiate between single-hot and multi-hot categorical features. Note, that we do not have any numerical input features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024 * 32  # Batch Size\n",
    "CATEGORICAL_COLUMNS = [\"userId\", \"movieId\"]  # Single-hot\n",
    "CATEGORICAL_MH_COLUMNS = [\"genres\"]  # Multi-hot\n",
    "NUMERIC_COLUMNS = []\n",
    "\n",
    "# Output from ETL-with-NVTabular\n",
    "TRAIN_PATHS = sorted(glob.glob(os.path.join(INPUT_DATA_DIR, \"train\", \"*.parquet\")))\n",
    "VALID_PATHS = sorted(glob.glob(os.path.join(INPUT_DATA_DIR, \"valid\", \"*.parquet\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we used NVTabular for ETL and stored the workflow to disk. We can load the NVTabular workflow to extract important metadata for our training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = nvt.Workflow.load(os.path.join(INPUT_DATA_DIR, \"workflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding table shows the cardinality of each categorical variable along with its associated embedding size. Each entry is of the form `(cardinality, embedding_size)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': (162542, 512), 'movieId': (56615, 512)}, {'genres': (21, 16)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_TABLE_SHAPES, MH_EMBEDDING_TABLE_SHAPES = nvt.ops.get_embedding_sizes(proc)\n",
    "EMBEDDING_TABLE_SHAPES, MH_EMBEDDING_TABLE_SHAPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing NVTabular Dataloader for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import PyTorch and the Merlin Dataloader for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from merlin.loader.torch import Loader\n",
    "\n",
    "# from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
    "from nvtabular.framework_utils.torch.models import Model\n",
    "from nvtabular.framework_utils.torch.utils import process_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take a look on our dataloader and how the data is represented as tensors. The NVTabular dataloaders are initialized as usual and we specify both single-hot and multi-hot categorical features as cats. The dataloader can automatically recognize the single/multi-hot columns and represent them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 'rating'\n",
    "\n",
    "\n",
    "def process_batch(data, _):\n",
    "    x = {col: data[col] for col in data.keys() if col != label_column}\n",
    "    y = data[label_column]\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "train_loader = Loader(\n",
    "    nvt.Dataset(TRAIN_PATHS),\n",
    "    batch_size=BATCH_SIZE,\n",
    ").map(process_batch)\n",
    "\n",
    "\n",
    "\n",
    "valid_loader = Loader(\n",
    "    nvt.Dataset(VALID_PATHS),\n",
    "    batch_size=BATCH_SIZE,\n",
    ").map(process_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a batch and take a look on the input features.<br><br>\n",
    "The single-hot categorical features (`userId` and `movieId`) have a shape of `(32768, 1)`, which is the batch size (as usually).\n",
    "\n",
    "For the multi-hot categorical feature `genres`, we receive a tuple of two Tensors. The first tensor are the actual data, containing the genre IDs. Note that the Tensor has more values than the batch_size. The reason is that one datapoint in the batch can contain more than one genre (multi-hot).\n",
    "\n",
    "The second tensor is a supporting Tensor, describing how many genres are associated with each datapoint in the batch.\n",
    "\n",
    "For example,\n",
    "- if the first two values in the second tensor are `0`, `2`, then the first 2 values (0, 1) in the first tensor are associated with the first datapoint in the batch (movieId/userId).\n",
    "- if the next value in the second tensor is `6`, then the 3rd, 4th and 5th value in the first tensor are associated with the second datapoint in the batch (continuing after the previous value stopped). \n",
    "- if the third value in the second tensor is `7`, then the 6th value in the first tensor is associated with the third datapoint in the batch. \n",
    "- and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'genres': (tensor([ 1, 11,  4,  ..., 11,  8,  4], device='cuda:0'),\n",
       "   tensor([[    0],\n",
       "           [    3],\n",
       "           [    6],\n",
       "           ...,\n",
       "           [88688],\n",
       "           [88691],\n",
       "           [88693]], device='cuda:0', dtype=torch.int32)),\n",
       "  'userId': tensor([[ 31056],\n",
       "          [  7087],\n",
       "          [  1696],\n",
       "          ...,\n",
       "          [ 54140],\n",
       "          [ 40743],\n",
       "          [120070]], device='cuda:0'),\n",
       "  'movieId': tensor([[ 285],\n",
       "          [  87],\n",
       "          [4594],\n",
       "          ...,\n",
       "          [1928],\n",
       "          [1313],\n",
       "          [ 747]], device='cuda:0')},\n",
       " tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each datapoint can have a different number of genres, it is more efficient to represent the genres as two flat tensors: One with the actual values (the first tensor) and one with the length for each datapoint (the second tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del batch\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented a simple PyTorch architecture.\n",
    "\n",
    "* Single-hot categorical features are fed into an Embedding Layer\n",
    "* Each value of a multi-hot categorical features is fed into an Embedding Layer and the multiple Embedding outputs are combined via summing\n",
    "* The output of the Embedding Layers are concatenated\n",
    "* The concatenated layers are fed through multiple feed-forward layers (Dense Layers, BatchNorm with ReLU activations)\n",
    "\n",
    "You can see more details by checking out the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the model. `EMBEDDING_TABLE_SHAPES` needs to be a Tuple representing the cardinality for single-hot and multi-hot input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': (162542, 512), 'movieId': (56615, 512)}, {'genres': (21, 16)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_TABLE_SHAPES_TUPLE = (\n",
    "    {\n",
    "        CATEGORICAL_COLUMNS[0]: EMBEDDING_TABLE_SHAPES[CATEGORICAL_COLUMNS[0]],\n",
    "        CATEGORICAL_COLUMNS[1]: EMBEDDING_TABLE_SHAPES[CATEGORICAL_COLUMNS[1]],\n",
    "    },\n",
    "    {CATEGORICAL_MH_COLUMNS[0]: MH_EMBEDDING_TABLE_SHAPES[CATEGORICAL_MH_COLUMNS[0]]},\n",
    ")\n",
    "EMBEDDING_TABLE_SHAPES_TUPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (initial_cat_layer): ConcatenatedEmbeddings(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): Embedding(162542, 512)\n",
       "      (1): Embedding(56615, 512)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (mh_cat_layer): MultiHotEmbeddings(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): EmbeddingBag(21, 16, mode=sum)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (initial_cont_layer): BatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=1040, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(\n",
    "    embedding_table_shapes=EMBEDDING_TABLE_SHAPES_TUPLE,\n",
    "    num_continuous=0,\n",
    "    emb_dropout=0.0,\n",
    "    layer_hidden_dims=[128, 128, 128],\n",
    "    layer_dropout_rates=[0.0, 0.0, 0.0],\n",
    ").to(\"cuda\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `process_epoch` function to train and validate our model. It iterates over the dataset and calculates as usually the loss and optimizer step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 610\n",
      "Total batches: 152\n",
      "Epoch 00. Train loss: 0.1909. Valid loss: 0.1694.\n",
      "CPU times: user 17 s, sys: 351 ms, total: 17.3 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import time\n",
    "EPOCHS = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time()\n",
    "    train_loss, y_pred, y = process_epoch(train_loader,\n",
    "                                          model,\n",
    "                                          train=True,\n",
    "                                          optimizer=optimizer)\n",
    "    valid_loss, y_pred, y = process_epoch(valid_loader,\n",
    "                                          model,\n",
    "                                          train=False)\n",
    "    print(f\"Epoch {epoch:02d}. Train loss: {train_loss:.4f}. Valid loss: {valid_loss:.4f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-pytorch-training:latest"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
