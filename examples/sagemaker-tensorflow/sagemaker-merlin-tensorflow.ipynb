{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361e6bb6-1d68-4797-a2b5-d87d164995cc",
   "metadata": {},
   "source": [
    "### Permissions\n",
    "\n",
    "Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because it creates new repositories on Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ba6bc5-f6ea-4d35-88f9-23683826e45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
      "\n",
      "RUN pip3 install sagemaker-training\n",
      "\n",
      "COPY train.py /opt/ml/code/train.py\n",
      "COPY serve /opt/ml/code/serve\n",
      "\n",
      "ENV SAGEMAKER_PROGRAM train.py\n",
      "\n",
      "EXPOSE 8080\n"
     ]
    }
   ],
   "source": [
    "! cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e40ffca-b651-413f-ac64-43f44a01e7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "set -euo pipefail\n",
      "\n",
      "# The name of our algorithm\n",
      "ALGORITHM_NAME=sagemaker-merlin-tensorflow\n",
      "REGION=us-east-1\n",
      "\n",
      "cd container\n",
      "\n",
      "ACCOUNT=$(aws sts get-caller-identity --query Account --output text --region ${REGION})\n",
      "\n",
      "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
      "\n",
      "REPOSITORY=\"${ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com\"\n",
      "IMAGE_URI=\"${REPOSITORY}/${ALGORITHM_NAME}:latest\"\n",
      "\n",
      "# Get the login command from ECR and execute it directly\n",
      "aws ecr get-login-password --region ${REGION} | docker login --username AWS --password-stdin ${REPOSITORY}\n",
      "\n",
      "# If the repository doesn't exist in ECR, create it.\n",
      "\n",
      "aws ecr describe-repositories --repository-names \"${ALGORITHM_NAME}\" --region ${REGION} > /dev/null 2>&1\n",
      "\n",
      "if [ $? -ne 0 ]\n",
      "then\n",
      "    aws ecr create-repository --repository-name \"${ALGORITHM_NAME}\" --region ${REGION} > /dev/null\n",
      "fi\n",
      "\n",
      "# Build the docker image locally with the image name and then push it to ECR\n",
      "# with the full name.\n",
      "\n",
      "docker build  -t ${ALGORITHM_NAME} .\n",
      "docker tag ${ALGORITHM_NAME} ${IMAGE_URI}\n",
      "\n",
      "docker push ${IMAGE_URI}\n"
     ]
    }
   ],
   "source": [
    "! cat build_and_push_image.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0e7947-60d0-4130-8819-021118a8ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name AWSOS-AD-Engineer to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::843263297212:role/AWSOS-AD-Engineer\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be9695-161e-4b53-abf3-728995fc8c79",
   "metadata": {},
   "source": [
    "We use the synthetic train and test datasets generated by mimicking the real Ali-CCP: Alibaba Click and Conversion Prediction dataset to build our recommender system ranking models.\n",
    "\n",
    "If you would like to use real Ali-CCP dataset instead, you can download the training and test datasets on tianchi.aliyun.com. You can then use get_aliccp() function to curate the raw csv files and save them as parquet files.\n",
    "\n",
    "\n",
    "```python\n",
    "from merlin.datasets.synthetic import generate_data\n",
    "\n",
    "DATA_FOLDER = os.environ.get(\"DATA_FOLDER\", \"/workspace/data/aliccp-raw-synthetic\")\n",
    "NUM_ROWS = os.environ.get(\"NUM_ROWS\", 1000000)\n",
    "SYNTHETIC_DATA = eval(os.environ.get(\"SYNTHETIC_DATA\", \"True\"))\n",
    "BATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\", 512))\n",
    "\n",
    "if SYNTHETIC_DATA:\n",
    "    train, valid = generate_data(\"aliccp-raw\", int(NUM_ROWS), set_sizes=(0.7, 0.3))\n",
    "    # save the datasets as parquet files\n",
    "    train.to_ddf().to_parquet(os.path.join(DATA_FOLDER, \"train\"))\n",
    "    valid.to_ddf().to_parquet(os.path.join(DATA_FOLDER, \"valid\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683bdac5-5d26-4e07-b23d-72a2a6a55e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"/workspace/data/aliccp-raw-synthetic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2ba473-90fc-4644-aea4-87e3c84eb405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  valid\n"
     ]
    }
   ],
   "source": [
    "! ls {DATA_DIRECTORY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b96348-dd30-4691-8beb-9723d67afee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = \"DEMO-merlin-tensorflow-aliccp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea36f4c-8fe3-44f4-a340-91923c7f6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40105894-6aa2-4346-a912-21cbd5881f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = sess.upload_data(DATA_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f67ed27-a0ea-4a8f-b4f7-c0457c1d90a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-843263297212/DEMO-merlin-tensorflow-aliccp\n"
     ]
    }
   ],
   "source": [
    "print(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1b93db-8bd1-4487-9cdf-220c81961be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3553, in cuda._cuda.ccuda._cuInit\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 424, in cuda._cuda.ccuda.cuPythonInit\n",
      "RuntimeError: Failed to dlopen libcuda.so\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3553, in cuda._cuda.ccuda._cuInit\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 424, in cuda._cuda.ccuda.cuPythonInit\n",
      "RuntimeError: Failed to dlopen libcuda.so\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/utils/gpu_utils.py:62: UserWarning: Function \"cuDeviceGetCount\" not found\n",
      "  warnings.warn(str(e))\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "2022-10-15 04:09:20.161588: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2022-10-15 04:09:21.157425: W tensorflow/stream_executor/platform/default/dso_loader.cc:65] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/hugectr/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/lib:/repos/dist/lib:/opt/tritonserver/lib\n",
      "2022-10-15 04:09:21.157446: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-15 04:09:21.157458: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-10-15 04:09:21.167132: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/utils/gpu_utils.py:62: UserWarning: Function \"cuDeviceGetCount\" not found\n",
      "  warnings.warn(str(e))\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "Exception ignored in: 'cuda._lib.ccudart.utils.cudaPythonGlobal.lazyInit'\n",
      "Traceback (most recent call last):\n",
      "  File \"cuda/_cuda/ccuda.pyx\", line 3556, in cuda._cuda.ccuda._cuInit\n",
      "RuntimeError: Function \"cuInit\" not found\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:251: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:251: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "Workflow saved to /tmp/workflow.\n",
      "batch_size = 512, epochs = 2\n",
      "Epoch 1/2\n",
      "1368/1368 - 12s - loss: 0.6932 - auc: 0.5003 - regularization_loss: 0.0000e+00 - val_loss: 0.6932 - val_auc: 0.4995 - val_regularization_loss: 0.0000e+00 - 12s/epoch - 9ms/step\n",
      "Epoch 2/2\n",
      "1368/1368 - 8s - loss: 0.6932 - auc: 0.5020 - regularization_loss: 0.0000e+00 - val_loss: 0.6931 - val_auc: 0.5010 - val_regularization_loss: 0.0000e+00 - 8s/epoch - 6ms/step\n",
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\n",
      "Model saved to /tmp/dlrm.\n",
      "INFO:__main__:Model saved to /tmp/dlrm.\n",
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\n",
      "Ensemble graph saved to /tmp/ensemble.\n",
      "INFO:__main__:Ensemble graph saved to /tmp/ensemble.\n"
     ]
    }
   ],
   "source": [
    "! python3 container/train.py \\\n",
    "    --train_dir=/workspace/data/aliccp_raw_synthetic/train/ \\\n",
    "    --valid_dir=/workspace/data/aliccp_raw_synthetic/valid/ \\\n",
    "    --model_dir=/tmp \\\n",
    "    --batch_size=512 \\\n",
    "    --epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b9fc54-bafa-4487-8f34-2f9448c0b3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843263297212.dkr.ecr.us-east-1.amazonaws.com/sagemaker-merlin-tensorflow:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sts\")\n",
    "account = client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = \"sagemaker-merlin-tensorflow\"\n",
    "\n",
    "ecr_image = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f238c8c6-656e-4b3d-96c6-32654357fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-15 04:25:17 Starting - Starting the training job...\n",
      "2022-10-15 04:25:40 Starting - Insufficient capacity error from EC2 while launching instances, retrying!ProfilerReport-1665807916: InProgress\n",
      "......\n",
      "2022-10-15 04:26:42 Starting - Preparing the instances for training.........\n",
      "2022-10-15 04:28:26 Downloading - Downloading input data\n",
      "2022-10-15 04:28:26 Training - Downloading the training image.......................................\n",
      "2022-10-15 04:35:22 Training - Training image download completed. Training in progress.\u001b[34m==================================\u001b[0m\n",
      "\u001b[34m== Triton Inference Server Base ==\u001b[0m\n",
      "\u001b[34m==================================\u001b[0m\n",
      "\u001b[34mNVIDIA Release 22.08 (build 42766143)\u001b[0m\n",
      "\u001b[34mCopyright (c) 2018-2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\u001b[0m\n",
      "\u001b[34mVarious files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\u001b[0m\n",
      "\u001b[34mThis container image and its contents are governed by the NVIDIA Deep Learning Container License.\u001b[0m\n",
      "\u001b[34mBy pulling and using the container, you accept the terms and conditions of this license:\u001b[0m\n",
      "\u001b[34mhttps://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\u001b[0m\n",
      "\u001b[34mNOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.7 driver version 515.65.01 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:17,120 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"valid\": \"/opt/ml/input/data/valid\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 1024,\n",
      "        \"epoch\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"sagemaker-merlin-tensorflow-2022-10-15-04-25-15-157\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":1024,\"epoch\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"valid\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"valid\":\"/opt/ml/input/data/valid\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":1024,\"epoch\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"sagemaker-merlin-tensorflow-2022-10-15-04-25-15-157\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"1024\",\"--epoch\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALID=/opt/ml/input/data/valid\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=1024\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/opt/tritonserver:/usr/local/lib/python3.8/dist-packages:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages/faiss-1.7.2-py3.8.egg:/usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg:/usr/local/lib/python3.8/dist-packages/merlin_hps-1.0.0-py3.8-linux-x86_64.egg:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --batch_size 1024 --epoch 10\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:17,121 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:27.782979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:27.784713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:27.784968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:27.825713: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:27.827663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:27.827976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:27.828185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:31.778352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:31.778705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:31.778980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[34m2022-10-15 04:35:31.779919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11468 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\u001b[0m\n",
      "\u001b[34mWorkflow saved to /opt/ml/model/workflow.\u001b[0m\n",
      "\u001b[34mbatch_size = 1024, epochs = 10\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n",
      "\u001b[34m684/684 - 18s - loss: 0.6932 - auc: 0.4996 - regularization_loss: 0.0000e+00 - val_loss: 0.6931 - val_auc: 0.4997 - val_regularization_loss: 0.0000e+00 - 18s/epoch - 26ms/step\u001b[0m\n",
      "\u001b[34mEpoch 2/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6932 - auc: 0.5015 - regularization_loss: 0.0000e+00 - val_loss: 0.6932 - val_auc: 0.5002 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34mEpoch 3/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6928 - auc: 0.5137 - regularization_loss: 0.0000e+00 - val_loss: 0.6939 - val_auc: 0.5010 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34mEpoch 4/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6882 - auc: 0.5414 - regularization_loss: 0.0000e+00 - val_loss: 0.6977 - val_auc: 0.5000 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34mEpoch 5/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6808 - auc: 0.5612 - regularization_loss: 0.0000e+00 - val_loss: 0.7022 - val_auc: 0.4999 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34mEpoch 6/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6762 - auc: 0.5698 - regularization_loss: 0.0000e+00 - val_loss: 0.7076 - val_auc: 0.4993 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 15ms/step\u001b[0m\n",
      "\u001b[34mEpoch 7/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6732 - auc: 0.5740 - regularization_loss: 0.0000e+00 - val_loss: 0.7203 - val_auc: 0.4998 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34mEpoch 8/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6707 - auc: 0.5764 - regularization_loss: 0.0000e+00 - val_loss: 0.7289 - val_auc: 0.4995 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34mEpoch 9/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6693 - auc: 0.5780 - regularization_loss: 0.0000e+00 - val_loss: 0.7468 - val_auc: 0.4994 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34mEpoch 10/10\u001b[0m\n",
      "\u001b[34m684/684 - 11s - loss: 0.6683 - auc: 0.5793 - regularization_loss: 0.0000e+00 - val_loss: 0.7550 - val_auc: 0.4993 - val_regularization_loss: 0.0000e+00 - 11s/epoch - 16ms/step\u001b[0m\n",
      "\u001b[34m/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model saved to /opt/ml/model/dlrm.\u001b[0m\n",
      "\u001b[34mModel saved to /opt/ml/model/dlrm.\u001b[0m\n",
      "\u001b[34mWARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\u001b[0m\n",
      "\u001b[34mWARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mEnsemble graph saved to /opt/ml/model/ensemble.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Ensemble graph saved to /opt/ml/model/ensemble.\u001b[0m\n",
      "\u001b[34m2022-10-15 04:38:16,480 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-10-15 04:38:43 Uploading - Uploading generated training model\n",
      "2022-10-15 04:38:43 Completed - Training job completed\n",
      "Training seconds: 624\n",
      "Billable seconds: 624\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "instance_type = \"ml.p3.2xlarge\"  # GPU instance, V100\n",
    "#instance_type = \"ml.g4dn.xlarge\"\n",
    "\n",
    "estimator = Estimator(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    image_uri=ecr_image,\n",
    "    hyperparameters={\n",
    "        \"batch_size\": 1_024,\n",
    "        \"epoch\": 10, \n",
    "    },\n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    {\n",
    "        \"train\": f\"{data_location}/train/\",\n",
    "        \"valid\": f\"{data_location}/valid/\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d44a96bd-a6ab-4ff7-9232-9e0f0c330ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-15-04-25-15-157/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(estimator.model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d6d979-1976-46dd-bf88-669bbad39ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-843263297212/sagemaker-merlin-tensorflow-2022-10-15-04-25-15-157/output/model.tar.gz to ../../../../tmp/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp {estimator.model_data} /tmp/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d90341dc-8c5a-4500-acf8-1491664cd426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble/\n",
      "ensemble/0_transformworkflow/\n",
      "ensemble/0_transformworkflow/1/\n",
      "ensemble/0_transformworkflow/1/model.py\n",
      "ensemble/0_transformworkflow/1/workflow/\n",
      "ensemble/0_transformworkflow/1/workflow/metadata.json\n",
      "ensemble/0_transformworkflow/1/workflow/workflow.pkl\n",
      "ensemble/0_transformworkflow/1/workflow/categories/\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_brands.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_shops.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_group.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_intentions.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_profile.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_geography.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.item_shop.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_is_occupied.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_consumption_2.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_categories.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.item_id.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.item_category.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_id.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.item_brand.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_gender.parquet\n",
      "ensemble/0_transformworkflow/1/workflow/categories/unique.user_age.parquet\n",
      "ensemble/0_transformworkflow/config.pbtxt\n",
      "ensemble/ensemble_model/\n",
      "ensemble/ensemble_model/1/\n",
      "ensemble/ensemble_model/config.pbtxt\n",
      "ensemble/1_predicttensorflow/\n",
      "ensemble/1_predicttensorflow/1/\n",
      "ensemble/1_predicttensorflow/1/model.savedmodel/\n",
      "ensemble/1_predicttensorflow/1/model.savedmodel/saved_model.pb\n",
      "ensemble/1_predicttensorflow/1/model.savedmodel/assets/\n",
      "ensemble/1_predicttensorflow/1/model.savedmodel/keras_metadata.pb\n",
      "ensemble/1_predicttensorflow/1/model.savedmodel/variables/\n",
      "ensemble/1_predicttensorflow/1/model.savedmodel/variables/variables.data-00000-of-00001\n",
      "ensemble/1_predicttensorflow/1/model.savedmodel/variables/variables.index\n",
      "ensemble/1_predicttensorflow/config.pbtxt\n",
      "workflow/\n",
      "workflow/metadata.json\n",
      "workflow/workflow.pkl\n",
      "workflow/categories/\n",
      "workflow/categories/unique.user_brands.parquet\n",
      "workflow/categories/unique.user_shops.parquet\n",
      "workflow/categories/unique.user_group.parquet\n",
      "workflow/categories/unique.user_intentions.parquet\n",
      "workflow/categories/unique.user_profile.parquet\n",
      "workflow/categories/unique.user_geography.parquet\n",
      "workflow/categories/unique.item_shop.parquet\n",
      "workflow/categories/unique.user_is_occupied.parquet\n",
      "workflow/categories/unique.user_consumption_2.parquet\n",
      "workflow/categories/unique.user_categories.parquet\n",
      "workflow/categories/unique.item_id.parquet\n",
      "workflow/categories/unique.item_category.parquet\n",
      "workflow/categories/unique.user_id.parquet\n",
      "workflow/categories/unique.item_brand.parquet\n",
      "workflow/categories/unique.user_gender.parquet\n",
      "workflow/categories/unique.user_age.parquet\n",
      "dlrm/\n",
      "dlrm/saved_model.pb\n",
      "dlrm/assets/\n",
      "dlrm/keras_metadata.pb\n",
      "dlrm/variables/\n",
      "dlrm/variables/variables.data-00000-of-00001\n",
      "dlrm/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "! tar -tf /tmp/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aaa86d7-093e-4bdc-a606-a730c1bf9a5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m container \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m: ecr_image,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelDataUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m: estimator\u001b[38;5;241m.\u001b[39mmodel_data,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#\"Environment\": {\"SAGEMAKER_TRITON_DEFAULT_MODEL_NAME\": \"ensemble_dali_inception\"},\u001b[39;00m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m sm_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriton-merlin-tensorflow-ensemble-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mgmtime())\n\u001b[0;32m---> 11\u001b[0m create_model_response \u001b[38;5;241m=\u001b[39m sm_client\u001b[38;5;241m.\u001b[39mcreate_model(\n\u001b[1;32m     12\u001b[0m     ModelName\u001b[38;5;241m=\u001b[39msm_model_name, ExecutionRoleArn\u001b[38;5;241m=\u001b[39mrole, PrimaryContainer\u001b[38;5;241m=\u001b[39mcontainer\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m model_arn \u001b[38;5;241m=\u001b[39m create_model_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelArn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Arn: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_arn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sm_client' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "container = {\n",
    "    \"Image\": ecr_image,\n",
    "    \"ModelDataUrl\": estimator.model_data,\n",
    "    #\"Environment\": {\"SAGEMAKER_TRITON_DEFAULT_MODEL_NAME\": \"ensemble_dali_inception\"},\n",
    "}\n",
    "\n",
    "sm_model_name = \"triton-merlin-tensorflow-ensemble-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Model Arn: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cade896-0e92-42ff-b507-96a82a248814",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "endpoint_config_arn = create_endpoint_config_response[\"EndpointConfigArn\"]\n",
    "\n",
    "print(f\"Endpoint Config Arn: {endpoint_config_arn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
