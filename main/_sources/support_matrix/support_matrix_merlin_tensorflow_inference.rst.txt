Merlin TensorFlow Inference Support Matrix
==========================================

This container enables you to deploy NVTabular workflows and TensorFlow
models to the Triton Inference Server for production.

TensorFlow is not included in the container.
The container includes a backend for TensorFlow that Triton Inference Server uses to execute TensorFlow models.

.. include:: ../generated/nvcr.io-nvidia-merlin-merlin-tensorflow-inference.rst

