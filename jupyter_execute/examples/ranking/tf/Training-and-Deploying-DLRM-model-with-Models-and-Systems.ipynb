{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc80cfdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51acf955",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models_04-exporting-ranking-models/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Exporting Ranking Models\n",
    "\n",
    "This notebook is created using the latest stable [merlin-tensorflow](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags) container. \n",
    "\n",
    "In this example notebook we demonstrate how to export (save) NVTabular `workflow` and a `ranking model` for model deployment with [Merlin Systems](https://github.com/NVIDIA-Merlin/systems) library. \n",
    "\n",
    "Learning Objectives:\n",
    "\n",
    "- Export NVTabular workflow for model deployment\n",
    "- Export TensorFlow DLRM model for model deployment\n",
    "- Load saved NVTabular Workflow\n",
    "- Load saved trained Merlin Models model\n",
    "- Create Ensemble Graph\n",
    "- Export Ensemble Graph\n",
    "- Deploy model on Triton Inference Server\n",
    "\n",
    "We will follow the steps below:\n",
    "- Prepare the data with NVTabular and export NVTabular workflow\n",
    "- Train a DLRM model with Merlin Models and export the trained model\n",
    "- Launch Triton server and deploy trained models on Triton\n",
    "- Send request to Triton and receive back the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4fec3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab14a7d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start with importing the libraries that we'll use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d5020c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 21:03:00.600621: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "[INFO]: sparse_operation_kit is imported\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.2.0-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.2.0-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Initialize finished, communication tool: horovod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 21:03:07.070258: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-06-28 21:03:07.070303: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-06-28 21:03:07.070448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16249 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:2d:00.0, compute capability: 7.0\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "import numpy as np\n",
    "\n",
    "from merlin.models.utils.example_utils import workflow_fit_transform\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb650a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature Engineering with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c715cd5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use the synthetic train and test datasets generated by mimicking the real [Ali-CCP: Alibaba Click and Conversion Prediction](https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1) dataset to build our recommender system ranking models. \n",
    "\n",
    "If you would like to use real Ali-CCP dataset instead, you can download the training and test datasets on [tianchi.aliyun.com](https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1). You can then use [get_aliccp()](https://github.com/NVIDIA-Merlin/models/blob/stable/merlin/datasets/ecommerce/aliccp/dataset.py#L43) function to curate the raw csv files and save them as parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c7457b-08c4-4453-bacc-5c8eef7042d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.datasets.synthetic import generate_data\n",
    "\n",
    "DATA_FOLDER = os.environ.get(\"DATA_FOLDER\", \"/workspace/data/\")\n",
    "NUM_ROWS = os.environ.get(\"NUM_ROWS\", 1000000)\n",
    "SYNTHETIC_DATA = eval(os.environ.get(\"SYNTHETIC_DATA\", \"True\"))\n",
    "BATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\", 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6651cc8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if SYNTHETIC_DATA:\n",
    "    train, valid = generate_data(\"aliccp-raw\", int(NUM_ROWS), set_sizes=(0.8, 0.2))\n",
    "    # save the datasets as parquet files\n",
    "    train.to_ddf().to_parquet(os.path.join(DATA_FOLDER, \"train\"))\n",
    "    valid.to_ddf().to_parquet(os.path.join(DATA_FOLDER, \"valid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0e794",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's define our input and output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1124f2c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(DATA_FOLDER, \"train\", \"*.parquet\")\n",
    "valid_path = os.path.join(DATA_FOLDER, \"valid\", \"*.parquet\")\n",
    "output_path = os.path.join(DATA_FOLDER, \"processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1162c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After we execute `fit()` and `transform()` functions on the raw dataset applying the operators defined in the NVTabular workflow pipeline below, the processed parquet files are saved to `output_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b3ddc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.61 s, sys: 1.09 s, total: 3.7 s\n",
      "Wall time: 3.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "category_temp_directory = os.path.join(DATA_FOLDER, \"categories\")\n",
    "user_id = [\"user_id\"] >> Categorify(out_path=category_temp_directory) >> TagAsUserID()\n",
    "item_id = [\"item_id\"] >> Categorify(out_path=category_temp_directory) >> TagAsItemID()\n",
    "targets = [\"click\"] >> AddMetadata(tags=[Tags.BINARY_CLASSIFICATION, \"target\"])\n",
    "\n",
    "item_features = [\"item_category\", \"item_shop\", \"item_brand\"] >> Categorify(out_path=category_temp_directory) >> TagAsItemFeatures()\n",
    "\n",
    "user_features = (\n",
    "    [\n",
    "        \"user_shops\",\n",
    "        \"user_profile\",\n",
    "        \"user_group\",\n",
    "        \"user_gender\",\n",
    "        \"user_age\",\n",
    "        \"user_consumption_2\",\n",
    "        \"user_is_occupied\",\n",
    "        \"user_geography\",\n",
    "        \"user_intentions\",\n",
    "        \"user_brands\",\n",
    "        \"user_categories\",\n",
    "    ]\n",
    "    >> Categorify(out_path=category_temp_directory)\n",
    "    >> TagAsUserFeatures()\n",
    ")\n",
    "\n",
    "outputs = user_id + item_id + item_features + user_features + targets\n",
    "\n",
    "workflow = nvt.Workflow(outputs)\n",
    "\n",
    "train_dataset = nvt.Dataset(train_path)\n",
    "valid_dataset = nvt.Dataset(valid_path)\n",
    "\n",
    "workflow.fit(train_dataset)\n",
    "workflow.transform(train_dataset).to_parquet(output_path=output_path + \"/train/\")\n",
    "workflow.transform(valid_dataset).to_parquet(output_path=output_path + \"/valid/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd8b10",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We save NVTabular `workflow` model in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e367206",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(DATA_FOLDER, \"workflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be619646",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's check out our saved workflow model folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e03167a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seedir in /usr/local/lib/python3.8/dist-packages (0.4.2)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.8/dist-packages (from seedir) (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeafadbe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "├─categories/\n",
      "│ └─categories/\n",
      "│   ├─meta.item_brand.parquet\n",
      "│   ├─meta.item_category.parquet\n",
      "│   ├─meta.item_id.parquet\n",
      "│   ├─meta.item_shop.parquet\n",
      "│   ├─meta.user_age.parquet\n",
      "│   ├─meta.user_brands.parquet\n",
      "│   ├─meta.user_categories.parquet\n",
      "│   ├─meta.user_consumption_2.parquet\n",
      "│   ├─meta.user_gender.parquet\n",
      "│   └─meta.user_geography.parquet\n",
      "├─dlrm/\n",
      "│ ├─.merlin/\n",
      "│ │ ├─input_schema.json\n",
      "│ │ └─output_schema.json\n",
      "│ ├─assets/\n",
      "│ ├─fingerprint.pb\n",
      "│ ├─keras_metadata.pb\n",
      "│ ├─saved_model.pb\n",
      "│ └─variables/\n",
      "│   ├─variables.data-00000-of-00001\n",
      "│   └─variables.index\n",
      "├─processed/\n",
      "│ ├─train/\n",
      "│ │ ├─.merlin/\n",
      "│ │ ├─_file_list.txt\n",
      "│ │ ├─_metadata\n",
      "│ │ ├─_metadata.json\n",
      "│ │ ├─part_0.parquet\n",
      "│ │ └─schema.pbtxt\n",
      "│ └─valid/\n",
      "│   ├─.merlin/\n",
      "│   ├─_file_list.txt\n",
      "│   ├─_metadata\n",
      "│   ├─_metadata.json\n",
      "│   ├─part_0.parquet\n",
      "│   └─schema.pbtxt\n",
      "├─train/\n",
      "│ └─part.0.parquet\n",
      "├─valid/\n",
      "│ └─part.0.parquet\n",
      "└─workflow/\n",
      "  ├─categories/\n",
      "  │ ├─unique.item_brand.parquet\n",
      "  │ ├─unique.item_category.parquet\n",
      "  │ ├─unique.item_id.parquet\n",
      "  │ ├─unique.item_shop.parquet\n",
      "  │ ├─unique.user_age.parquet\n",
      "  │ ├─unique.user_brands.parquet\n",
      "  │ ├─unique.user_categories.parquet\n",
      "  │ ├─unique.user_consumption_2.parquet\n",
      "  │ ├─unique.user_gender.parquet\n",
      "  │ └─unique.user_geography.parquet\n",
      "  ├─metadata.json\n",
      "  └─workflow.pkl\n"
     ]
    }
   ],
   "source": [
    "import seedir as sd\n",
    "\n",
    "sd.seedir(\n",
    "    DATA_FOLDER,\n",
    "    style=\"lines\",\n",
    "    itemlimit=10,\n",
    "    depthlimit=3,\n",
    "    exclude_folders=\".ipynb_checkpoints\",\n",
    "    sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8e0ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build and Train a DLRM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f24b6b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this example, we build, train, and export a Deep Learning Recommendation Model [(DLRM)](https://arxiv.org/abs/1906.00091) architecture. To learn more about how to train different deep learning models, how easily transition from one model to another and the seamless integration between data preparation and model training visit [03-Exploring-different-models.ipynb](https://github.com/NVIDIA-Merlin/models/blob/stable/examples/03-Exploring-different-models.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb8dcc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "NVTabular workflow above exports a schema file, schema.pbtxt, of our processed dataset. To learn more about the schema object, schema file  and `tags`, you can explore [02-Merlin-Models-and-NVTabular-integration.ipynb](02-Merlin-Models-and-NVTabular-integration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3a3421",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define train and valid dataset objects\n",
    "train = Dataset(os.path.join(output_path, \"train\", \"*.parquet\"))\n",
    "valid = Dataset(os.path.join(output_path, \"valid\", \"*.parquet\"))\n",
    "\n",
    "# define schema object\n",
    "schema = train.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b164b7ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'click'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = schema.select_by_tag(Tags.TARGET).column_names[0]\n",
    "target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71847bb9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = mm.DLRMModel(\n",
    "    schema,\n",
    "    embedding_dim=64,\n",
    "    bottom_block=mm.MLPBlock([128, 64]),\n",
    "    top_block=mm.MLPBlock([128, 64, 32]),\n",
    "    prediction_tasks=mm.BinaryOutput(target_column),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d009deb7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 21:03:36.828993: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6932 - auc: 0.4998 - regularization_loss: 0.0000e+00 - loss_batch: 0.6932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 21:04:40.190967: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 69s 38ms/step - loss: 0.6932 - auc: 0.4998 - regularization_loss: 0.0000e+00 - loss_batch: 0.6932 - val_loss: 0.6931 - val_auc: 0.5000 - val_regularization_loss: 0.0000e+00 - val_loss_batch: 0.6932\n",
      "CPU times: user 1min 51s, sys: 14.1 s, total: 2min 5s\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74b2a4b1c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(\"adam\", run_eagerly=False, metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit(train, validation_data=valid, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7051d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f999a063",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, prepare_list_features_layer_call_fn, prepare_list_features_layer_call_and_return_conditional_losses, dense_9_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/data/dlrm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/data/dlrm/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(DATA_FOLDER, \"dlrm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9235b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have NVTabular wokflow  and DLRM model exported, now it is time to move on to the next step: model deployment with [Merlin Systems](https://github.com/NVIDIA-Merlin/systems). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2667e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deploying the model with Merlin Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee302de0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last step of machine learning (ML)/deep learning (DL) pipeline is to deploy the ETL workflow and saved model into production. In the production setting, we want to transform the input data as done during training (ETL). We need to apply the same mean/std for continuous features and use the same categorical mapping to convert the categories to continuous integer before we use the DL model for a prediction. Therefore, we deploy the NVTabular workflow with the Tensorflow model as an ensemble model to Triton Inference using [Merlin Systems](https://github.com/NVIDIA-Merlin/systems) library very easily. The ensemble model guarantees that the same transformation is applied to the raw inputs.\n",
    "\n",
    "In the next steps, we will learn how to deploy NVTabular workflow and the trained DLRM model into [Triton Inference Server](https://github.com/triton-inference-server/server) with [Merlin Systems](https://github.com/NVIDIA-Merlin/systems) library. NVIDIA Triton Inference Server (TIS) simplifies the deployment of AI models at scale in production. TIS provides a cloud and edge inferencing solution optimized for both CPUs and GPUs. It supports a number of different machine learning frameworks such as TensorFlow and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84002b14-5be5-4896-96ac-ea058bf8b7e3",
   "metadata": {},
   "source": [
    "First, we load the `nvtabular.Workflow` that we created in with this [example](https://github.com/NVIDIA-Merlin/models/blob/stable/examples/04-Exporting-ranking-models.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6b6cf0-2867-4cce-ade6-d0d86e2f7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular.workflow import Workflow\n",
    "\n",
    "workflow = Workflow.load(os.path.join(DATA_FOLDER, \"workflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206c105-0cd2-4710-af63-a8862307b67e",
   "metadata": {},
   "source": [
    "After we load the workflow, we remove the label columns from it's inputs. This removes all columns with the TARGET tag from the workflow. We do this because we need to set the workflow to only require the features needed to predict, not train, when creating an inference pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73729623-89af-442f-82ad-0ffad6e73fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nvtabular.workflow.workflow.Workflow at 0x7f74b290f550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from merlin.schema.tags import Tags\n",
    "\n",
    "label_columns = workflow.output_schema.select_by_tag(Tags.TARGET).column_names\n",
    "workflow.remove_inputs(label_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eddb76-971c-4a69-bfda-e1fe127b2582",
   "metadata": {},
   "source": [
    "After loading the workflow, we load the model. This model was trained with the output of the workflow from the Exporting Ranking Models example from Merlin Models.\n",
    "\n",
    "First, we need to import the Merlin Models library. Loading a TensorFlow model, which is based on custom subclasses, requires to the subclass definition. Otherwise, TensorFlow cannot load correctly load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec339d34-3667-4fe2-a9f5-ecb770e5c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_path = os.path.join(DATA_FOLDER, \"dlrm\")\n",
    "\n",
    "model = tf.keras.models.load_model(tf_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b911f-4c6b-427b-a1f9-888f0f8c7613",
   "metadata": {},
   "source": [
    "### Create the Ensemble Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f74ec8-c4e7-49e7-ba86-eae2f8f0b744",
   "metadata": {},
   "source": [
    "After we have both the model and the workflow loaded, we can create the ensemble graph. You create the graph. The goal is to illustrate the path of data through your full system. In this example we only serve a workflow with a model, but you can add other components that help you meet your business logic requirements.\n",
    "\n",
    "Because this example has two components—a model and a workflow—we require two operators. These operators, also known as inference operators, are meant to abstract away all the \"hard parts\" of loading a specific component, such as a workflow or model, into Triton Inference Server.\n",
    "\n",
    "The following code block shows how to use two inference operators:\n",
    "\n",
    "- **TransformWorkflow:**<br>\n",
    "    This operator ensures that the workflow is correctly saved and packaged with the required config so the server will know how to load it.\n",
    "\n",
    "- **PredictTensorflow:**<br>\n",
    "    This operator will do something similar with the model, loaded before.\n",
    "\n",
    "Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86a951b0-1d44-456e-9dc1-d77e98223248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model_context_2_layer_call_fn, model_context_2_layer_call_and_return_conditional_losses, prepare_list_features_2_layer_call_fn, prepare_list_features_2_layer_call_and_return_conditional_losses, dense_9_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpomjyo5xq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpomjyo5xq/assets\n"
     ]
    }
   ],
   "source": [
    "from merlin.systems.dag.ops.workflow import TransformWorkflow\n",
    "from merlin.systems.dag.ops.tensorflow import PredictTensorflow\n",
    "\n",
    "serving_operators = workflow.input_schema.column_names >> TransformWorkflow(workflow) >> PredictTensorflow(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8324aa-756f-4df8-9c51-595e473b0ce5",
   "metadata": {},
   "source": [
    "### Export Graph as Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a33309-4a82-41ac-8439-2a6aa95241af",
   "metadata": {},
   "source": [
    "The last step is to create the ensemble artifacts that Triton Inference Server can consume. To make these artifacts, we import the Ensemble class. The class is responsible for interpreting the graph and exporting the correct files for the server.\n",
    "\n",
    "After you run the following cell, you'll see that we create a ColumnSchema for the expected inputs to the workflow. The workflow is a Schema.\n",
    "\n",
    "When you are creating an Ensemble object you supply the graph and a schema representing the starting input of the graph. the inputs to the ensemble graph are the inputs to the first operator of your graph.\n",
    "\n",
    "After you have created the Ensemble you export the graph, supplying an export path for the Ensemble.export function.\n",
    "\n",
    "This returns an ensemble config which represents the entire inference pipeline and a list of node-specific configs.\n",
    "\n",
    "Let's take a look below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e305ed1-4c19-470c-82c0-0635f2d1d851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ID, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>user_id</td>\n",
       "      <td>773</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_id</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM, Tags.ID)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.i...</td>\n",
       "      <td>0</td>\n",
       "      <td>789</td>\n",
       "      <td>item_id</td>\n",
       "      <td>790</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_category</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.i...</td>\n",
       "      <td>0</td>\n",
       "      <td>789</td>\n",
       "      <td>item_category</td>\n",
       "      <td>790</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>item_shop</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.i...</td>\n",
       "      <td>0</td>\n",
       "      <td>789</td>\n",
       "      <td>item_shop</td>\n",
       "      <td>790</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>item_brand</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.i...</td>\n",
       "      <td>0</td>\n",
       "      <td>789</td>\n",
       "      <td>item_brand</td>\n",
       "      <td>790</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_shops</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>user_shops</td>\n",
       "      <td>773</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_profile</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>user_profile</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user_group</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>user_group</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user_gender</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>user_gender</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user_age</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>user_age</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>user_consumption_2</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>user_consumption_2</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_is_occupied</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>user_is_occupied</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_geography</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>user_geography</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>user_intentions</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>user_intentions</td>\n",
       "      <td>773</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>user_brands</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>user_brands</td>\n",
       "      <td>773</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>user_categories</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/workspace/data/categories/categories/unique.u...</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>user_categories</td>\n",
       "      <td>773</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'user_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_id.parquet', 'domain': {'min': 0, 'max': 772, 'name': 'user_id'}, 'embedding_sizes': {'cardinality': 773, 'dimension': 66}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'item_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>, <Tags.ID: 'id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.item_id.parquet', 'domain': {'min': 0, 'max': 789, 'name': 'item_id'}, 'embedding_sizes': {'cardinality': 790, 'dimension': 67}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'item_category', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.item_category.parquet', 'domain': {'min': 0, 'max': 789, 'name': 'item_category'}, 'embedding_sizes': {'cardinality': 790, 'dimension': 67}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'item_shop', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.item_shop.parquet', 'domain': {'min': 0, 'max': 789, 'name': 'item_shop'}, 'embedding_sizes': {'cardinality': 790, 'dimension': 67}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'item_brand', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.item_brand.parquet', 'domain': {'min': 0, 'max': 789, 'name': 'item_brand'}, 'embedding_sizes': {'cardinality': 790, 'dimension': 67}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_shops', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_shops.parquet', 'domain': {'min': 0, 'max': 772, 'name': 'user_shops'}, 'embedding_sizes': {'cardinality': 773, 'dimension': 66}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_profile', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_profile.parquet', 'domain': {'min': 0, 'max': 73, 'name': 'user_profile'}, 'embedding_sizes': {'cardinality': 74, 'dimension': 18}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_group', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_group.parquet', 'domain': {'min': 0, 'max': 13, 'name': 'user_group'}, 'embedding_sizes': {'cardinality': 14, 'dimension': 16}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_gender', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_gender.parquet', 'domain': {'min': 0, 'max': 4, 'name': 'user_gender'}, 'embedding_sizes': {'cardinality': 5, 'dimension': 16}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_age', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_age.parquet', 'domain': {'min': 0, 'max': 8, 'name': 'user_age'}, 'embedding_sizes': {'cardinality': 9, 'dimension': 16}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_consumption_2', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_consumption_2.parquet', 'domain': {'min': 0, 'max': 5, 'name': 'user_consumption_2'}, 'embedding_sizes': {'cardinality': 6, 'dimension': 16}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_is_occupied', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_is_occupied.parquet', 'domain': {'min': 0, 'max': 4, 'name': 'user_is_occupied'}, 'embedding_sizes': {'cardinality': 5, 'dimension': 16}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_geography', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_geography.parquet', 'domain': {'min': 0, 'max': 6, 'name': 'user_geography'}, 'embedding_sizes': {'cardinality': 7, 'dimension': 16}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_intentions', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_intentions.parquet', 'domain': {'min': 0, 'max': 772, 'name': 'user_intentions'}, 'embedding_sizes': {'cardinality': 773, 'dimension': 66}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_brands', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_brands.parquet', 'domain': {'min': 0, 'max': 772, 'name': 'user_brands'}, 'embedding_sizes': {'cardinality': 773, 'dimension': 66}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'user_categories', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': '/workspace/data/categories/categories/unique.user_categories.parquet', 'domain': {'min': 0, 'max': 772, 'name': 'user_categories'}, 'embedding_sizes': {'cardinality': 773, 'dimension': 66}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "440ce7a2-9a6d-47aa-9506-b7027ab0ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model_context_2_layer_call_fn, model_context_2_layer_call_and_return_conditional_losses, prepare_list_features_2_layer_call_fn, prepare_list_features_2_layer_call_and_return_conditional_losses, dense_9_layer_call_fn while saving (showing 5 of 96). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from merlin.systems.dag.ensemble import Ensemble\n",
    "\n",
    "ensemble = Ensemble(serving_operators, workflow.input_schema)\n",
    "\n",
    "export_path = os.path.join(DATA_FOLDER, \"ensemble\")\n",
    "\n",
    "ens_conf, node_confs = ensemble.export(export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987010e0-fae5-48dc-9781-f68e1e0035f3",
   "metadata": {},
   "source": [
    "Display the path to the directory with the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa8da6c-1f81-4ee2-b8d2-3dca75aeaedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/ensemble\n"
     ]
    }
   ],
   "source": [
    "print(export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47dd90-39df-4c0b-849c-c06f11977512",
   "metadata": {},
   "source": [
    "### Verification of Ensemble Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09fb14-92d8-44d4-b727-91ecf0e2dd71",
   "metadata": {},
   "source": [
    "After we export the ensemble, we can check the export path for the graph's artifacts. The directory structure represents an ordering number followed by an operator identifier such as `0_transformworkflow`, `1_predicttensorflow`, and so on.\n",
    "\n",
    "Inside each of those directories, the export method writes a config.pbtxt file and a directory with a number. The number indicates the version and begins at 1. The artifacts for each operator are found inside the version folder. These artifacts vary depending on the operator in use.\n",
    "\n",
    "Install the seedir python package so we can view some of the directory contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be28d294-f9f2-4086-9d79-5bd9d93c603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble/\n",
      "├─0_transformworkflowtriton/\n",
      "│ ├─1/\n",
      "│ │ ├─model.py\n",
      "│ │ └─workflow/\n",
      "│ └─config.pbtxt\n",
      "├─1_predicttensorflowtriton/\n",
      "│ ├─1/\n",
      "│ │ └─model.savedmodel/\n",
      "│ └─config.pbtxt\n",
      "└─executor_model/\n",
      "  ├─1/\n",
      "  │ ├─ensemble/\n",
      "  │ └─model.py\n",
      "  └─config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "sd.seedir(export_path, style='lines', itemlimit=10, depthlimit=3, exclude_folders='.ipynb_checkpoints', sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bc00b-3d39-4093-90d6-6bc4c84507f9",
   "metadata": {},
   "source": [
    "### Starting Triton Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42fb70f-a9b3-4240-b190-b6e68b0c9b88",
   "metadata": {},
   "source": [
    "After we export the ensemble, we are ready to start the Triton Inference Server. The server is installed in all the Merlin inference containers. If you are not using one of our containers, then ensure it is installed in your environment. For more information, see the Triton Inference Server documentation.\n",
    "\n",
    "You can start the server by running the following command:\n",
    "```\n",
    "tritonserver --model-repository=/workspace/data/ensemble\n",
    "\n",
    "For the --model-repository argument, specify the same value as the export_path that you specified previously in the ensemble.export method.\n",
    "```\n",
    "After you run the tritonserver command, wait until your terminal shows messages like the following example:\n",
    "```\n",
    "I0414 18:29:50.741833 4067 grpc_server.cc:4421] Started GRPCInferenceService at 0.0.0.0:8001\n",
    "I0414 18:29:50.742197 4067 http_server.cc:3113] Started HTTPService at 0.0.0.0:8000\n",
    "I0414 18:29:50.783470 4067 http_server.cc:178] Started Metrics Service at 0.0.0.0:8002\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c838873-ee04-45bb-9725-01105c66956b",
   "metadata": {},
   "source": [
    "### Retrieving Recommendations from Triton Inference Server\n",
    "Now that our server is running, we can send requests to it. This request is composed of values that correspond to the request schema that was created when we exported the ensemble graph.\n",
    "\n",
    "In the code below we create a request to send to triton and send it. We will then analyze the response, to show the full experience.\n",
    "\n",
    "First we need to ensure that we have a client connected to the server that we started. To do this, we use the Triton HTTP client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc26afee-8853-4bb0-a027-68613248088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client created.\n"
     ]
    }
   ],
   "source": [
    "import tritonclient.http as client\n",
    "\n",
    "# Create a triton client\n",
    "try:\n",
    "    triton_client = client.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "    print(\"client created.\")\n",
    "except Exception as e:\n",
    "    print(\"channel creation failed: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb2d2e-60f2-4406-82aa-f040403729a3",
   "metadata": {},
   "source": [
    "After we create the client and verified it is connected to the server instance, we can communicate with the server and ensure all the models are loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b12afdf8-1e73-4eb3-9ea1-85dd4773a649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/health/live, headers None\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n",
      "POST /v2/repository/index, headers None\n",
      "\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '191'}>\n",
      "bytearray(b'[{\"name\":\"0_transformworkflowtriton\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"1_predicttensorflowtriton\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"executor_model\",\"version\":\"1\",\"state\":\"READY\"}]')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': '0_transformworkflowtriton', 'version': '1', 'state': 'READY'},\n",
       " {'name': '1_predicttensorflowtriton', 'version': '1', 'state': 'READY'},\n",
       " {'name': 'executor_model', 'version': '1', 'state': 'READY'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure triton is in a good state\n",
    "triton_client.is_server_live()\n",
    "triton_client.get_model_repository_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d5603-568f-41f4-ac0d-c5852b9f33dd",
   "metadata": {},
   "source": [
    "After verifying the models are correctly loaded by the server, we use some original, raw validation data and send it as an inference request to the server.\n",
    "\n",
    "The df_lib object is cudf if a GPU is available and pandas otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bb6aec6-0a7e-41a7-b42d-0a378c530d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_shop</th>\n",
       "      <th>item_brand</th>\n",
       "      <th>user_shops</th>\n",
       "      <th>user_profile</th>\n",
       "      <th>user_group</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_consumption_2</th>\n",
       "      <th>user_is_occupied</th>\n",
       "      <th>user_geography</th>\n",
       "      <th>user_intentions</th>\n",
       "      <th>user_brands</th>\n",
       "      <th>user_categories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__null_dask_index__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>5936</td>\n",
       "      <td>2045</td>\n",
       "      <td>1670</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>484</td>\n",
       "      <td>830</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>2850</td>\n",
       "      <td>982</td>\n",
       "      <td>1879</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>544</td>\n",
       "      <td>934</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>238</td>\n",
       "      <td>82</td>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>277</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_id  item_id  item_category  item_shop  item_brand  \\\n",
       "__null_dask_index__                                                           \n",
       "800000                    25       26             85       5936        2045   \n",
       "800001                    28       13             41       2850         982   \n",
       "800002                     9        2              4        238          82   \n",
       "\n",
       "                     user_shops  user_profile  user_group  user_gender  \\\n",
       "__null_dask_index__                                                      \n",
       "800000                     1670             2           1            1   \n",
       "800001                     1879             2           1            1   \n",
       "800002                      557             1           1            1   \n",
       "\n",
       "                     user_age  user_consumption_2  user_is_occupied  \\\n",
       "__null_dask_index__                                                   \n",
       "800000                      1                   1                 1   \n",
       "800001                      1                   1                 1   \n",
       "800002                      1                   1                 1   \n",
       "\n",
       "                     user_geography  user_intentions  user_brands  \\\n",
       "__null_dask_index__                                                 \n",
       "800000                            1              484          830   \n",
       "800001                            1              544          934   \n",
       "800002                            1              162          277   \n",
       "\n",
       "                     user_categories  \n",
       "__null_dask_index__                   \n",
       "800000                            88  \n",
       "800001                            98  \n",
       "800002                            30  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from merlin.core.dispatch import get_lib\n",
    "\n",
    "df_lib = get_lib()\n",
    "\n",
    "# read in data for request\n",
    "batch = df_lib.read_parquet(\n",
    "    os.path.join(DATA_FOLDER,\"valid\", \"part.0.parquet\"), columns=workflow.input_schema.column_names\n",
    ").head(3)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b23899-dbb4-4701-bfa3-0d21da333159",
   "metadata": {},
   "source": [
    "After we isolate our batch, we convert the dataframe representation into inputs for Triton. We also declare the outputs that we expect to receive from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "080d84dc-9c09-4d94-8ced-8d160ca88f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['click/binary_output']\n"
     ]
    }
   ],
   "source": [
    "from merlin.systems.triton import convert_df_to_triton_input\n",
    "import tritonclient.grpc as grpcclient\n",
    "# create inputs and outputs\n",
    "\n",
    "inputs = convert_df_to_triton_input(workflow.input_schema, batch, grpcclient.InferInput)\n",
    "\n",
    "output_cols = ensemble.graph.output_schema.column_names\n",
    "print(output_cols)\n",
    "\n",
    "outputs = [\n",
    "    grpcclient.InferRequestedOutput(col)\n",
    "    for col in output_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01208b4d-5478-48a3-9114-b904b2ca2167",
   "metadata": {},
   "source": [
    "Now that our inputs and outputs are created, we can use the triton_client that we created earlier to send the inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95dea3b8-92aa-41f9-a1b4-2cb516c6b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send request to tritonserver\n",
    "with grpcclient.InferenceServerClient(\"localhost:8001\") as client:\n",
    "    response = client.infer(\"executor_model\", inputs, request_id=\"1\", outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921c299-df76-45ef-9acc-5b17bc52bd3a",
   "metadata": {},
   "source": [
    "When the server completes the inference request, it returns a response, i.e. likelihood per request. This response is parsed to get the desired predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b766ef55-5661-4268-aed9-6f4096cce58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5002032]\n",
      " [0.5001995]\n",
      " [0.5001995]]\n"
     ]
    }
   ],
   "source": [
    "predictions = response.as_numpy('click/binary_output')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee5636-600a-4422-8165-f70e8e847031",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This sample notebook started with data preprocessing and model training. We learned how to create an ensemble graph, verify the ensemble artifacts in the file system, and then put the ensemble into production with Triton Inference Server. Finally, we sent a simple inference request to the server and printed the response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-tensorflow:latest"
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "a398807c5c2ed8e5ff9d9890488d007fa99cbabcec733962e21659a28c5da99b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}