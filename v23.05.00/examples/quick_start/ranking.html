

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Quick-start for ranking models with Merlin &#8212; NVIDIA Merlin</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/versions.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../_static/js/rtd-version-switcher.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/quick_start/ranking';</script>
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/examples/quick_start/ranking.html" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVJ1Y1YJHK', {
        'anonymize_ip': false,
    });
  </script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,300&display=swap" rel="stylesheet">
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">NVIDIA Merlin</p>
  
</a></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../guide/recommender_system_guide.html">Recommender System Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../guide/recommender_models.html">Recommender Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../index.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../getting-started-movielens/index.html">Getting Started using the MovieLens Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../getting-started-movielens/01-Download-Convert.html">MovieLens Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../getting-started-movielens/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../getting-started-movielens/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../getting-started-movielens/03-Training-with-TF.html">Getting Started MovieLens: Training with TensorFlow</a></li>


<li class="toctree-l3"><a class="reference internal" href="../getting-started-movielens/03-Training-with-PyTorch.html">Training with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../getting-started-movielens/04-Triton-Inference-with-HugeCTR.html">Serving the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../getting-started-movielens/04-Triton-Inference-with-TF.html">Serve Recommendations from the TensorFlow Model</a></li>

</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Building-and-deploying-multi-stage-RecSys/index.html">Deploying a Multi-Stage Recommender System</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Building-and-deploying-multi-stage-RecSys/01-Building-Recommender-Systems-with-Merlin.html">Building the Recommender System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Building-and-deploying-multi-stage-RecSys/02-Deploying-multi-stage-RecSys-with-Merlin-Systems.html">Deploying the Recommender System with Triton</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sagemaker-tensorflow/index.html">Merlin and AWS SageMaker</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sagemaker-tensorflow/sagemaker-merlin-tensorflow.html">Training and Serving Merlin on AWS SageMaker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../scaling-criteo/index.html">Scaling Large Datasets with Criteo</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../scaling-criteo/01-Download-Convert.html">Criteo Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../scaling-criteo/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../scaling-criteo/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../scaling-criteo/03-Training-with-Merlin-Models-TensorFlow.html">Training with Merlin Models and TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../scaling-criteo/04-Triton-Inference-with-HugeCTR.html">Deploy the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../scaling-criteo/04-Triton-Inference-with-Merlin-Models-TensorFlow.html">Deploy the TensorFlow Model with Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../support_matrix/index.html">Merlin Support Matrix</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../support_matrix/support_matrix_merlin_hugectr.html">Merlin HugeCTR Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../support_matrix/support_matrix_merlin_tensorflow.html">Merlin TensorFlow Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../support_matrix/support_matrix_merlin_pytorch.html">Merlin PyTorch Support Matrix</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-merlin-ecosystem-nav" aria-label="Merlin Ecosystem Nav">
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul class="nav bd-sidenav">
      <li class="toctree-l1"><a class="reference external" href="/core/v23.05.00">Core</a></li>
      <li class="toctree-l1"><a class="reference external" href="/models/v23.05.00">Models</a></li>
      <li class="toctree-l1"><a class="reference external" href="/systems/v23.05.00">Systems</a></li>
      <li class="toctree-l1"><a class="reference external" href="/NVTabular/v23.05.00">NVTabular</a></li>
      <li class="toctree-l1"><a class="reference external" href="/Transformers4Rec/v23.05.00">Transformers4Rec</a></li>
      <li class="toctree-l1"><a class="reference external" href="/dataloader/v23.05.00">Dataloader</a></li>
      <li class="toctree-l1"><a class="reference external" href="/HugetCTR/v23.05.00">HugeCTR</a></li>
    </ul>
  </div>
</nav></div>
        <div class="sidebar-primary-item">
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"></span>
    v: v23.05.00
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../v22.11.00/index.html">v22.11.00</a></dd>
      <dd><a href="../../../v22.12.00/index.html">v22.12.00</a></dd>
      <dd><a href="../../../v23.02.00/index.html">v23.02.00</a></dd>
      <dd><a href="../../../v23.04.00/index.html">v23.04.00</a></dd>
      <dd><a href="ranking.html">v23.05.00</a></dd>
      <dd><a href="../../../v23.06.00/index.html">v23.06.00</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../main/index.html">main</a></dd>
      <dd><a href="../../../stable/index.html">stable</a></dd>
    </dl>
  </div>
</div></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Quick-start for ranking models with Merlin</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-tenrec-dataset">Download the TenRec dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data">Preparing the data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-docker-container">Start Docker container</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">Preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-ranking-model">Training a ranking model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-ranking-model-with-multi-task-learning">Training a ranking model with multi-task learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-an-mmoe-model">Training an MMOE model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">Hyperparameter tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-deployment-on-triton-inference-server">Model Deployment on Triton Inference Server</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="quick-start-for-ranking-models-with-merlin">
<h1>Quick-start for ranking models with Merlin<a class="headerlink" href="#quick-start-for-ranking-models-with-merlin" title="Permalink to this heading">#</a></h1>
<p><strong>Do you want to get the best possible accuracy for your ranking problem?</strong>
<strong>This guide will teach you best practices on preprocessing data, training and hypertuning ranking models with Merlin.</strong></p>
<p>We iterate in this guide over a typical Data Science process which involves data preprocessing / feature engineering, model training and evaluation and hyperparameter tuning.</p>
<center>
<img src="images/quick_start_process.png" alt="Data science process with Merlin" >
</center>
<p>We use as example here the <a class="reference external" href="https://static.qblv.qq.com/qblv/h5/algo-frontend/tenrec_dataset.html">TenRec dataset</a>, which is large (140 million positive interactions from 5 million users), contains explicit negative feedback (items exposed to the user and not interacted) and multiple target columns (click, like, share, follow).</p>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h2>
<p>You can run these scripts either using the latest Merlin TensorFlow image or installing the necessary Merlin libraries according to their documentation (<a class="reference external" href="https://github.com/NVIDIA-Merlin/core">core</a>, <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a>, <a class="reference external" href="https://github.com/NVIDIA-Merlin/dataloader">dataloader</a>, <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/">models</a>).<br />
In this doc we provide the commands for setting up a Docker container for Merlin TensorFlow, as it provides all necessary libraries already installed.</p>
<section id="download-the-tenrec-dataset">
<h3>Download the TenRec dataset<a class="headerlink" href="#download-the-tenrec-dataset" title="Permalink to this heading">#</a></h3>
<p>You can find the TenRec dataset in this <a class="reference external" href="https://static.qblv.qq.com/qblv/h5/algo-frontend/tenrec_dataset.html">link</a>. You might switch the page language to <em>English</em> in the top-right link, if you prefer.<br />
To be able to download the data, you need first to agree with the terms an register your e-mail. After downloading the zipped file (4.2 GB) you just need to uncompress the data.</p>
</section>
</section>
<section id="preparing-the-data">
<h2>Preparing the data<a class="headerlink" href="#preparing-the-data" title="Permalink to this heading">#</a></h2>
<p>The TenRec dataset contains a number of CSV files. We will be using the <code class="docutils literal notranslate"><span class="pre">QK-video.csv</span></code>, which logs user interactions with different videos.</p>
<p>Here is an example on how the data looks like. For ranking models, you typically have user, item and contextual features and one or more targets, that can be a binary (e.g. has the customer clicked or liked and item) or regression target (e.g. watch times).</p>
<p><img alt="TenRec dataset structure" src="../../_images/tenrec_dataset.png" /></p>
<p>As <code class="docutils literal notranslate"><span class="pre">QK-video.csv</span></code> has a reasonable size (~15 GB with ~493 million examples), feel free to reduce it for less rows you want to test the pipeline more quickly or if you don’t have a powerful GPU available (V100 with 32 GB or better). For example, with the following command you can truncate the file keeping the first 10 million rows (header line included).</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">10000001</span><span class="w"> </span>QK-video.csv<span class="w"> </span>&gt;<span class="w"> </span>QK-video-10M.csv
</pre></div>
</div>
<section id="start-docker-container">
<h3>Start Docker container<a class="headerlink" href="#start-docker-container" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Pull the latest <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow">Merlin TensorFlow image</a>.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>nvcr.io/nvidia/merlin/merlin-tensorflow:latest<span class="w"> </span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Set <code class="docutils literal notranslate"><span class="pre">INPUT_DATA_PATH</span></code> variable to the folder where <code class="docutils literal notranslate"><span class="pre">QK-video.csv</span></code> was saved.<br />
The <code class="docutils literal notranslate"><span class="pre">OUTPUT_PATH</span></code> is the place where the preprocessed dataset and trained model will be saved.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">INPUT_DATA_PATH</span><span class="o">=</span>/path/to/input/dataset/
<span class="nv">OUTPUT_PATH</span><span class="o">=</span>/path/to/output/path/
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Start a Merlin TensorFlow container in interactive mode</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--ipc<span class="o">=</span>host<span class="w"> </span>-v<span class="w"> </span><span class="nv">$INPUT_DATA_PATH</span>:/data<span class="w"> </span>-v<span class="w"> </span><span class="nv">$OUTPUT_PATH</span>:/outputs<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>nvcr.io/nvidia/merlin/merlin-tensorflow:latest<span class="w"> </span>/bin/bash
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Inside the container, go to <code class="docutils literal notranslate"><span class="pre">/Merlin/examples/quick_start</span></code> folder and install the Quick-start dependencies.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/Merlin/examples/quick_start
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</section>
</section>
<section id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this heading">#</a></h2>
<p>In order to make it easy getting the data ready for model training, we provide a generic script: <a class="reference download internal" download="" href="../../_downloads/b1b6a929bb312ed88036980fc4d45ebb/preprocessing.py"><span class="xref download myst">preprocessing.py</span></a>. That script is based on <strong>dask_cudf</strong> and <strong>NVTabular</strong> libraries that leverage GPUs for accelerated and distributed preprocessing.<br />
P.s. <strong>NVTabular</strong> also supports CPU which is suitable for prototyping in dev environments.</p>
<p>The preprocessing script outputs preprocessed data as a number of parquet files, as well as a <em>schema</em> that stores output features metadata like statistics and tags.</p>
<p>In this example, we set some options for preprocessing. Here is the explanation of the main arguments; you can check the <span class="xref myst">full documentation and best practices for preprocessing</span>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--categorical_features</span></code> - Names of the categorical/discrete features (concatenated with “,” without space).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--binary_classif_targets</span></code> - Names of the available target columns for binary classification task</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--regression_targets</span></code> - Names of the available target columns for regression task</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--user_id_feature</span></code> - Name of the user id feature</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--item_id_feature</span></code> - Name of the item id feature</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--to_int32</span></code>, <code class="docutils literal notranslate"><span class="pre">--to_int16</span></code>, <code class="docutils literal notranslate"><span class="pre">--to_int8</span></code> - Allows type casting the columns to the lower possible precision, which may avoid memory issues with large datasets.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--dataset_split_strategy</span></code> - Strategy for splitting train and eval sets. In this case, <code class="docutils literal notranslate"><span class="pre">random_by_user</span></code> is chosen, which means that train and test will have the same users with some random examples reserved for evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--random_split_eval_perc</span></code> - Percentage of data to reserve for eval set</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--filter_query</span></code> - A filter query condition compatible with dask-cudf <code class="docutils literal notranslate"><span class="pre">DataFrame.query()</span></code>. In this example, we keep only examples were all targets are 0 or where click=1, to remove examples where we have other targets equals to 1, but click = 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--min_item_freq</span></code>, <code class="docutils literal notranslate"><span class="pre">--min_user_freq</span></code>, <code class="docutils literal notranslate"><span class="pre">max_user_freq</span></code> - Filters out training examples from users or items based on their min or max frequency threshold</p></li>
</ul>
<p>For larger dataset (like the full TenRec dataset), in particular when using filtering options that require dask_cudf filtering (e.g. <code class="docutils literal notranslate"><span class="pre">--filter_query</span></code>, <code class="docutils literal notranslate"><span class="pre">--min_item_freq</span></code>) we recommend using the following options to avoid out-of-memory errors:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--enable_dask_cuda_cluster</span></code> - Initializes a dask-cudf <code class="docutils literal notranslate"><span class="pre">LocalCUDACluster</span></code> for managed single or multi-GPU preprocessing</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--persist_intermediate_files</span></code> - Persists/caches to disk intermediate files during preprocessing (in paricular after filtering).</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/Merlin/examples/quick_start/scripts/preproc/
<span class="nv">OUT_DATASET_PATH</span><span class="o">=</span>/outputs/dataset
python<span class="w"> </span>preprocessing.py<span class="w"> </span>--input_data_format<span class="o">=</span>csv<span class="w"> </span>--csv_na_values<span class="o">=</span><span class="se">\\</span>N<span class="w"> </span>--data_path<span class="w"> </span>/data/QK-video.csv<span class="w"> </span>--filter_query<span class="o">=</span><span class="s2">&quot;click==1 or (click==0 and follow==0 and like==0 and share==0)&quot;</span><span class="w"> </span>--min_item_freq<span class="o">=</span><span class="m">30</span><span class="w"> </span>--min_user_freq<span class="o">=</span><span class="m">30</span><span class="w"> </span>--max_user_freq<span class="o">=</span><span class="m">150</span><span class="w"> </span>--num_max_rounds_filtering<span class="o">=</span><span class="m">5</span><span class="w"> </span>--enable_dask_cuda_cluster<span class="w"> </span>--persist_intermediate_files<span class="w"> </span>--output_path<span class="o">=</span><span class="nv">$OUT_DATASET_PATH</span><span class="w"> </span>--categorical_features<span class="o">=</span>user_id,item_id,video_category,gender,age<span class="w"> </span>--binary_classif_targets<span class="o">=</span>click,follow,like,share<span class="w"> </span>--regression_targets<span class="o">=</span>watching_times<span class="w"> </span>--to_int32<span class="o">=</span>user_id,item_id<span class="w"> </span>--to_int16<span class="o">=</span>watching_times<span class="w"> </span>--to_int8<span class="o">=</span>gender,age,video_category,click,follow,like,share<span class="w"> </span>--user_id_feature<span class="o">=</span>user_id<span class="w"> </span>--item_id_feature<span class="o">=</span>item_id<span class="w"> </span>--dataset_split_strategy<span class="o">=</span>random_by_user<span class="w"> </span>--random_split_eval_perc<span class="o">=</span><span class="m">0</span>.2
</pre></div>
</div>
<p>After you execute this script, a folder <code class="docutils literal notranslate"><span class="pre">dataset</span></code> will be created in <code class="docutils literal notranslate"><span class="pre">--output_path</span></code> with the preprocessed datasets , with <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">eval</span></code> folders. You will find a number of partitioned parquet files inside those dataset folders, as well as a <code class="docutils literal notranslate"><span class="pre">schema.pbtxt</span></code> file produced by <code class="docutils literal notranslate"><span class="pre">NVTabular</span></code> which is very important for automated model building in the next step.</p>
</section>
<section id="training-a-ranking-model">
<h2>Training a ranking model<a class="headerlink" href="#training-a-ranking-model" title="Permalink to this heading">#</a></h2>
<p>Merlin Models is a Merlin library that makes it easy to build and train RecSys models. It is built on top of TensorFlow, and provides building blocks for creating input layers based on the features in the schema, different feature interaction layers and output layers based on the target columns defined in the schema.</p>
<p>A number of popular ranking models are available in Merlin Models API like <strong>DLRM</strong>, <strong>DCN-v2</strong>, <strong>Wide&amp;Deep</strong>, <strong>DeepFM</strong>. This Quick-start provides a generic ranking script <a class="reference download internal" download="" href="../../_downloads/1c928518abcb337bfb61461a825be6ee/ranking.py"><span class="xref download myst">ranking.py</span></a> for building and training those models using Models API.</p>
<p>In the following command example, you can easily train the popular <strong>DLRM</strong> model which performs 2nd level feature interaction. It sets <code class="docutils literal notranslate"><span class="pre">--model</span> <span class="pre">dlrm</span></code> and <code class="docutils literal notranslate"><span class="pre">--embeddings_dim</span> <span class="pre">64</span></code> because DLRM models require all categorical columns to be embedded with the same dimension for the feature interaction. You notice that we can set many of the common model (e.g. top <code class="docutils literal notranslate"><span class="pre">--mlp_layers</span></code>) and training hyperparameters like learning rate (<code class="docutils literal notranslate"><span class="pre">--lr</span></code>) and its decay (<code class="docutils literal notranslate"><span class="pre">--lr_decay_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">--lr_decay_steps</span></code>), L2 regularization (<code class="docutils literal notranslate"><span class="pre">--l2_reg</span></code>, <code class="docutils literal notranslate"><span class="pre">embeddings_l2_reg</span></code>), <code class="docutils literal notranslate"><span class="pre">--dropout</span></code> among others.  We set <code class="docutils literal notranslate"><span class="pre">--epochs</span> <span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">--train_steps_per_epoch</span> <span class="pre">10</span></code> to train for just 10 batches and make runtime faster. If you have a  GPU with more memory (e.g. V100 with 32 GB), you might increase <code class="docutils literal notranslate"><span class="pre">--train_batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">--eval_batch_size</span></code> to a much larger batch size, for example to <code class="docutils literal notranslate"><span class="pre">65536</span></code>.<br />
There are many target columns available in the dataset, and you can select one of them for training by setting <code class="docutils literal notranslate"><span class="pre">--tasks=click</span></code>. In this dataset, there are about 3.7 negative examples (<code class="docutils literal notranslate"><span class="pre">click=0</span></code>) for each positive example (<code class="docutils literal notranslate"><span class="pre">click=1</span></code>). That leads to some class unbalance. We can deal with that by setting <code class="docutils literal notranslate"><span class="pre">--stl_positive_class_weight</span></code> to give more weight to the loss for positive examples, which are rarer.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/Merlin/examples/quick_start/scripts/ranking/
<span class="nv">OUT_DATASET_PATH</span><span class="o">=</span>/outputs/dataset
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="nv">TF_GPU_ALLOCATOR</span><span class="o">=</span>cuda_malloc_async<span class="w"> </span>python<span class="w">  </span>ranking.py<span class="w"> </span>--train_data_path<span class="w"> </span><span class="nv">$OUT_DATASET_PATH</span>/train<span class="w"> </span>--eval_data_path<span class="w"> </span><span class="nv">$OUT_DATASET_PATH</span>/eval<span class="w"> </span>--output_path<span class="w"> </span>./outputs/<span class="w"> </span>--tasks<span class="o">=</span>click<span class="w"> </span>--stl_positive_class_weight<span class="w"> </span><span class="m">3</span><span class="w"> </span>--model<span class="w"> </span>dlrm<span class="w"> </span>--embeddings_dim<span class="w"> </span><span class="m">64</span><span class="w"> </span>--l2_reg<span class="w"> </span>1e-4<span class="w"> </span>--embeddings_l2_reg<span class="w"> </span>1e-6<span class="w"> </span>--dropout<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span>--mlp_layers<span class="w"> </span><span class="m">64</span>,32<span class="w">  </span>--lr<span class="w"> </span>1e-4<span class="w"> </span>--lr_decay_rate<span class="w"> </span><span class="m">0</span>.99<span class="w"> </span>--lr_decay_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span>--train_batch_size<span class="w"> </span><span class="m">65536</span><span class="w"> </span>--eval_batch_size<span class="w"> </span><span class="m">65536</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span>--train_steps_per_epoch<span class="w"> </span><span class="m">10</span><span class="w"> </span>
</pre></div>
</div>
<p>You can explore the <span class="xref myst">full documentation and best practices for ranking models</span>, which contains details about the command line arguments.</p>
</section>
<section id="training-a-ranking-model-with-multi-task-learning">
<h2>Training a ranking model with multi-task learning<a class="headerlink" href="#training-a-ranking-model-with-multi-task-learning" title="Permalink to this heading">#</a></h2>
<p>When multiple targets are available for the same features, models typically benefit from joint training a single model with multiple heads / losses. Merlin Models supports some architectures designed specifically for multi-task learning based on experts. You can find an example notebook with detailed explanations <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/main/examples/usecases/ranking_with_multitask_learning.ipynb">here</a>.</p>
<p>The <a class="reference download internal" download="" href="../../_downloads/1c928518abcb337bfb61461a825be6ee/ranking.py"><span class="xref download myst">ranking.py</span></a> script makes it easy to train ranking models with multi-task learning by setting more than one target, e.g. <code class="docutils literal notranslate"><span class="pre">--tasks=&quot;click,like,follow,share&quot;</span></code>).</p>
<section id="training-an-mmoe-model">
<h3>Training an MMOE model<a class="headerlink" href="#training-an-mmoe-model" title="Permalink to this heading">#</a></h3>
<p>In the following example, we use the popular <strong>MMOE</strong> (<code class="docutils literal notranslate"><span class="pre">--model</span> <span class="pre">mmoe</span></code>) architecture for multi-task learning. It creates independent expert sub-networks (as defined by <code class="docutils literal notranslate"><span class="pre">--mmoe_num_mlp_experts</span></code>, <code class="docutils literal notranslate"><span class="pre">--expert_mlp_layers</span></code>) that interacts independently the input features. Each task has a gate with <code class="docutils literal notranslate"><span class="pre">--gate_dim</span></code> that averages the expert outputs based on learned softmax weights, so that each task can harvest relevant information for its predictions. Each task might also have an independent tower by setting <code class="docutils literal notranslate"><span class="pre">--tower_layers</span></code>.<br />
You can also balance the loss weights by setting <code class="docutils literal notranslate"><span class="pre">--mtl_loss_weight_*</span></code> arguments and the tasks positive class weight by setting <code class="docutils literal notranslate"><span class="pre">--mtl_pos_class_weight_*</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/Merlin/examples/quick_start/scripts/ranking/

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="nv">TF_GPU_ALLOCATOR</span><span class="o">=</span>cuda_malloc_async<span class="w"> </span>python<span class="w"> </span>ranking.py<span class="w"> </span>--train_data_path<span class="w"> </span><span class="nv">$OUT_DATASET_PATH</span>/train<span class="w"> </span>--eval_data_path<span class="w"> </span><span class="nv">$OUT_DATASET_PATH</span>/eval<span class="w"> </span>--output_path<span class="w"> </span>./outputs/<span class="w"> </span>--tasks<span class="o">=</span>click,like,follow,share<span class="w"> </span>--model<span class="w"> </span>mmoe<span class="w"> </span>--mmoe_num_mlp_experts<span class="w"> </span><span class="m">3</span><span class="w"> </span>--expert_mlp_layers<span class="w"> </span><span class="m">128</span><span class="w"> </span>--gate_dim<span class="w"> </span><span class="m">32</span><span class="w"> </span>--use_task_towers<span class="o">=</span>True<span class="w"> </span>--tower_layers<span class="w"> </span><span class="m">64</span><span class="w"> </span>--embedding_sizes_multiplier<span class="w"> </span><span class="m">4</span><span class="w"> </span>--l2_reg<span class="w"> </span>1e-5<span class="w"> </span>--embeddings_l2_reg<span class="w"> </span>1e-6<span class="w"> </span>--dropout<span class="w"> </span><span class="m">0</span>.05<span class="w">  </span>--lr<span class="w"> </span>1e-4<span class="w"> </span>--lr_decay_rate<span class="w"> </span><span class="m">0</span>.99<span class="w"> </span>--lr_decay_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span>--train_batch_size<span class="w"> </span><span class="m">65536</span><span class="w"> </span>--eval_batch_size<span class="w"> </span><span class="m">65536</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span>--mtl_pos_class_weight_click<span class="o">=</span><span class="m">1</span><span class="w"> </span>--mtl_pos_class_weight_like<span class="o">=</span><span class="m">2</span><span class="w"> </span>--mtl_pos_class_weight_share<span class="o">=</span><span class="m">3</span><span class="w"> </span>--mtl_pos_class_weight_follow<span class="o">=</span><span class="m">4</span><span class="w">  </span>--mtl_loss_weight_click<span class="o">=</span><span class="m">3</span><span class="w"> </span>--mtl_loss_weight_like<span class="o">=</span><span class="m">3</span><span class="w"> </span>--mtl_loss_weight_follow<span class="o">=</span><span class="m">1</span><span class="w"> </span>--mtl_loss_weight_share<span class="o">=</span><span class="m">1</span><span class="w"> </span>--train_steps_per_epoch<span class="w"> </span><span class="m">10</span><span class="w"> </span>
</pre></div>
</div>
<p>You can find more quick-start information on multi-task learning and MMOE architecture <span class="xref myst">here</span>.</p>
</section>
</section>
<section id="hyperparameter-tuning">
<h2>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this heading">#</a></h2>
<p>We provide a <a class="reference internal" href="scripts/ranking/hypertuning/tutorial_with_wb_sweeps.html"><span class="doc std std-doc">tutorial</span></a> on how to do <strong>hyperparameter tuning with Merlin models and Weights&amp;Biases Sweeps</strong>.</p>
<p>We also make it available a <span class="xref myst">benchmark</span> resulted from our own hyperparameter tuning of TenRec dataset. It compares the different single-task and multi-task learning models. It provides also empirical information on what were the improvements obtained with hyperparameter tuning, the curated hypertuning search space for modeling hyperparameters of <code class="docutils literal notranslate"><span class="pre">ranking.py</span></code> and the most important hyperparameters.</p>
</section>
<section id="model-deployment-on-triton-inference-server">
<h2>Model Deployment on Triton Inference Server<a class="headerlink" href="#model-deployment-on-triton-inference-server" title="Permalink to this heading">#</a></h2>
<p>In the model deployment step, we deploy NVTabular workflow, and the trained and saved ranking model(s) on <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a>. The <a class="reference download internal" download="" href="../../_downloads/8f4cd7e0df0825238e676416b628235c/inference.py"><span class="xref download myst">inference.py</span></a> script makes it easy to export model configuration files and the required artifacts to deploy the models on Triton. Moreover, we provide an example <a class="reference internal" href="scripts/inference/inference.html"><span class="doc std std-doc">notebook</span></a> to demonstrate how to prepare a batch raw request to sent Triton and receive a response from it. You can find more information about inference step and the scripts <span class="xref myst">here</span>.</p>
</section>
</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-tenrec-dataset">Download the TenRec dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data">Preparing the data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-docker-container">Start Docker container</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">Preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-ranking-model">Training a ranking model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-ranking-model-with-multi-task-learning">Training a ranking model with multi-task learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-an-mmoe-model">Training an MMOE model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">Hyperparameter tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-deployment-on-triton-inference-server">Model Deployment on Triton Inference Server</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, NVIDIA.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>