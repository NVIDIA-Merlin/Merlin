# syntax=docker/dockerfile:1.2
ARG MERLIN_VERSION=23.06
ARG TRITON_VERSION=23.06
ARG TORCH_VERSION=23.06

ARG DLFW_IMAGE=nvcr.io/nvidia/pytorch:${TORCH_VERSION}-py3
ARG FULL_IMAGE=nvcr.io/nvidia/tritonserver:${TRITON_VERSION}-py3
ARG BASE_IMAGE=nvcr.io/nvstaging/merlin/merlin-base:${MERLIN_VERSION}

FROM ${DLFW_IMAGE} as dlfw
FROM ${FULL_IMAGE} as triton
FROM ${BASE_IMAGE} as base

# Install packages
RUN apt update -y --fix-missing && \
    apt install -y --no-install-recommends \
        libatlas-base-dev && \
    apt autoremove -y && \
    apt clean && \
    rm -rf /var/lib/apt/lists/*

# Torch Metrics and Lightning (without torch)
RUN pip install --no-cache-dir --no-deps torch torchmetrics pytorch-lightning lightning-utilities \
        && pip install --no-cache-dir --upgrade pip \
        && pip install sympy \
        && rm -rf /usr/local/lib/python${PYTHON_VERSION}/dist-packages/torch \
        && rm -rf /usr/local/lib/python${PYTHON_VERSION}/dist-packages/caffe2

# Triton Torch backend
COPY --chown=1000:1000 --from=triton /opt/tritonserver/backends/pytorch backends/pytorch

# DLFW Python packages
COPY --chown=1000:1000 --from=dlfw /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numba /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numba
COPY --chown=1000:1000 --from=dlfw /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numpy /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numpy
COPY --chown=1000:1000 --from=dlfw /usr/local/lib/python${PYTHON_VERSION}/dist-packages/torch /usr/local/lib/python${PYTHON_VERSION}/dist-packages/torch

COPY --chown=1000:1000 --from=dlfw /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numba-*.dist-info /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numba.dist-info/
COPY --chown=1000:1000 --from=dlfw /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numpy-*.dist-info /usr/local/lib/python${PYTHON_VERSION}/dist-packages/numpy.dist-info/
COPY --chown=1000:1000 --from=dlfw /usr/local/lib/python${PYTHON_VERSION}/dist-packages/torch-*.egg-info /usr/local/lib/python${PYTHON_VERSION}/dist-packages/torch.egg-info/

# Argumeints "_XXXX" are only valid when $HUGECTR_DEV_MODE==false
# Install hps_torch in merlin-pytorch
ARG HUGECTR_DEV_MODE=false
ARG _HUGECTR_REPO="github.com/NVIDIA-Merlin/HugeCTR.git"
ARG _CI_JOB_TOKEN=""
ARG HUGECTR_VER=main

RUN if [ "$HUGECTR_DEV_MODE" == "false" ]; then \
	export HUGECTR_HOME=/usr/local/hugectr && \
        rm -rf ${HUGECTR_HOME}/lib/libgmock* ${HUGECTR_HOME}/lib/pkgconfig/gmock* ${HUGECTR_HOME}/include/gmock && \
        rm -rf ${HUGECTR_HOME}/lib/libgtest* ${HUGECTR_HOME}/lib/pkgconfig/gtest* ${HUGECTR_HOME}/include/gtest && \
        git clone --branch ${HUGECTR_VER} --depth 1 --recurse-submodules --shallow-submodules https://${_CI_JOB_TOKEN}${_HUGECTR_REPO} /hugectr && \
        pushd /hugectr/hps_torch/ && \
        pip --no-cache-dir install ninja && \
        TORCH_CUDA_ARCH_LIST="7.0 7.5 8.0 9.0" python setup.py install && \
        popd && \
        rm -rf /hugectr \
    ; fi

# Add all torch libraries to /usr/local
RUN ln -s /opt/tritonserver/backends/pytorch/* /usr/local/lib/

RUN pip install --no-cache-dir matplotlib
