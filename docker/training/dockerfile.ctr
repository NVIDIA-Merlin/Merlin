# syntax=docker/dockerfile:1
ARG IMAGE=nvcr.io/nvidia/tensorflow:22.03-tf2-py3
FROM ${IMAGE}

# Args
ARG HWLOC_VER=2.4.1
ARG CORE_VER=main
ARG HUGECTR_VER=master
ARG MODELS_VER=main
ARG NVTAB_VER=main
ARG SYSTEMS_VER=main
ARG TF4REC_VER=main

# Envs
ENV CUDA_SHORT_VERSION=11.6
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/lib:/repos/dist/lib
ENV CUDA_HOME=/usr/local/cuda
ENV CUDA_PATH=$CUDA_HOME
ENV CUDA_CUDA_LIBRARY=${CUDA_HOME}/lib64/stubs
ENV PATH=${CUDA_HOME}/lib64/:${PATH}:${CUDA_HOME}/bin
ENV PATH=$PATH:/usr/lib/x86_64-linux-gnu/
RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1

# Copy files into the container
COPY *-hadoop.sh ./

# Install system packages
ENV DEBIAN_FRONTEND=noninteractive

RUN [ $(uname -m) = 'x86_64' ] \
    && curl -o /tmp/cuda-keyring.deb \
        https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb \
    || curl -o /tmp/cuda-keyring.deb \
        https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/cuda-keyring_1.0-1_all.deb; \
    dpkg -i /tmp/cuda-keyring.deb \
    && rm /tmp/cuda-keyring.deb

RUN apt update -y --fix-missing && \
    apt install -y --no-install-recommends \
       graphviz \
       libexpat1-dev \
       openssl \
       protobuf-compiler \
        # [ HugeCTR dependencies ]
        #   Required to build RocksDB.
            libgflags-dev \
            zlib1g-dev libbz2-dev libsnappy-dev liblz4-dev libzstd-dev \
        #   Required to build RdKafka.
            zlib1g-dev libzstd-dev \
            libssl-dev libsasl2-dev \
        #   Required to build Protocol Buffers.
            autoconf automake libtool \
        #   Required to build Hadoop.
            default-jdk maven \
            libpmem-dev \
            libsasl2-dev libssl-dev \
            libsnappy-dev libzstd-dev zlib1g-dev \
        #   Required to run Hadoop.
            openssh-server \
        # [ HugeCTR ]
            libaio-dev libtbb-dev \
            clang-format \
       software-properties-common && \
    apt remove --purge cmake -y && \
    apt autoremove -y && \
    apt clean && \
    rm -rf /var/lib/apt/lists/*

ENV JAVA_HOME=/usr/lib/jvm/default-java
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${JAVA_HOME}/lib:${JAVA_HOME}/lib/server

# Install cmake newer version
RUN wget http://www.cmake.org/files/v3.21/cmake-3.21.1.tar.gz && \
    tar xf cmake-3.21.1.tar.gz && cd cmake-3.21.1 && ./configure && make && make install

# Install multiple packages
RUN pip install nvidia-pyindex mpi4py onnx onnxruntime
RUN pip install betterproto graphviz pybind11 pydot pytest transformers==4.12
RUN pip install --upgrade notebook
RUN pip install --upgrade ipython
RUN pip install --upgrade horovod
RUN pip install tritonclient[all] grpcio-channelz
RUN pip install git+https://github.com/rapidsai/asvdb.git@main

# Install Merlin Core
RUN git clone https://github.com/NVIDIA-Merlin/core.git /core/ && \
    cd /core/ && git checkout ${CORE_VER} && pip install --no-deps -e .
ENV PYTHONPATH=$PYTHONPATH:/core

# Install Merlin Systems
RUN git clone https://github.com/NVIDIA-Merlin/systems.git /systems/ && \
    cd /systems/ && git checkout ${SYSTEMS_VER} && pip install --no-deps -e .
ENV PYTHONPATH=$PYTHONPATH:/systems

# Install NVTabular
ENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'
RUN git clone https://github.com/NVIDIA-Merlin/NVTabular.git /nvtabular/ && \
    cd /nvtabular/ && git checkout ${NVTAB_VER} && pip install . --no-deps
ENV PYTHONPATH=$PYTHONPATH:/nvtabular

# Install Transformers4Rec
RUN git clone https://github.com/NVIDIA-Merlin/Transformers4Rec.git /transformers4rec && \
    cd /transformers4rec/ && git checkout ${TF4REC_VER} && pip install . --no-deps
ENV PYTHONPATH=$PYTHONPATH:/transformers4rec

# Install Models
RUN git clone https://github.com/NVIDIA-Merlin/Models.git /models/ && \
    cd /models/ && git checkout ${MODELS_VER} && pip install . --no-deps
ENV PYTHONPATH=$PYTHONPATH:/models

# Add Merlin Repo
RUN git clone https://github.com/NVIDIA-Merlin/Merlin/ /Merlin

# Install CUDA-Aware hwloc
RUN cd /opt/hpcx/ompi/include/openmpi/opal/mca/hwloc/hwloc201 && rm -rfv hwloc201.h hwloc/include/hwloc.h
RUN mkdir -p /var/tmp && wget -q -nc --no-check-certificate -P /var/tmp https://download.open-mpi.org/release/hwloc/v2.4/hwloc-${HWLOC_VER}.tar.gz && \
    mkdir -p /var/tmp && tar -x -f /var/tmp/hwloc-${HWLOC_VER}.tar.gz -C /var/tmp && \
    cd /var/tmp/hwloc-${HWLOC_VER} && \
    ./configure CPPFLAGS="-I/usr/local/cuda/include/ -L/usr/local/cuda/lib64/" LDFLAGS="-L/usr/local/cuda/lib64" --enable-cuda && \
    make -j$(nproc) && make install && \
    rm -rf /var/tmp/hwloc-${HWLOC_VER} /var/tmp/hwloc-${HWLOC_VER}.tar.gz



# -----------------------------------------------------------------------------
#    HugeCTR + Dependencies

ARG HIREDIS_VER=1.0.2
ARG REDIS_PP_VER=1.3.3
ARG ROCKSDB_VER=6.29.3
ARG RDKAFKA_VER=1.8.2
# Optional.
ARG PROTOC_VER=3.19.4
ARG HADOOP_VER=3.3.2

# Dependency: Build and install Redis native client.
RUN git clone --branch v${HIREDIS_VER} --depth 1 https://github.com/redis/hiredis.git hiredis && \
    mkdir hiredis/build && \
    cd hiredis/build && \
    cmake .. && \
    make -j$(nproc) && \
    make install && \
    cd ../.. && \
    rm -rf hiredis

RUN git clone --branch ${REDIS_PP_VER} --depth 1 https://github.com/sewenew/redis-plus-plus.git redis_pp && \
    mkdir redis_pp/build && \
    cd redis_pp/build && \
    cmake -DREDIS_PLUS_PLUS_CXX_STANDARD=17 .. && \
    make -j$(nproc) && \
    make install && \
    cd ../.. && \
    rm -rf redis_pp

# Dependency: Build and install RocksDB.
RUN git clone --branch v${ROCKSDB_VER} --depth 1 https://github.com/facebook/rocksdb.git rocksdb && \
    cd rocksdb && \
    PORTABLE=1 make -j$(nproc) shared_lib && \
    make install-shared && \
    cd .. && \
    rm -rf rocksdb

# Dependency: Build and install RdKafka.
RUN git clone --branch v${RDKAFKA_VER} --depth 1 https://github.com/edenhill/librdkafka.git rdkafka && \
    cd rdkafka && \
    ./configure --enable-static && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf rdkafka

# Optional dependency: Build and install protocol buffers and Hadoop/HDFS.
ARG INSTALL_HDFS=false
ARG BUILD_HADOOP=false

RUN git clone --branch v${PROTOC_VER} --depth 1 https://github.com/protocolbuffers/protobuf.git protobuf && \
    cd protobuf && \
    git submodule update --init --recursive && \
    ./autogen.sh && \
    ./configure && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf protobuf && \
    ldconfig && \
    echo "Protocol Buffers version: $(protoc --version)"

ENV HADOOP_HOME=/opt/hadoop
ENV PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin \
    HDFS_NAMENODE_USER=root \
    HDFS_SECONDARYNAMENODE_USER=root \
    HDFS_DATANODE_USER=root \
    YARN_RESOURCEMANAGER_USER=root \
    YARN_NODEMANAGER_USER=root \
    # Tackles with ThreadReaper stack overflow issues: https://bugs.openjdk.java.net/browse/JDK-8153057
    LIBHDFS_OPTS='-Djdk.lang.processReaperUseDefaultStackSize=true' \
    # Tackles with JVM setting error signals that UCX library will check (GitLab issue #425).
    UCX_ERROR_SIGNALS='' \
    CLASSPATH=${CLASSPATH}:\
${HADOOP_HOME}/etc/hadoop/*:\
${HADOOP_HOME}/share/hadoop/common/*:\
${HADOOP_HOME}/share/hadoop/common/lib/*:\
${HADOOP_HOME}/share/hadoop/hdfs/*:\
${HADOOP_HOME}/share/hadoop/hdfs/lib/*:\
${HADOOP_HOME}/share/hadoop/mapreduce/*:\
${HADOOP_HOME}/share/hadoop/yarn/*:\
${HADOOP_HOME}/share/hadoop/yarn/lib/*

RUN if [[ "${INSTALL_HDFS}" == "true" || "${BUILD_HADOOP}" == "true" ]]; then \
        ./build-hadoop.sh "${HADOOP_VER}" \
    ; fi && \
    if [[ "${INSTALL_HDFS}" == "true" ]]; then \
        ./install-hadoop.sh "${HADOOP_VER}" \
    ; fi

# HugeCTR itself.

# Arguments "_XXXX" are only valid when $HUGECTR_DEV_MODE==false
ARG HUGECTR_DEV_MODE=false
ARG _HUGECTR_REPO="github.com/NVIDIA-Merlin/HugeCTR.git"
ARG _CI_JOB_TOKEN=""

ENV OMPI_MCA_plm_rsh_agent=sh
ENV OMPI_MCA_opal_cuda_support=true

ENV NCCL_LAUNCH_MODE=PARALLEL
ENV NCCL_COLLNET_ENABLE=0

ENV SHARP_COLL_NUM_COLL_GROUP_RESOURCE_ALLOC_THRESHOLD=0
ENV SHARP_COLL_LOCK_ON_COMM_INIT=1
ENV SHARP_COLL_LOG_LEVEL=3
ENV HCOLL_ENABLE_MCAST=0

# link sub modules expected by hugectr cmake
RUN ln -s /usr/lib/libcudf.so /usr/lib/libcudf_base.so
RUN ln -s /usr/lib/libcudf.so /usr/lib/libcudf_io.so
RUN ln -s /usr/lib/x86_64-linux-gnu/libibverbs.so.1 /usr/lib/x86_64-linux-gnu/libibverbs.so

RUN rm -rf /usr/lib/x86_64-linux-gnu/libibverbs.so && \
    ln -s /usr/lib/x86_64-linux-gnu/libibverbs.so.1.14.36.0 /usr/lib/x86_64-linux-gnu/libibverbs.so

# Install HugeCTR
ARG HUGECTR_HOME=/usr/local/hugectr
RUN if [[ "${HUGECTR_DEV_MODE}" == "false" ]]; then \
        git clone --branch ${HUGECTR_VER} --depth 1 https://${_CI_JOB_TOKEN}${_HUGECTR_REPO} /hugectr && \
        cd /hugectr && \
        git submodule update --init --recursive && \
        mkdir build && \
        cd build && \
        LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs/:$LD_LIBRARY_PATH && \
        export PATH=$PATH:/usr/local/cuda-${CUDA_SHORT_VERSION}/compat && \
        if [[ -f "/usr/local/lib/libhdfs.so" ]]; then \
            cmake -DCMAKE_BUILD_TYPE=Release -DSM="60;61;70;75;80" -DENABLE_MULTINODES=ON -DENABLE_HDFS=ON .. \
        ; else \
            cmake -DCMAKE_BUILD_TYPE=Release -DSM="60;61;70;75;80" -DENABLE_MULTINODES=ON .. \
        ; fi && \
        make -j$(nproc) && \
        make install && \
        rm -rf ./* && \
        chmod +x ${HUGECTR_HOME}/bin/* ${HUGECTR_HOME}/lib/*.so && \
        cd ../onnx_converter && \
        python setup.py install \
    ; fi

ENV PATH=$PATH:${HUGECTR_HOME}/bin \
    LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${HUGECTR_HOME}/lib \
    PYTHONPATH=${PYTHONPATH}:${HUGECTR_HOME}/lib

# Remove fake lib
RUN rm /usr/local/cuda/lib64/stubs/libcuda.so.1

# Clean up
RUN rm -rf /repos
RUN rm -rf /usr/local/share/jupyter/lab/staging/node_modules/marked
RUN rm -rf /usr/local/share/jupyter/lab/staging/node_modules/node-fetch

HEALTHCHECK NONE
CMD ["/bin/bash"]
ENTRYPOINT ["/bin/bash", "-c", "/opt/nvidia/nvidia_entrypoint.sh"]
