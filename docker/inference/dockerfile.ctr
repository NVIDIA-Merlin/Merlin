# syntax=docker/dockerfile:1.2
ARG TRITON_VERSION=22.03
ARG FULL_IMAGE=nvcr.io/nvidia/tritonserver:${TRITON_VERSION}-py3
ARG BASE_IMAGE=${FULL_IMAGE}-min
FROM ${FULL_IMAGE} as full
FROM ${BASE_IMAGE} as base


# Args
ARG CUDF_VER=v22.02.00
ARG RMM_VER=v22.02.00
ARG CORE_VER=main
ARG HUGECTR_VER=master
ARG HUGECTR_BACKEND_VER=main
ARG NVTAB_VER=main
ARG NVTAB_BACKEND_VER=main
ARG MODELS_VER=main
ARG SYSTEMS_VER=main
ARG TF4REC_VER=main

# Envs
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/lib:/repos/dist/lib
ENV DEBIAN_FRONTEND=noninteractive
ENV CUDA_HOME=/usr/local/cuda
ENV CUDA_PATH=$CUDA_HOME
ENV CUDA_CUDA_LIBRARY=${CUDA_HOME}/lib64/stubs
ENV PATH=${CUDA_HOME}/lib64/:${PATH}:${CUDA_HOME}/bin
ENV PYTHONPATH=/usr/lib/python3.8/site-packages:$PYTHONPATH

# Copy files into the container
COPY *-hadoop.sh ./

# Install system packages
ENV DEBIAN_FRONTEND=noninteractive

RUN apt update -y --fix-missing && \
    apt install -y --no-install-recommends software-properties-common && \
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin && \
    mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600 && \
    apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub && \
    add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"

RUN apt update -y --fix-missing && \
    apt install -y --no-install-recommends \
        datacenter-gpu-manager \
        libarchive-dev \
        libb64-dev \
        libboost-serialization-dev \
        libcurl4-openssl-dev \
        libre2-dev \
        openssl \
        pkg-config \
        protobuf-compiler \
        python3-dev \
        python3-pip \
        rapidjson-dev \
        # [ HugeCTR dependencies ]
        #   Required to build RocksDB.
            libgflags-dev \
            zlib1g-dev libbz2-dev libsnappy-dev liblz4-dev libzstd-dev \
        #   Required to build RdKafka.
            zlib1g-dev libzstd-dev \
            libssl-dev libsasl2-dev \
        #   Required to build Protocol Buffers.
            autoconf automake libtool \
        #   Required to build Hadoop.
            default-jdk maven \
            libpmem-dev \
            libsasl2-dev libssl-dev \
            libsnappy-dev libzstd-dev zlib1g-dev \
        #   Required to run Hadoop.
            openssh-server \
        # [ HugeCTR ]
            libtbb-dev \
            clang-format && \
    apt-get remove -y --purge cmake -y && \
    apt autoremove -y && \
    apt clean && \
    rm -rf /var/lib/apt/lists/*

ENV JAVA_HOME=/usr/lib/jvm/default-java
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${JAVA_HOME}/lib:${JAVA_HOME}/lib/server

RUN ln -s /usr/bin/python3 /usr/bin/python

# Install multiple packages
RUN pip install numba==0.55.1 numpy==1.21.5 --no-deps
RUN pip install pandas==1.3.5
RUN pip install cupy-cuda115 nvidia-pyindex pybind11 pytest protobuf transformers==4.12 tensorflow-metadata 
RUN pip install betterproto cachetools graphviz nvtx scipy sklearn pandas
RUN pip install tritonclient[all] grpcio-channelz
RUN pip install dask==2021.11.2 distributed==2021.11.2 dask[dataframe]==2021.11.2 dask-cuda==22.2.0
RUN pip install git+https://github.com/rapidsai/asvdb.git@main
RUN pip install numba==0.55.1 numpy==1.21.5 --no-deps
RUN pip install "cuda-python>=11.5,<12.0"

# Triton Server
WORKDIR /opt/tritonserver
COPY --chown=1000:1000 --from=full /opt/tritonserver/LICENSE .
COPY --chown=1000:1000 --from=full /opt/tritonserver/TRITON_VERSION .
COPY --chown=1000:1000 --from=full /opt/tritonserver/NVIDIA_Deep_Learning_Container_License.pdf .
COPY --chown=1000:1000 --from=full /opt/tritonserver/bin bin/
COPY --chown=1000:1000 --from=full /opt/tritonserver/lib lib/
COPY --chown=1000:1000 --from=full /opt/tritonserver/include include/
COPY --chown=1000:1000 --from=full /opt/tritonserver/repoagents/ repoagents/
COPY --chown=1000:1000 --from=full /opt/tritonserver/backends/python backends/python
COPY --chown=1000:1000 --from=full /usr/bin/serve /usr/bin/.
ENV PATH=/opt/tritonserver/bin:${PATH}:
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/tritonserver/lib

# Install cmake
RUN wget http://www.cmake.org/files/v3.21/cmake-3.21.1.tar.gz && \
    tar xf cmake-3.21.1.tar.gz && cd cmake-3.21.1 && ./configure && make && make install

# Install spdlog
RUN git clone --branch v1.9.2 https://github.com/gabime/spdlog.git build-env && \
    pushd build-env && \
      mkdir build && cd build && cmake .. && make -j && make install && \
    popd && \
    rm -rf build-env

# Install arrow
ENV ARROW_HOME=/usr/local
RUN git clone --branch apache-arrow-6.0.1 --recurse-submodules https://github.com/apache/arrow.git build-env && \
    pushd build-env && \
      export PARQUET_TEST_DATA="${PWD}/cpp/submodules/parquet-testing/data" && \
      export ARROW_TEST_DATA="${PWD}/testing/data" && \
      pip install -r python/requirements-build.txt && \
      mkdir cpp/release && \
      pushd cpp/release && \
        cmake -DCMAKE_INSTALL_PREFIX=${ARROW_HOME} \
              -DCMAKE_INSTALL_LIBDIR=lib \
              -DCMAKE_LIBRARY_PATH=${CUDA_CUDA_LIBRARY} \
              -DARROW_FLIGHT=ON \
              -DARROW_GANDIVA=OFF \
              -DARROW_ORC=ON \
              -DARROW_WITH_BZ2=ON \
              -DARROW_WITH_ZLIB=ON \
              -DARROW_WITH_ZSTD=ON \
              -DARROW_WITH_LZ4=ON \
              -DARROW_WITH_SNAPPY=ON \
              -DARROW_WITH_BROTLI=ON \
              -DARROW_PARQUET=ON \
              -DARROW_PYTHON=ON \
              -DARROW_PLASMA=ON \
              -DARROW_BUILD_TESTS=ON \
              -DARROW_CUDA=ON \
              -DARROW_DATASET=ON \
              -DARROW_HDFS=ON \
              -DARROW_S3=ON \ 
              .. && \
        make -j$(nproc) && \
        make install && \
      popd && \
      pushd python && \
        export PYARROW_WITH_PARQUET=ON && \
        export PYARROW_WITH_CUDA=ON && \
        export PYARROW_WITH_ORC=ON && \
        export PYARROW_WITH_DATASET=ON && \
        export PYARROW_WITH_S3=ON && \
        export PYARROW_WITH_HDFS=ON && \
        python setup.py build_ext --build-type=release bdist_wheel && \
        pip install dist/*.whl --no-deps --force-reinstall && \
      popd && \
    popd && \
    rm -rf build-env

# Install rmm
ENV INSTALL_PREFIX=/usr
RUN git clone https://github.com/rapidsai/rmm.git build-env && cd build-env/ && \
    git checkout ${RMM_VER} && \
    cd ..; \
    pushd build-env && \
    ./build.sh librmm && \
    pip install python/. --no-deps && \
    popd && \
    rm -rf build-env

# Install CUDF
RUN git clone https://github.com/rapidsai/cudf.git build-env && cd build-env/ && \
    git checkout ${CUDF_VER} && \
    git submodule update --init --recursive && \
    cd .. && \
    pushd build-env && \
      export CUDF_HOME=${PWD} && \
      export CUDF_ROOT=${PWD}/cpp/build/ && \
      export CMAKE_LIBRARY_PATH=${CUDA_CUDA_LIBRARY} && \
      export CUDAFLAGS=-Wno-error=unknown-pragmas && \
      ./build.sh libcudf cudf dask_cudf --allgpuarch --cmake-args=\"-DCUDF_ENABLE_ARROW_S3=OFF\" && \
    popd && \
    rm -rf build-env

# Install Merlin Core
RUN git clone https://github.com/NVIDIA-Merlin/core.git /core/ && \
    cd /core/ && git checkout ${CORE_VER} && pip install . --no-deps
ENV PYTHONPATH=$PYTHONPATH:/core

# Install Merlin Systems
RUN git clone https://github.com/NVIDIA-Merlin/systems.git /systems/ && \
    cd /systems/ && git checkout ${SYSTEMS_VER} && pip install --no-deps -e .
ENV PYTHONPATH=$PYTHONPATH:/systems

# Install NVTabular
ENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'
RUN git clone https://github.com/NVIDIA-Merlin/NVTabular.git /nvtabular/ && \
    cd /nvtabular/ && git checkout ${NVTAB_VER} && pip install . --no-deps
ENV PYTHONPATH=$PYTHONPATH:/nvtabular

# Install Transformers4Rec
RUN git clone https://github.com/NVIDIA-Merlin/Transformers4Rec.git /transformers4rec && \
    cd /transformers4rec/ && git checkout ${TF4REC_VER} && pip install . --no-deps
ENV PYTHONPATH=$PYTHONPATH:/transformers4rec

# Install Models
RUN git clone https://github.com/NVIDIA-Merlin/Models.git /models/ && \
    cd /models/ && git checkout ${MODELS_VER} && pip install . --no-deps;
ENV PYTHONPATH=$PYTHONPATH:/models

# Add Merlin Repo
RUN git clone https://github.com/NVIDIA-Merlin/Merlin/ /Merlin

# Install NVTabular Triton Backend
ARG TRITON_VERSION
RUN git clone https://github.com/NVIDIA-Merlin/nvtabular_triton_backend.git build-env && \
    cd build-env && git checkout ${NVTAB_BACKEND_VER} && cd .. && \
    pushd build-env && \
      mkdir build && \
      cd build && \
      cmake -Dpybind11_DIR=/usr/local/lib/python3.8/dist-packages/pybind11/share/cmake/pybind11 \
        -D TRITON_COMMON_REPO_TAG="r$TRITON_VERSION"    \
        -D TRITON_CORE_REPO_TAG="r$TRITON_VERSION"      \
        -D TRITON_BACKEND_REPO_TAG="r$TRITON_VERSION" .. \
      && make -j && \
      mkdir -p /opt/tritonserver/backends/nvtabular && \
      cp libtriton_nvtabular.so /opt/tritonserver/backends/nvtabular/ && \
    popd && \
    rm -rf build-env 



# -----------------------------------------------------------------------------
#    HugeCTR + Dependencies

ARG HIREDIS_VER=1.0.2 
ARG REDIS_PP_VER=1.3.3 
ARG ROCKSDB_VER=6.29.3 
ARG RDKAFKA_VER=1.8.2 
# Optional.
ARG PROTOC_VER=3.19.4 
ARG HADOOP_VER=3.3.2

# Dependency: Build and install Redis native client.
RUN git clone --branch v${HIREDIS_VER} --depth 1 https://github.com/redis/hiredis.git hiredis && \
    mkdir hiredis/build && \
    cd hiredis/build && \
    cmake .. && \
    make -j$(nproc) && \
    make install && \
    cd ../.. && \
    rm -rf hiredis

RUN git clone --branch ${REDIS_PP_VER} --depth 1 https://github.com/sewenew/redis-plus-plus.git redis_pp && \
    mkdir redis_pp/build && \
    cd redis_pp/build && \
    cmake -DREDIS_PLUS_PLUS_CXX_STANDARD=17 .. && \
    make -j$(nproc) && \
    make install && \
    cd ../.. && \
    rm -rf redis_pp

# Dependency: Build and install RocksDB.
RUN git clone --branch v${ROCKSDB_VER} --depth 1 https://github.com/facebook/rocksdb.git rocksdb && \
    cd rocksdb && \
    PORTABLE=1 make -j$(nproc) shared_lib && \
    make install-shared && \
    cd .. && \
    rm -rf rocksdb

# Dependency: Build and install RdKafka.
RUN git clone --branch v${RDKAFKA_VER} --depth 1 https://github.com/edenhill/librdkafka.git rdkafka && \
    cd rdkafka && \
    ./configure --enable-static && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf rdkafka

# Optional dependency: Build and install protocol buffers and Hadoop/HDFS.
ARG INSTALL_HDFS=false
ARG BUILD_HADOOP=false

RUN git clone --branch v${PROTOC_VER} --depth 1 https://github.com/protocolbuffers/protobuf.git protobuf && \
    cd protobuf && \
    git submodule update --init --recursive && \
    ./autogen.sh && \
    ./configure && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf protobuf && \
    ldconfig && \
    echo "Protocol Buffers version: $(protoc --version)"

ENV HADOOP_HOME=/opt/hadoop
ENV PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin \
    HDFS_NAMENODE_USER=root \
    HDFS_SECONDARYNAMENODE_USER=root \
    HDFS_DATANODE_USER=root \
    YARN_RESOURCEMANAGER_USER=root \
    YARN_NODEMANAGER_USER=root \
    # Tackles with ThreadReaper stack overflow issues: https://bugs.openjdk.java.net/browse/JDK-8153057
    LIBHDFS_OPTS='-Djdk.lang.processReaperUseDefaultStackSize=true' \
    # Tackles with JVM setting error signals that UCX library will check (GitLab issue #425).
    UCX_ERROR_SIGNALS='' \
    CLASSPATH=${CLASSPATH}:\
${HADOOP_HOME}/etc/hadoop/*:\
${HADOOP_HOME}/share/hadoop/common/*:\
${HADOOP_HOME}/share/hadoop/common/lib/*:\
${HADOOP_HOME}/share/hadoop/hdfs/*:\
${HADOOP_HOME}/share/hadoop/hdfs/lib/*:\
${HADOOP_HOME}/share/hadoop/mapreduce/*:\
${HADOOP_HOME}/share/hadoop/yarn/*:\
${HADOOP_HOME}/share/hadoop/yarn/lib/*

RUN if [[ "${INSTALL_HDFS}" == "true" || "${BUILD_HADOOP}" == "true" ]]; then \
        ./build-hadoop.sh "${HADOOP_VER}" \
    ; fi && \
    if [[ "${INSTALL_HDFS}" == "true" ]]; then \
        ./install-hadoop.sh "${HADOOP_VER}" \
    ; fi

# HugeCTR itself.

# Arguments "_XXXX" are only valid when $HUGECTR_DEV_MODE==false
ARG HUGECTR_DEV_MODE=false
ARG _HUGECTR_REPO="github.com/NVIDIA-Merlin/HugeCTR.git"
ARG _HUGECTR_BACKEND_REPO="github.com/triton-inference-server/hugectr_backend"
ARG _CI_JOB_TOKEN=""

# Install HugeCTR
ARG HUGECTR_HOME=/usr/local/hugectr
RUN if [[ "${HUGECTR_DEV_MODE}" == "false" ]]; then \
        git clone --branch ${HUGECTR_VER} --depth 1 https://${_CI_JOB_TOKEN}${_HUGECTR_REPO} /hugectr && \
        cd /hugectr && \
        git submodule update --init --recursive && \
        mkdir build && \
        cd build && \
        if [[ -f "/usr/local/lib/libhdfs.so" ]]; then \
            cmake -DCMAKE_BUILD_TYPE=Release -DSM="60;61;70;75;80" -DENABLE_INFERENCE=ON -DENABLE_HDFS=ON .. \
        ; else \
            cmake -DCMAKE_BUILD_TYPE=Release -DSM="60;61;70;75;80" -DENABLE_INFERENCE=ON .. \
        ; fi && \
        make -j$(nproc) && \
        make install && \
        rm -rf ./* && \
        chmod +x ${HUGECTR_HOME}/bin/* ${HUGECTR_HOME}/lib/*.so \
    ; fi

ENV PATH=$PATH:${HUGECTR_HOME}/bin \
    CPATH=$CPATH:${HUGECTR_HOME}/include \
    LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${HUGECTR_HOME}/lib \
    PYTHONPATH=${PYTHONPATH}:${HUGECTR_HOME}/lib

# Install Triton inference backend.
RUN if [ "${HUGECTR_DEV_MODE}" == "false" ]; then \
        git clone --branch ${HUGECTR_BACKEND_VER} --depth 1 https://${_CI_JOB_TOKEN}${_HUGECTR_BACKEND_REPO} /repos/hugectr_triton_backend && \
        mkdir /repos/hugectr_triton_backend/build && \
        cd /repos/hugectr_triton_backend/build && \
        cmake \
            -DCMAKE_INSTALL_PREFIX:PATH=${HUGECTR_HOME} \
            -DTRITON_COMMON_REPO_TAG="r${TRITON_VERSION}" \
            -DTRITON_CORE_REPO_TAG="r${TRITON_VERSION}" \
            -DTRITON_BACKEND_REPO_TAG="r${TRITON_VERSION}" .. && \
        make -j$(nproc) && \
        make install && \
        cd ../.. && \
        rm -rf hugectr_triton_backend && \
        chmod +x ${HUGECTR_HOME}/lib/*.so ${HUGECTR_HOME}/backends/hugectr/*.so \
    ; fi
RUN ln -s ${HUGECTR_HOME}/backends/hugectr /opt/tritonserver/backends/hugectr

# Clean up
RUN rm -rf /repos

HEALTHCHECK NONE
CMD ["/bin/bash"]
ENTRYPOINT ["/bin/bash", "-c", "/opt/nvidia/nvidia_entrypoint.sh"]
