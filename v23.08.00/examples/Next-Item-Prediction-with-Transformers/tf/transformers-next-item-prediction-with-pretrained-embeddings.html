

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Transformer-based architecture for next-item prediction task with pretrained embeddings &#8212; NVIDIA Merlin</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/versions.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=927b94d3fcb96560df09"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/js/rtd-version-switcher.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/Next-Item-Prediction-with-Transformers/tf/transformers-next-item-prediction-with-pretrained-embeddings';</script>
    <link rel="canonical" href="https://nvidia-merlin.github.io/Merlin/stable/examples/Next-Item-Prediction-with-Transformers/tf/transformers-next-item-prediction-with-pretrained-embeddings.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVJ1Y1YJHK', {
        'anonymize_ip': false,
    });
  </script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,300&display=swap" rel="stylesheet">
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">NVIDIA Merlin</p>
  
</a></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../README.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../guide/recommender_system_guide.html">Recommender System Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/recommender_models.html">Recommender Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../index.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../getting-started-movielens/index.html">Getting Started using the MovieLens Dataset</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../getting-started-movielens/01-Download-Convert.html">MovieLens Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../getting-started-movielens/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../getting-started-movielens/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../getting-started-movielens/03-Training-with-TF.html">Getting Started MovieLens: Training with TensorFlow</a></li>


<li class="toctree-l3"><a class="reference internal" href="../../getting-started-movielens/03-Training-with-PyTorch.html">Training with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../getting-started-movielens/04-Triton-Inference-with-HugeCTR.html">Serving the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../getting-started-movielens/04-Triton-Inference-with-TF.html">Serve Recommendations from the TensorFlow Model</a></li>

</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../Building-and-deploying-multi-stage-RecSys/index.html">Deploying a Multi-Stage Recommender System</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Building-and-deploying-multi-stage-RecSys/01-Building-Recommender-Systems-with-Merlin.html">Building the Recommender System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Building-and-deploying-multi-stage-RecSys/02-Deploying-multi-stage-RecSys-with-Merlin-Systems.html">Deploying the Recommender System with Triton</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../sagemaker-tensorflow/index.html">Merlin and AWS SageMaker</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../sagemaker-tensorflow/sagemaker-merlin-tensorflow.html">Training and Serving Merlin on AWS SageMaker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../scaling-criteo/index.html">Scaling Large Datasets with Criteo</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../scaling-criteo/01-Download-Convert.html">Criteo Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../scaling-criteo/02-ETL-with-NVTabular.html">Feature Engineering with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../scaling-criteo/03-Training-with-HugeCTR.html">Training with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../scaling-criteo/03-Training-with-Merlin-Models-TensorFlow.html">Training with Merlin Models and TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../scaling-criteo/04-Triton-Inference-with-HugeCTR.html">Deploy the HugeCTR Model with Triton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../scaling-criteo/04-Triton-Inference-with-Merlin-Models-TensorFlow.html">Deploy the TensorFlow Model with Triton</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../containers.html">Merlin Containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../support_matrix/index.html">Merlin Support Matrix</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_hugectr.html">Merlin HugeCTR Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_tensorflow.html">Merlin TensorFlow Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../support_matrix/support_matrix_merlin_pytorch.html">Merlin PyTorch Support Matrix</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-merlin-ecosystem-nav" aria-label="Merlin Ecosystem Nav">
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul class="nav bd-sidenav">
      <li class="toctree-l1"><a class="reference external" href="/core/v23.08.00">Core</a></li>
      <li class="toctree-l1"><a class="reference external" href="/models/v23.08.00">Models</a></li>
      <li class="toctree-l1"><a class="reference external" href="/systems/v23.08.00">Systems</a></li>
      <li class="toctree-l1"><a class="reference external" href="/NVTabular/v23.08.00">NVTabular</a></li>
      <li class="toctree-l1"><a class="reference external" href="/Transformers4Rec/v23.08.00">Transformers4Rec</a></li>
      <li class="toctree-l1"><a class="reference external" href="/dataloader/v23.08.00">Dataloader</a></li>
      <li class="toctree-l1"><a class="reference external" href="/HugetCTR/v23.08.00">HugeCTR</a></li>
    </ul>
  </div>
</nav></div>
        <div class="sidebar-primary-item">
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"></span>
    v: v23.08.00
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../../v22.12.00/index.html">v22.12.00</a></dd>
      <dd><a href="../../../../v23.02.00/index.html">v23.02.00</a></dd>
      <dd><a href="../../../../v23.04.00/index.html">v23.04.00</a></dd>
      <dd><a href="../../../../v23.05.00/index.html">v23.05.00</a></dd>
      <dd><a href="../../../../v23.06.00/index.html">v23.06.00</a></dd>
      <dd><a href="transformers-next-item-prediction-with-pretrained-embeddings.html">v23.08.00</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../../main/index.html">main</a></dd>
      <dd><a href="../../../../stable/index.html">stable</a></dd>
    </dl>
  </div>
</div></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/NVIDIA-Merlin/Merlin" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Transformer-based architecture for next-item prediction task with pretrained embeddings</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning objectives</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#downloading-and-preparing-the-dataset">Downloading and preparing the dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clean-downloaded-data">Clean downloaded data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-synthetic-data">Generate synthetic data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-a-workflow">Constructing a workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-and-training-the-model">Creating and training the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#serving-predictions">Serving predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright 2022 NVIDIA Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#`</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions anda</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>

<span class="c1"># Each user is responsible for checking the content of datasets and the</span>
<span class="c1"># applicable licenses and determining if suitable for the intended use.</span>
</pre></div>
</div>
</div>
</div>
<img alt="https://developer.download.nvidia.com/notebooks/dlsw%20notebooks/merlin_models-transformers-next-item-prediction-with-pretrained-embeddings/nvidia_logo.png" src="https://developer.download.nvidia.com/notebooks/dlsw%20notebooks/merlin_models-transformers-next-item-prediction-with-pretrained-embeddings/nvidia_logo.png" />
<section id="transformer-based-architecture-for-next-item-prediction-task-with-pretrained-embeddings">
<h1>Transformer-based architecture for next-item prediction task with pretrained embeddings<a class="headerlink" href="#transformer-based-architecture-for-next-item-prediction-task-with-pretrained-embeddings" title="Permalink to this heading">#</a></h1>
<p>This notebook is created using the latest stable <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow/tags">merlin-tensorflow</a> container.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>In this use case we will train a Transformer-based architecture for next-item prediction task with pretrained embeddings.</p>
<p><strong>You can chose to download the full dataset manually or use synthetic data.</strong></p>
<p>We will use the <a class="reference external" href="https://github.com/coveooss/SIGIR-ecom-data-challenge">SIGIR eCOM 2021 Data Challenge Dataset</a> to train a session-based model. The dataset contains 36M events of users browsing an online store.</p>
<p>We will reshape the data to organize it into ‘sessions’. Each session will be a full customer online journey in chronological order. The goal will be to predict the <code class="docutils literal notranslate"><span class="pre">url</span></code> of the next action taken.</p>
<section id="learning-objectives">
<h3>Learning objectives<a class="headerlink" href="#learning-objectives" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Training a Transformer-based architecture for next-item prediction task</p></li>
</ul>
</section>
</section>
<section id="downloading-and-preparing-the-dataset">
<h2>Downloading and preparing the dataset<a class="headerlink" href="#downloading-and-preparing-the-dataset" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>
<span class="kn">from</span> <span class="nn">merlin.schema</span> <span class="kn">import</span> <span class="n">ColumnSchema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">Tags</span>

<span class="n">OUTPUT_DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;OUTPUT_DATA_DIR&#39;</span><span class="p">,</span> <span class="s1">&#39;/workspace/data&#39;</span><span class="p">)</span>
<span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;NUM_EPOCHS&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">NUM_EXAMPLES</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;NUM_EXAMPLES&#39;</span><span class="p">,</span> <span class="mi">100_000</span><span class="p">))</span>
<span class="n">MINIMUM_SESSION_LENGTH</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;MINIMUM_SESSION_LENGTH&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-06-20 22:58:36.667322: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named &#39;torch&#39;
  warn(f&quot;PyTorch dtype mappings did not load successfully due to an error: {exc.msg}&quot;)
2023-06-20 22:58:38.026020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:38.026445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:38.026622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
</pre></div>
</div>
</div>
</div>
<p>You can download the full dataset by registering <a class="reference external" href="https://www.coveo.com/en/ailabs/sigir-ecom-data-challenge">here</a>. If you chose to download the data, please place it alongside this notebook in the <code class="docutils literal notranslate"><span class="pre">sigir_dataset</span></code> directory and extract it.</p>
<p>By default, in this notebook we will be using synthetically generated data based on the SIGIR dataset, but you can run on the full dataset by changing the value of the boolean flag below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RUN_ON_SYNTHETIC_DATA</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<section id="clean-downloaded-data">
<h3>Clean downloaded data<a class="headerlink" href="#clean-downloaded-data" title="Permalink to this heading">#</a></h3>
<p>If you are training on the full SIGIR dataset, the following code will pre-process it.</p>
<p>Here we deal with <code class="docutils literal notranslate"><span class="pre">nan</span></code> values, drop rows with missing information and parse strings containing lists to lists.</p>
<p>The synthetically generated data is already clean – it doesn’t require this pre-processing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">RUN_ON_SYNTHETIC_DATA</span><span class="p">:</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s1">&#39;/workspace/sigir_dataset/train/browsing_train.csv&#39;</span><span class="p">,</span> <span class="n">part_size</span><span class="o">=</span><span class="s1">&#39;500MB&#39;</span><span class="p">)</span>
    <span class="n">skus</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s1">&#39;/workspace/sigir_dataset/train/sku_to_content.csv&#39;</span><span class="p">)</span>

    <span class="n">skus</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/workspace/sigir_dataset/train/sku_to_content.csv&#39;</span><span class="p">)</span>

    <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;description_vector&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;description_vector&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;image_vector&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;image_vector&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>

    <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;description_vector&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;description_vector&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">eval</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;image_vector&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">skus</span><span class="p">[</span><span class="s1">&#39;image_vector&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">eval</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">skus</span> <span class="o">=</span> <span class="n">skus</span><span class="p">[</span><span class="n">skus</span><span class="o">.</span><span class="n">description_vector</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">skus</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">skus</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="generate-synthetic-data">
<h3>Generate synthetic data<a class="headerlink" href="#generate-synthetic-data" title="Permalink to this heading">#</a></h3>
<p>If you are not running on the full dataset, the following lines of code will generate its synthetic counterpart.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">RUN_ON_SYNTHETIC_DATA</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">merlin.datasets.synthetic</span> <span class="kn">import</span> <span class="n">generate_data</span>

    <span class="n">train</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="s1">&#39;sigir-browsing&#39;</span><span class="p">,</span> <span class="n">NUM_EXAMPLES</span><span class="p">)</span>
    <span class="n">skus</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="s1">&#39;sigir-sku&#39;</span><span class="p">,</span> <span class="n">NUM_EXAMPLES</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="constructing-a-workflow">
<h2>Constructing a workflow<a class="headerlink" href="#constructing-a-workflow" title="Permalink to this heading">#</a></h2>
<p>We need to process our data further before we can use it to train our model.</p>
<p>In particular, the <code class="docutils literal notranslate"><span class="pre">skus</span></code> dataset contains the mapping between the <code class="docutils literal notranslate"><span class="pre">product_sku_hash</span></code> (essentially an item id) to the <code class="docutils literal notranslate"><span class="pre">description_vector</span></code> – an embedding obtained from the description.</p>
<p>We would like to enable our model to make use of this piece of information. In order to feed this data to our model, we need to map the <code class="docutils literal notranslate"><span class="pre">product_sku_hash</span></code> to an id.</p>
<p>But we need to make sure that the way we process <code class="docutils literal notranslate"><span class="pre">skus</span></code> and the <code class="docutils literal notranslate"><span class="pre">train</span></code> dataset (event information) is consistent, that the same <code class="docutils literal notranslate"><span class="pre">product_sku_hash</span></code> is mapped to the same id both when processing <code class="docutils literal notranslate"><span class="pre">skus</span></code> and <code class="docutils literal notranslate"><span class="pre">train</span></code>.</p>
<p>We do so by defining and fitting a <code class="docutils literal notranslate"><span class="pre">Categorify</span></code> op once and using it to process both the <code class="docutils literal notranslate"><span class="pre">skus</span></code> and the <code class="docutils literal notranslate"><span class="pre">train</span></code> datasets.</p>
<p>Additionally, we apply some further processing to the <code class="docutils literal notranslate"><span class="pre">train</span></code> dataset. We group rows by <code class="docutils literal notranslate"><span class="pre">session_id_hash</span></code> so that each training example will contain events from a single customer visit to the online store arranged in chronological order.</p>
<p>If you would like to learn more about leveraging <code class="docutils literal notranslate"><span class="pre">NVTabular</span></code> to process tabular data on the GPU using a set of industry standard operators, please consult the examples available <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular/tree/main/examples">here</a>.</p>
<p>Let’s first process the <code class="docutils literal notranslate"><span class="pre">train</span></code> dataset and retain the <code class="docutils literal notranslate"><span class="pre">Categorify</span></code> operator (<code class="docutils literal notranslate"><span class="pre">cat_op</span></code>) for processing of <code class="docutils literal notranslate"><span class="pre">skus</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_op</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Categorify</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;product_sku_hash&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">cat_op</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">TagAsItemID</span><span class="p">()</span>
<span class="n">out</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;event_type&#39;</span><span class="p">,</span> <span class="s1">&#39;product_action&#39;</span><span class="p">,</span> <span class="s1">&#39;session_id_hash&#39;</span><span class="p">,</span> <span class="s1">&#39;hashed_url&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Categorify</span><span class="p">()</span>
<span class="n">out</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;server_timestamp_epoch_ms&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">NormalizeMinMax</span><span class="p">()</span>

<span class="n">groupby_features</span> <span class="o">=</span> <span class="n">out</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Groupby</span><span class="p">(</span>
    <span class="n">groupby_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;session_id_hash&#39;</span><span class="p">],</span>
    <span class="n">aggs</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;product_sku_hash&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;list&#39;</span><span class="p">],</span>
        <span class="s1">&#39;event_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;list&#39;</span><span class="p">],</span>
        <span class="s1">&#39;product_action&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;list&#39;</span><span class="p">],</span>
        <span class="s1">&#39;hashed_url&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;list&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">],</span>
        <span class="s1">&#39;server_timestamp_epoch_ms&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;list&#39;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="n">sort_cols</span><span class="o">=</span><span class="s2">&quot;server_timestamp_epoch_ms&quot;</span>
<span class="p">)</span>

<span class="n">filtered_sessions</span> <span class="o">=</span> <span class="n">groupby_features</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;hashed_url_count&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">MINIMUM_SESSION_LENGTH</span><span class="p">)</span>

<span class="c1"># We won&#39;t be needing the `session_id_hash` nor the `hashed_url_count` any longer</span>
<span class="n">wf</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="p">(</span>
    <span class="n">filtered_sessions</span><span class="p">[</span>
        <span class="s1">&#39;product_sku_hash_list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;event_type_list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;product_action_list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;hashed_url_list&#39;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Let&#39;s save the output of our workflow -- transformed `train` for later use (training of our model).</span>
<span class="n">wf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s1">&#39;train_transformed&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here are a couple of example rows from <code class="docutils literal notranslate"><span class="pre">train_transformed</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s1">&#39;train_transformed&#39;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;parquet&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_sku_hash_list</th>
      <th>event_type_list</th>
      <th>product_action_list</th>
      <th>hashed_url_list</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[578, 972, 378, 420, 328, 126, 233, 925, 410, ...</td>
      <td>[3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 3, 4, 4, 4, ...</td>
      <td>[3, 3, 5, 6, 4, 3, 3, 4, 4, 4, 6, 5, 3, 4, 3, ...</td>
      <td>[766, 955, 745, 210, 940, 688, 986, 524, 425, ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[298, 304, 393, 697, 706, 313, 834, 83, 502, 1...</td>
      <td>[4, 4, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 3, 4, 3, ...</td>
      <td>[3, 5, 6, 4, 4, 3, 3, 3, 6, 6, 3, 3, 6, 6, 3, ...</td>
      <td>[13, 221, 915, 658, 456, 378, 802, 180, 580, 4...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[706, 221, 22, 702, 339, 645, 436, 358, 84, 35...</td>
      <td>[4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 3, ...</td>
      <td>[3, 6, 4, 6, 3, 3, 5, 5, 4, 6, 4, 6, 3, 5, 6, ...</td>
      <td>[271, 940, 562, 498, 172, 239, 270, 215, 489, ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[278, 153, 189, 717, 580, 540, 219, 79, 200, 9...</td>
      <td>[3, 3, 3, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, ...</td>
      <td>[6, 6, 6, 6, 3, 4, 4, 4, 4, 4, 3, 6, 5, 4, 3, ...</td>
      <td>[169, 419, 875, 725, 926, 770, 160, 554, 763, ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[156, 922, 914, 592, 842, 916, 137, 928, 615, ...</td>
      <td>[3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, ...</td>
      <td>[6, 4, 5, 6, 5, 4, 3, 3, 6, 5, 6, 5, 3, 6, 3, ...</td>
      <td>[318, 506, 281, 191, 506, 480, 965, 399, 761, ...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now that we have processed the train set, we can use the mapping preserved in the <code class="docutils literal notranslate"><span class="pre">cat_op</span></code> to process the <code class="docutils literal notranslate"><span class="pre">skus</span></code> dataset containing the embeddings we are after.</p>
<p>Let’s now <code class="docutils literal notranslate"><span class="pre">Categorify</span></code> the <code class="docutils literal notranslate"><span class="pre">product_sku_hash</span></code> in <code class="docutils literal notranslate"><span class="pre">skus</span></code> and grab just the description embedding information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">skus</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_sku_hash</th>
      <th>description_vector</th>
      <th>category_hash</th>
      <th>price_bucket</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>13</td>
      <td>[0.07939800762120258, 0.3465797761609977, -0.3...</td>
      <td>16</td>
      <td>0.186690</td>
    </tr>
    <tr>
      <th>1</th>
      <td>25</td>
      <td>[0.4275482879608162, -0.30569476366666, 0.1440...</td>
      <td>38</td>
      <td>0.951997</td>
    </tr>
    <tr>
      <th>2</th>
      <td>18</td>
      <td>[-0.31035419787213536, 0.18070481533058008, 0....</td>
      <td>22</td>
      <td>0.973384</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>[-0.31319783485940356, -0.11623980504981396, -...</td>
      <td>138</td>
      <td>0.146260</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11</td>
      <td>[0.25091279302969943, -0.33473442518442525, 0....</td>
      <td>119</td>
      <td>0.808252</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;product_sku_hash&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">cat_op</span>
<span class="n">wf_skus</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="p">(</span><span class="n">out</span> <span class="o">+</span> <span class="s1">&#39;description_vector&#39;</span><span class="p">)</span>
<span class="n">skus_ds</span> <span class="o">=</span> <span class="n">wf_skus</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">skus</span><span class="p">)</span>

<span class="n">skus_ds</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_sku_hash</th>
      <th>description_vector</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>836</td>
      <td>[0.07939800762120258, 0.3465797761609977, -0.3...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>979</td>
      <td>[0.4275482879608162, -0.30569476366666, 0.1440...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>11</td>
      <td>[-0.31035419787213536, 0.18070481533058008, 0....</td>
    </tr>
    <tr>
      <th>3</th>
      <td>469</td>
      <td>[-0.31319783485940356, -0.11623980504981396, -...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>118</td>
      <td>[0.25091279302969943, -0.33473442518442525, 0....</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let us now export the embedding information to a <code class="docutils literal notranslate"><span class="pre">numpy</span></code> array and write it to disk.</p>
<p>We will later pass this information to the <code class="docutils literal notranslate"><span class="pre">Loader</span></code> so that it will load the correct emebedding for the product corresponding to a given step of a customer journey.</p>
<p>The embeddings are linked to the train set using the <code class="docutils literal notranslate"><span class="pre">product_sku_hash</span></code> information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">skus_ds</span><span class="o">.</span><span class="n">to_npy</span><span class="p">(</span><span class="s1">&#39;skus.npy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>How will the <code class="docutils literal notranslate"><span class="pre">Loader</span></code> know which embedding to associate with a given row of the train set?</p>
<p>The <code class="docutils literal notranslate"><span class="pre">product_sku_hash</span></code> ids have been exported along with the embeddings and are contained in the first column of the output <code class="docutils literal notranslate"><span class="pre">numpy</span></code> array.</p>
<p>Here is the id of the first embedding stored in <code class="docutils literal notranslate"><span class="pre">skus.npy</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;skus.npy&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>836.0
</pre></div>
</div>
</div>
</div>
<p>and here is the embedding vector corresponding to <code class="docutils literal notranslate"><span class="pre">product_sku_hash</span></code> of id referenced above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;skus.npy&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.07939801,  0.34657978, -0.38269496,  0.56307004, -0.10142923,
        0.03702352, -0.11606304,  0.10070879, -0.21879928,  0.06107687,
       -0.20743195, -0.01330719,  0.60182867,  0.0920322 ,  0.2648726 ,
        0.56061561,  0.48643498,  0.39045152, -0.40012162,  0.09153962,
       -0.38351605,  0.57134731,  0.59986226, -0.40321368, -0.32984972,
        0.37559494,  0.1554353 , -0.0413067 ,  0.33814398,  0.30678041,
        0.24001132,  0.42737922,  0.41554601, -0.40451691,  0.50428902,
       -0.2004803 , -0.38297056,  0.06580838,  0.48285745,  0.51406472,
        0.02268894,  0.36343324,  0.32497967, -0.29736346, -0.00538915,
        0.12329302, -0.04998194,  0.27843002,  0.20212714,  0.39019503])
</pre></div>
</div>
</div>
</div>
<p>We are now ready to construct the <code class="docutils literal notranslate"><span class="pre">Loader</span></code> that will feed the data to our model.</p>
<p>We begin by reading in the embeddings information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;skus.npy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We are now ready to define the <code class="docutils literal notranslate"><span class="pre">Loader</span></code>.</p>
<p>We are passing in an <code class="docutils literal notranslate"><span class="pre">EmbeddingOperator</span></code> that will ensure that correct <code class="docutils literal notranslate"><span class="pre">sku</span></code> information (correct <code class="docutils literal notranslate"><span class="pre">description_vector</span></code>) is associated with the correct step in the customer journey (with the lookup key being contained in the <code class="docutils literal notranslate"><span class="pre">product_sku_hash_list</span></code>)</p>
<p>When specifying the dataset, we are creating a <code class="docutils literal notranslate"><span class="pre">Merlin</span> <span class="pre">Dataset</span></code> based on the <code class="docutils literal notranslate"><span class="pre">train_transformed</span></code> data we saved above.</p>
<p>Depending on the hardware that you will be running this on and the size of the dataset that you will be using, should you run out of GPU memory, you can specify one of the several parameters that can ease the memory load (<code class="docutils literal notranslate"><span class="pre">npartitions</span></code>, <code class="docutils literal notranslate"><span class="pre">part_size</span></code>, or <code class="docutils literal notranslate"><span class="pre">part_mem_fraction</span></code>).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">BATCH_SIZE</span></code> of 16 should work on a broad set of hardware, but if you are training on a lot of data and your hardware permitting you might want to significantly increase it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">16</span>

<span class="kn">from</span> <span class="nn">merlin.dataloader.tensorflow</span> <span class="kn">import</span> <span class="n">Loader</span>
<span class="kn">from</span> <span class="nn">merlin.dataloader.ops.embeddings</span> <span class="kn">import</span> <span class="n">EmbeddingOperator</span>
<span class="kn">import</span> <span class="nn">merlin.models.tf</span> <span class="k">as</span> <span class="nn">mm</span>

<span class="n">embedding_operator</span> <span class="o">=</span> <span class="n">EmbeddingOperator</span><span class="p">(</span>
    <span class="n">embeddings</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">id_lookup_table</span><span class="o">=</span><span class="n">embeddings</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">lookup_key</span><span class="o">=</span><span class="s2">&quot;product_sku_hash_list&quot;</span><span class="p">,</span>
    <span class="n">embedding_name</span><span class="o">=</span><span class="s1">&#39;product_embeddings&#39;</span>
<span class="p">)</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">Loader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s1">&#39;train_transformed&#39;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;parquet&#39;</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><span class="p">[</span>
        <span class="n">embedding_operator</span>
    <span class="p">],</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.
[INFO]: sparse_operation_kit is imported
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.
[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so
[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.1.4-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so
[SOK INFO] Initialize finished, communication tool: horovod
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-06-20 22:58:50.835162: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-20 22:58:50.836068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:50.836268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:50.836425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:50.836673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:50.836849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:50.837009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-06-20 22:58:50.837114: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2023-06-20 22:58:50.837130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -&gt; device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5
</pre></div>
</div>
</div>
</div>
<p>Using the <code class="docutils literal notranslate"><span class="pre">EmbeddingOperator</span></code> object we referenced our <code class="docutils literal notranslate"><span class="pre">product_embeddings</span></code> and insructed the model what to use as a key to look up the information.</p>
<p>Below is an example batch of data that our model will consume.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">sample_batch</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">include_targets</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prepare_features</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">product_embeddings</span></code> are included in the batch.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;product_sku_hash_list&#39;, &#39;event_type_list&#39;, &#39;product_action_list&#39;, &#39;hashed_url_list&#39;, &#39;product_embeddings&#39;])
</pre></div>
</div>
</div>
</div>
</section>
<section id="creating-and-training-the-model">
<h2>Creating and training the model<a class="headerlink" href="#creating-and-training-the-model" title="Permalink to this heading">#</a></h2>
<p>We are now ready to construct our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">merlin.models.tf</span> <span class="k">as</span> <span class="nn">mm</span>

<span class="n">input_block</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">InputBlockV2</span><span class="p">(</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">output_schema</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="o">=</span><span class="n">mm</span><span class="o">.</span><span class="n">Embeddings</span><span class="p">(</span>
        <span class="n">loader</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">CATEGORICAL</span><span class="p">),</span>
        <span class="n">sequence_combiner</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">pretrained_embeddings</span><span class="o">=</span><span class="n">mm</span><span class="o">.</span><span class="n">PretrainedEmbeddings</span><span class="p">(</span>
        <span class="n">loader</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">select_by_tag</span><span class="p">(</span><span class="n">Tags</span><span class="o">.</span><span class="n">EMBEDDING</span><span class="p">),</span>
        <span class="n">sequence_combiner</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">normalizer</span><span class="o">=</span><span class="s2">&quot;l2-norm&quot;</span><span class="p">,</span>
        <span class="n">output_dims</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;product_embeddings&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">},</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have now constructed an <code class="docutils literal notranslate"><span class="pre">input_block</span></code> that will take our batch and transform it in a fashion that will make it amenable for further processing by subsequent layers of our model.</p>
<p>To test that everything has worked, we can pass our example <code class="docutils literal notranslate"><span class="pre">batch</span></code> through the <code class="docutils literal notranslate"><span class="pre">input_block</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us now construct the remaining layers of our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;hashed_url_list&#39;</span>

<span class="c1"># We do not need the `train_transformed` dataset here, but we do need</span>
<span class="c1"># to access the schema.</span>
<span class="c1"># It contains important information that will help our model construct itself.</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s1">&#39;train_transformed&#39;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;parquet&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span>

<span class="n">dmodel</span><span class="o">=</span><span class="mi">64</span>
<span class="n">mlp_block</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">(</span>
                <span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="n">dmodel</span><span class="p">],</span>
                <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                <span class="n">no_activation_last_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
<span class="n">transformer_block</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">XLNetBlock</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">dmodel</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
    <span class="n">input_block</span><span class="p">,</span>
    <span class="n">mlp_block</span><span class="p">,</span>
    <span class="n">transformer_block</span><span class="p">,</span>
    <span class="n">mm</span><span class="o">.</span><span class="n">CategoricalOutput</span><span class="p">(</span>
        <span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">(</span><span class="n">target</span><span class="p">),</span>
        <span class="n">default_loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And let us train it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">run_eagerly</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">NUM_EPOCHS</span><span class="p">,</span> <span class="n">pre</span><span class="o">=</span><span class="n">mm</span><span class="o">.</span><span class="n">SequenceMaskRandom</span><span class="p">(</span><span class="n">schema</span><span class="o">=</span><span class="n">loader</span><span class="o">.</span><span class="n">output_schema</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">masking_prob</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">transformer</span><span class="o">=</span><span class="n">transformer_block</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.
  warnings.warn(
2023-06-20 22:58:58.950175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
WARNING:tensorflow:Gradients do not exist for variables [&#39;model/mask_emb:0&#39;, &#39;transformer/layer_._0/rel_attn/r_s_bias:0&#39;, &#39;transformer/layer_._0/rel_attn/seg_embed:0&#39;, &#39;transformer/layer_._1/rel_attn/r_s_bias:0&#39;, &#39;transformer/layer_._1/rel_attn/seg_embed:0&#39;] when minimizing the loss. If you&#39;re using `model.compile()`, did you forget to provide a `loss` argument?
WARNING:tensorflow:Gradients do not exist for variables [&#39;model/mask_emb:0&#39;, &#39;transformer/layer_._0/rel_attn/r_s_bias:0&#39;, &#39;transformer/layer_._0/rel_attn/seg_embed:0&#39;, &#39;transformer/layer_._1/rel_attn/r_s_bias:0&#39;, &#39;transformer/layer_._1/rel_attn/seg_embed:0&#39;] when minimizing the loss. If you&#39;re using `model.compile()`, did you forget to provide a `loss` argument?
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-06-20 22:59:11.285571: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: model/xl_net_block/sequential_block_7/replace_masked_embeddings/RaggedWhere/Assert/AssertGuard/branch_executed/_95
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>18/18 [==============================] - 42s 2s/step - loss: 6.9800 - recall_at_10: 0.0106 - mrr_at_10: 0.0033 - ndcg_at_10: 0.0050 - map_at_10: 0.0033 - precision_at_10: 0.0011 - regularization_loss: 0.0000e+00 - loss_batch: 6.9689
Epoch 2/5
18/18 [==============================] - 34s 2s/step - loss: 6.9591 - recall_at_10: 0.0106 - mrr_at_10: 0.0031 - ndcg_at_10: 0.0048 - map_at_10: 0.0031 - precision_at_10: 0.0011 - regularization_loss: 0.0000e+00 - loss_batch: 6.9363
Epoch 3/5
18/18 [==============================] - 39s 2s/step - loss: 6.9471 - recall_at_10: 0.0107 - mrr_at_10: 0.0028 - ndcg_at_10: 0.0046 - map_at_10: 0.0028 - precision_at_10: 0.0011 - regularization_loss: 0.0000e+00 - loss_batch: 6.9206
Epoch 4/5
18/18 [==============================] - 38s 2s/step - loss: 6.9398 - recall_at_10: 0.0103 - mrr_at_10: 0.0030 - ndcg_at_10: 0.0047 - map_at_10: 0.0030 - precision_at_10: 0.0010 - regularization_loss: 0.0000e+00 - loss_batch: 6.9015
Epoch 5/5
18/18 [==============================] - 38s 2s/step - loss: 6.9375 - recall_at_10: 0.0104 - mrr_at_10: 0.0030 - ndcg_at_10: 0.0047 - map_at_10: 0.0030 - precision_at_10: 0.0010 - regularization_loss: 0.0000e+00 - loss_batch: 6.9095
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f55081d17c0&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="serving-predictions">
<h2>Serving predictions<a class="headerlink" href="#serving-predictions" title="Permalink to this heading">#</a></h2>
<p>Now that we have prepared a workflow for processing our data (<code class="docutils literal notranslate"><span class="pre">wf</span></code>), defined the embedding operator (<code class="docutils literal notranslate"><span class="pre">embedding_operator</span></code>) and trained our model (<code class="docutils literal notranslate"><span class="pre">model</span></code>), we have all the components we need to serve our model using the Triton Inference Server (TIS).</p>
<p>Let us define a set of inference operators (a pipeline for processing our data all the way to obtaining predictions) and export them as an ensemble that we will be able to serve using TIS.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.dag.ops.tensorflow</span> <span class="kn">import</span> <span class="n">PredictTensorflow</span>
<span class="kn">from</span> <span class="nn">merlin.systems.dag.ensemble</span> <span class="kn">import</span> <span class="n">Ensemble</span>
<span class="kn">from</span> <span class="nn">merlin.systems.dag.ops.workflow</span> <span class="kn">import</span> <span class="n">TransformWorkflow</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inference_operators</span> <span class="o">=</span> <span class="n">wf</span><span class="o">.</span><span class="n">input_schema</span><span class="o">.</span><span class="n">column_names</span> <span class="o">&gt;&gt;</span> <span class="n">TransformWorkflow</span><span class="p">(</span><span class="n">wf</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">embedding_operator</span> <span class="o">&gt;&gt;</span> <span class="n">PredictTensorflow</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, sequence_mask_random_layer_call_fn, sequence_mask_random_layer_call_and_return_conditional_losses, prepare_list_features_1_layer_call_fn while saving (showing 5 of 110). These functions will not be directly callable after loading.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Assets written to: /tmp/tmpi3g8g7q7/assets
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Assets written to: /tmp/tmpi3g8g7q7/assets
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ensemble</span> <span class="o">=</span> <span class="n">Ensemble</span><span class="p">(</span><span class="n">inference_operators</span><span class="p">,</span> <span class="n">wf</span><span class="o">.</span><span class="n">input_schema</span><span class="p">)</span>
<span class="n">ensemble</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;ensemble&#39;</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Skipping full serialization of Keras layer TFSharedEmbeddings(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Skipping full serialization of Keras layer Dropout(
  (_feature_shapes): Dict(
    (product_sku_hash_list): TensorShape([16, None, 1])
    (event_type_list): TensorShape([16, None, 1])
    (product_action_list): TensorShape([16, None, 1])
    (hashed_url_list): TensorShape([16, None, 1])
    (product_embeddings): TensorShape([16, None, 50])
  )
  (_feature_dtypes): Dict(
    (product_sku_hash_list): tf.int64
    (event_type_list): tf.int64
    (product_action_list): tf.int64
    (hashed_url_list): tf.int64
    (product_embeddings): tf.float32
  )
), because it is not built.
WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, sequence_mask_random_layer_call_fn, sequence_mask_random_layer_call_and_return_conditional_losses, prepare_list_features_1_layer_call_fn while saving (showing 5 of 110). These functions will not be directly callable after loading.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Assets written to: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel/assets
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:tensorflow:Assets written to: /workspace/data/ensemble/1_predicttensorflowtriton/1/model.savedmodel/assets
/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py:101: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  config[key] = tf.keras.utils.serialize_keras_object(maybe_value)
/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/combinators.py:288: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  config[i] = tf.keras.utils.serialize_keras_object(layer)
/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  return serialization.serialize_keras_object(obj)
/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.
  warnings.warn(
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
</pre></div>
</div>
</div>
</div>
<p>After we export the ensemble, we are ready to start the Triton Inference Server.</p>
<p>The server is installed in Merlin Tensorflow and Merlin PyTorch containers. If you are not using one of our containers, then ensure it is installed in your environment. For more information, see the Triton Inference Server <a class="reference external" href="https://github.com/triton-inference-server/server/blob/r22.03/README.md#documentation">documentation</a>.</p>
<p>You can start the server by running the following command:</p>
<p><code class="docutils literal notranslate"><span class="pre">tritonserver</span> <span class="pre">--model-repository={OUTPUT_DATA_DIR}/ensemble/</span></code></p>
<p>For the –model-repository argument, specify the same value as the <code class="docutils literal notranslate"><span class="pre">export_path</span></code> that you specified previously in the <code class="docutils literal notranslate"><span class="pre">ensemble.export</span></code> method.</p>
<p>After you run the <code class="docutils literal notranslate"><span class="pre">tritonserver</span></code> command, wait until your terminal shows messages like the following example:</p>
<p>I0414 18:29:50.741833 4067 grpc_server.cc:4421] Started GRPCInferenceService at 0.0.0.0:8001<br>
I0414 18:29:50.742197 4067 http_server.cc:3113] Started HTTPService at 0.0.0.0:8000<br>
I0414 18:29:50.783470 4067 http_server.cc:178] Started Metrics Service at 0.0.0.0:8002</p>
<p>Let us now package our data for inference. We will send 5 rows of data, which corresponds to a single customer journey (session) through the online store. The data will be first processed by the <code class="docutils literal notranslate"><span class="pre">NVTabular</span></code> workflow and subsequentally passed to our transformer model for predicting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># obtaining five rows of data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="c1"># making sure all the rows correspond to the same online session (have the same `session_id_hash`)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;session_id_hash&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;session_id_hash&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let us now send the data to the Triton Inference Server for inference.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin.systems.triton</span> <span class="kn">import</span> <span class="n">convert_df_to_triton_input</span>
<span class="kn">import</span> <span class="nn">tritonclient.grpc</span> <span class="k">as</span> <span class="nn">grpcclient</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">convert_df_to_triton_input</span><span class="p">(</span><span class="n">wf</span><span class="o">.</span><span class="n">input_schema</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

<span class="k">with</span> <span class="n">grpcclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="p">(</span><span class="s2">&quot;localhost:8001&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">client</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="s1">&#39;executor_model&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s parse the response.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="s2">&quot;hashed_url_list/categorical_output&quot;</span><span class="p">)</span>
<span class="n">predictions</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-2.2332087 , -2.1218574 , -2.390479  , ..., -0.7735352 ,
         0.1954267 , -0.34523243]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>The response contains logits predicting the id of the url the customer is most likely to arrive at as next step of their journey through the online store.</p>
<p>Here is the predicted hashed url id:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_hashed_url_id</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="n">predicted_hashed_url_id</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>34
</pre></div>
</div>
</div>
</div>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h2>
<p>We have trained a transformer model for the next item prediction task using language model masking.</p>
<p>For another session-based example that goes deeper into data preprocessing and that covers several advanced techniques (Weight Tying, Temperature Scaling) please see <a class="reference external" href="https://github.com/NVIDIA-Merlin/models/blob/t4rec_use_case/examples/usecases/ecommerce-session-based-next-item-prediction-for-fashion.ipynb">Session-Based Next Item Prediction for Fashion E-Commerce</a>.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning objectives</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#downloading-and-preparing-the-dataset">Downloading and preparing the dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clean-downloaded-data">Clean downloaded data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-synthetic-data">Generate synthetic data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-a-workflow">Constructing a workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-and-training-the-model">Creating and training the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#serving-predictions">Serving predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, NVIDIA.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>